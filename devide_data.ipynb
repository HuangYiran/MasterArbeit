{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devide the dataset into training data and valuation data and test data:<br>\n",
    "The target set here are hidden value and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_s1 = '../data/MasterArbeit/plan_c_rank_en.de/hidden_ed_2015_s1'\n",
    "src_s2 = '../data/MasterArbeit/plan_c_rank_en.de/hidden_ed_2015_s2'\n",
    "src_ref = '../data/MasterArbeit/plan_c_rank_en.de/hidden_ed_2015_ref'\n",
    "tgt = '../data/MasterArbeit/plan_c_rank_en.de/data_result_2015'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_sys = '../data/MasterArbeit/plan_a_en.de/sys_hidden'\n",
    "src_ref = '../data/MasterArbeit/plan_a_en.de/ref_hidden'\n",
    "tgt = '../data/MasterArbeit/plan_a_en.de/data_scores'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## read hidden value\n",
    "import numpy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9392\n"
     ]
    }
   ],
   "source": [
    "with file(src_sys) as fi:\n",
    "    data_sys_out = torch.from_numpy(numpy.load(fi))\n",
    "print(len(data_sys_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9392\n"
     ]
    }
   ],
   "source": [
    "with file(src_ref) as fi:\n",
    "    data_ref = torch.from_numpy(numpy.load(fi))\n",
    "print(len(data_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54447\n"
     ]
    }
   ],
   "source": [
    "with file(src_ref) as fi:\n",
    "    data_ref = torch.from_numpy(numpy.load(fi))\n",
    "print(len(data_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9392\n"
     ]
    }
   ],
   "source": [
    "data_scores = []\n",
    "with open(tgt) as fi:\n",
    "    for item in fi:\n",
    "        data_scores.append(item)\n",
    "print(len(data_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the ratio\n",
    "sep1 = int(round(len(data_sys_out)*0.1))\n",
    "sep2 = int(round(len(data_sys_out)*0.2))\n",
    "end = len(data_sys_out) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the ration\n",
    "sep = int(round(len(data_s1)*0.5))\n",
    "end = len(data_s1) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# departure the data\n",
    "val_s1 = data_s1[0: sep]\n",
    "val_s2 = data_s2[0: sep]\n",
    "val_ref = data_ref[0: sep]\n",
    "val_result = data_scores[0: sep]\n",
    "\n",
    "test_s1 = data_s1[sep: end]\n",
    "test_s2 = data_s2[sep: end]\n",
    "test_ref = data_ref[sep: end]\n",
    "test_result = data_scores[sep: end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_val_s1 = '../data/MasterArbeit/plan_c_rank_en.de/val_s1_hidden'\n",
    "dir_val_s2 = '../data/MasterArbeit/plan_c_rank_en.de/val_s2_hidden'\n",
    "dir_val_ref = '../data/MasterArbeit/plan_c_rank_en.de/val_ref_hidden'\n",
    "dir_val_tgt = '../data/MasterArbeit/plan_c_rank_en.de/val_result'\n",
    "\n",
    "dir_test_s1 = '../data/MasterArbeit/plan_c_rank_en.de/test_s1_hidden'\n",
    "dir_test_s2 = '../data/MasterArbeit/plan_c_rank_en.de/test_s2_hidden'\n",
    "dir_test_ref = '../data/MasterArbeit/plan_c_rank_en.de/test_ref_hidden'\n",
    "dir_test_tgt = '../data/MasterArbeit/plan_c_rank_en.de/test_result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_numpy(val_s1, dir_val_s1)\n",
    "write_numpy(val_s2, dir_val_s2)\n",
    "write_numpy(val_ref, dir_val_ref)\n",
    "write_data(dir_val_tgt, val_result)\n",
    "\n",
    "write_numpy(test_s1, dir_test_s1)\n",
    "write_numpy(test_s2, dir_test_s2)\n",
    "write_numpy(test_ref, dir_test_ref)\n",
    "write_data(dir_test_tgt, test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# departure the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sys_out = data_sys_out[sep2:end]\n",
    "train_ref = data_ref[sep2:end]\n",
    "train_scores = data_scores[sep2:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_sys_out = data_sys_out[sep1+1:sep2]\n",
    "val_ref = data_ref[sep1+1:sep2]\n",
    "val_scores = data_scores[sep1+1:sep2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sys_out = data_sys_out[0:sep1]\n",
    "test_ref = data_ref[0:sep1]\n",
    "test_scores = data_scores[0:sep1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_train_sys_hidden = '../data/MasterArbeit/plan_a_en.de/train_sys_hidden'\n",
    "out_train_ref_hidden = '../data/MasterArbeit/plan_a_en.de/train_ref_hidden'\n",
    "out_train_scores = '../data/MasterArbeit/plan_a_en.de/train_scores'\n",
    "\n",
    "out_val_sys_hidden = '../data/MasterArbeit/plan_a_en.de/val_sys_hidden'\n",
    "out_val_ref_hidden = '../data/MasterArbeit/plan_a_en.de/val_ref_hidden'\n",
    "out_val_scores = '../data/MasterArbeit/plan_a_en.de/val_scores'\n",
    "\n",
    "out_test_sys_hidden = '../data/MasterArbeit/plan_a_en.de/test_sys_hidden'\n",
    "out_test_ref_hidden = '../data/MasterArbeit/plan_a_en.de/test_ref_hidden'\n",
    "out_test_scores = '../data/MasterArbeit/plan_a_en.de/test_scores'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_numpy(src, tgt):\n",
    "    with open(tgt,'w') as fi:\n",
    "        tmp = src.numpy()\n",
    "        numpy.save(fi, tmp)\n",
    "def write_data(filename, li):\n",
    "    with open(filename, 'w') as fi:\n",
    "        for line in li:\n",
    "            fi.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_numpy(train_sys_out, out_train_sys_hidden)\n",
    "write_numpy(train_ref, out_train_ref_hidden)\n",
    "write_numpy(val_sys_out, out_val_sys_hidden)\n",
    "write_numpy(val_ref, out_val_ref_hidden)\n",
    "write_numpy(test_sys_out, out_test_sys_hidden)\n",
    "write_numpy(test_ref, out_test_ref_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_data(out_train_scores, train_scores)\n",
    "write_data(out_val_scores, val_scores)\n",
    "write_data(out_test_scores, test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "the original set is too large. try to devide it into small sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys = \"../data/MasterArbeit/data2/pred_prepronc\"\n",
    "ref = \"../data/MasterArbeit/data2/ref_prepronc\"\n",
    "src = \"../data/MasterArbeit/data2/src_prepronc\"\n",
    "tgt = \"../data/MasterArbeit/data2/record_prepronc_clean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254074\n"
     ]
    }
   ],
   "source": [
    "data_sys = []\n",
    "with open(sys) as fi:\n",
    "    for item in fi:\n",
    "        data_sys.append(item)\n",
    "print(len(data_sys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254074\n"
     ]
    }
   ],
   "source": [
    "data_ref = []\n",
    "with open(ref) as fi:\n",
    "    for item in fi:\n",
    "        data_ref.append(item)\n",
    "print(len(data_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254074\n"
     ]
    }
   ],
   "source": [
    "data_src = []\n",
    "with open(src) as fi:\n",
    "    for item in fi:\n",
    "        data_src.append(item)\n",
    "print(len(data_src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254074\n"
     ]
    }
   ],
   "source": [
    "data_scores = []\n",
    "with open(tgt) as fi:\n",
    "    for item in fi:\n",
    "        data_scores.append(item)\n",
    "print(len(data_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_data(filename, li):\n",
    "    with open(filename, 'w') as fi:\n",
    "        for line in li:\n",
    "            fi.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25408"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_block = 10\n",
    "num_sent = len(data_sys)\n",
    "len_block = int(math.ceil(num_sent*1.0/num_block))\n",
    "len_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(num_block):\n",
    "    start = i * len_block\n",
    "    if (i+1)*len_block > num_sent:\n",
    "        end = num_sent\n",
    "    else:\n",
    "        end = (i+1) * len_block \n",
    "    filename_src = \"../data/MasterArbeit/data2/src_prepronc\"+str(i+1)\n",
    "    filename_sys = \"../data/MasterArbeit/data2/sys_prepronc\"+str(i+1)\n",
    "    filename_ref = \"../data/MasterArbeit/data2/ref_prepronc\"+str(i+1)\n",
    "    filename_scores = \"../data/MasterArbeit/data2/record_prepronc_cleaned\"+str(i+1)\n",
    "    write_data(filename_src, data_src[start:end])\n",
    "    write_data(filename_sys, data_sys[start:end])\n",
    "    write_data(filename_ref, data_ref[start:end])\n",
    "    write_data(filename_scores, tgt[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### cross valuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plan A en-de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## read hidden value\n",
    "import numpy\n",
    "import torch\n",
    "import math\n",
    "\n",
    "src_sys = '../data/MasterArbeit/plan_a_en.de/sys_hidden'\n",
    "src_ref = '../data/MasterArbeit/plan_a_en.de/ref_hidden'\n",
    "tgt = '../data/MasterArbeit/plan_a_en.de/data_scores'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9392\n",
      "9392\n",
      "9392\n"
     ]
    }
   ],
   "source": [
    "with file(src_sys) as fi:\n",
    "    data_sys_out = torch.from_numpy(numpy.load(fi))\n",
    "print(len(data_sys_out))\n",
    "with file(src_ref) as fi:\n",
    "    data_ref = torch.from_numpy(numpy.load(fi))\n",
    "print(len(data_ref))\n",
    "data_scores = []\n",
    "with open(tgt) as fi:\n",
    "    for item in fi:\n",
    "        data_scores.append(item)\n",
    "print(len(data_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "940"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_size = int(math.ceil(len(data_sys_out)*1.0/10))\n",
    "chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sys_out_list = torch.split(data_sys_out, chunk_size)\n",
    "data_ref_list = torch.split(data_sys_out, chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "seps = []\n",
    "tmp = 0\n",
    "for i in range(len(data_sys_out_list)):\n",
    "    tmp += len(data_sys_out_list[i])\n",
    "    seps.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[940, 1880, 2820, 3760, 4700, 5640, 6580, 7520, 8460, 9392]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scores = numpy.array(data_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scores_list = numpy.array_split(data_scores, seps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "932"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_scores_list[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_train_sys_hidden = '../data/MasterArbeit/plan_a_en.de_cross/train_sys_hidden'\n",
    "out_train_ref_hidden = '../data/MasterArbeit/plan_a_en.de_cross/train_ref_hidden'\n",
    "out_train_scores = '../data/MasterArbeit/plan_a_en.de_cross/train_scores'\n",
    "\n",
    "out_val_sys_hidden = '../data/MasterArbeit/plan_a_en.de_cross/val_sys_hidden'\n",
    "out_val_ref_hidden = '../data/MasterArbeit/plan_a_en.de_cross/val_ref_hidden'\n",
    "out_val_scores = '../data/MasterArbeit/plan_a_en.de_cross/val_scores'\n",
    "\n",
    "out_test_sys_hidden = '../data/MasterArbeit/plan_a_en.de_cross/test_sys_hidden'\n",
    "out_test_ref_hidden = '../data/MasterArbeit/plan_a_en.de_cross/test_ref_hidden'\n",
    "out_test_scores = '../data/MasterArbeit/plan_a_en.de_cross/test_scores'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_numpy(src, tgt):\n",
    "    with open(tgt,'w') as fi:\n",
    "        tmp = src.numpy()\n",
    "        numpy.save(fi, tmp)\n",
    "def write_data(filename, li):\n",
    "    with open(filename, 'w') as fi:\n",
    "        for line in li:\n",
    "            fi.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chunks = len(data_sys_out_list)\n",
    "for i in range(num_chunks):\n",
    "    # attributes to hold the data\n",
    "    val_sys_out = []\n",
    "    val_ref = []\n",
    "    val_scores = []\n",
    "    test_sys_out = []\n",
    "    test_ref = []\n",
    "    test_scores = []\n",
    "    train_sys_out = []\n",
    "    train_ref = []\n",
    "    train_scores = []\n",
    "    # distribute index\n",
    "    tmp_data_sys = list(map(lambda x: id(x), data_sys_out_list))\n",
    "    tmp_data_ref = list(map(lambda x: id(x), data_ref_list))\n",
    "    tmp_scores = list(map(lambda x: id(x), data_scores_list))\n",
    "    val_sys_out.append(tmp_data_sys[i])\n",
    "    val_ref.append( tmp_data_ref[i])\n",
    "    val_scores.append(tmp_scores[i])\n",
    "    if i + 1 == num_chunks:\n",
    "        test_sys_out.append(tmp_data_sys[1])\n",
    "        test_ref.append(tmp_data_ref[1])\n",
    "        test_scores.append(tmp_scores[1])\n",
    "    else:\n",
    "        test_sys_out.append(tmp_data_sys[i+1])\n",
    "        test_ref.append(tmp_data_ref[i+1])\n",
    "        test_scores.append(tmp_scores[i+1])\n",
    "    tmp_data_sys.remove(val_sys_out[0])\n",
    "    tmp_data_sys.remove(test_sys_out[0])\n",
    "    tmp_data_ref.remove(val_ref[0])\n",
    "    tmp_data_ref.remove(test_ref[0])\n",
    "    tmp_scores.remove(val_scores[0])\n",
    "    tmp_scores.remove(test_scores[0])\n",
    "    train_sys_out.extend(tmp_data_sys)\n",
    "    train_ref.extend(tmp_data_ref)\n",
    "    train_scores.extend(tmp_scores)\n",
    "    # read data\n",
    "    val_sys_out = read_data(val_sys_out, data_sys_out_list)\n",
    "    test_sys_out = read_data(test_sys_out, data_sys_out_list)\n",
    "    train_sys_out = read_data(train_sys_out, data_sys_out_list)\n",
    "    val_ref = read_data(val_ref, data_ref_list)\n",
    "    test_ref = read_data(test_ref, data_ref_list)\n",
    "    train_ref = read_data(train_ref, data_ref_list)\n",
    "    val_scores = read_data(val_scores, data_scores_list)\n",
    "    test_scores = read_data(test_scores, data_scores_list)\n",
    "    train_scores = read_data(train_scores, data_scores_list)\n",
    "    # change the type of the attribute if necessary\n",
    "    val_sys_out = torch.cat(val_sys_out)\n",
    "    test_sys_out = torch.cat(test_sys_out)\n",
    "    train_sys_out = torch.cat(train_sys_out)\n",
    "    val_ref = torch.cat(val_ref)\n",
    "    test_ref = torch.cat(test_ref)\n",
    "    train_ref = torch.cat(train_ref)\n",
    "    write_numpy(train_sys_out, out_train_sys_hidden+str(i))\n",
    "    write_numpy(train_ref, out_train_ref_hidden+str(i))\n",
    "    write_numpy(val_sys_out, out_val_sys_hidden+str(i))\n",
    "    write_numpy(val_ref, out_val_ref_hidden+str(i))\n",
    "    write_numpy(test_sys_out, out_test_sys_hidden+str(i))\n",
    "    write_numpy(test_ref, out_test_ref_hidden+str(i))\n",
    "    write_data(out_train_scores+str(i), train_scores)\n",
    "    write_data(out_val_scores+str(i), val_scores)\n",
    "    write_data(out_test_scores+str(i), test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(a, b):\n",
    "    return [x for x in b if id(x) in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_sys_out_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plan A de-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## read hidden value\n",
    "import numpy\n",
    "import torch\n",
    "import math\n",
    "\n",
    "src_sys = '../data/MasterArbeit/plan_a_de.en/sys_hidden'\n",
    "src_ref = '../data/MasterArbeit/plan_a_de.en/ref_hidden'\n",
    "tgt = '../data/MasterArbeit/plan_a_de.en/data_scores'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26857\n",
      "26857\n",
      "26857\n"
     ]
    }
   ],
   "source": [
    "with file(src_sys) as fi:\n",
    "    data_sys_out = torch.from_numpy(numpy.load(fi))\n",
    "print(len(data_sys_out))\n",
    "with file(src_ref) as fi:\n",
    "    data_ref = torch.from_numpy(numpy.load(fi))\n",
    "print(len(data_ref))\n",
    "data_scores = []\n",
    "with open(tgt) as fi:\n",
    "    for item in fi:\n",
    "        data_scores.append(item)\n",
    "print(len(data_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2686"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_size = int(math.ceil(len(data_sys_out)*1.0/10))\n",
    "chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_sys_out_list = torch.split(data_sys_out, chunk_size)\n",
    "data_ref_list = torch.split(data_sys_out, chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seps = []\n",
    "tmp = 0\n",
    "for i in range(len(data_sys_out_list)):\n",
    "    tmp += len(data_sys_out_list[i])\n",
    "    seps.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2686, 5372, 8058, 10744, 13430, 16116, 18802, 21488, 24174, 26857]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2683"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_scores = numpy.array(data_scores)\n",
    "data_scores_list = numpy.array_split(data_scores, seps)\n",
    "len(data_scores_list[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_train_sys_hidden = '../data/MasterArbeit/plan_a_de.en_cross/train_sys_hidden'\n",
    "out_train_ref_hidden = '../data/MasterArbeit/plan_a_de.en_cross/train_ref_hidden'\n",
    "out_train_scores = '../data/MasterArbeit/plan_a_de.en_cross/train_scores'\n",
    "\n",
    "out_val_sys_hidden = '../data/MasterArbeit/plan_a_de.en_cross/val_sys_hidden'\n",
    "out_val_ref_hidden = '../data/MasterArbeit/plan_a_de.en_cross/val_ref_hidden'\n",
    "out_val_scores = '../data/MasterArbeit/plan_a_de.en_cross/val_scores'\n",
    "\n",
    "out_test_sys_hidden = '../data/MasterArbeit/plan_a_de.en_cross/test_sys_hidden'\n",
    "out_test_ref_hidden = '../data/MasterArbeit/plan_a_de.en_cross/test_ref_hidden'\n",
    "out_test_scores = '../data/MasterArbeit/plan_a_de.en_cross/test_scores'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_numpy(src, tgt):\n",
    "    with open(tgt,'w') as fi:\n",
    "        tmp = src.numpy()\n",
    "        numpy.save(fi, tmp)\n",
    "def write_data(filename, li):\n",
    "    with open(filename, 'w') as fi:\n",
    "        for line in li:\n",
    "            fi.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(a, b):\n",
    "    return [x for x in b if id(x) in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_chunks = len(data_sys_out_list)\n",
    "for i in range(num_chunks):\n",
    "    # attributes to hold the data\n",
    "    val_sys_out = []\n",
    "    val_ref = []\n",
    "    val_scores = []\n",
    "    test_sys_out = []\n",
    "    test_ref = []\n",
    "    test_scores = []\n",
    "    train_sys_out = []\n",
    "    train_ref = []\n",
    "    train_scores = []\n",
    "    # distribute index\n",
    "    tmp_data_sys = list(map(lambda x: id(x), data_sys_out_list))\n",
    "    tmp_data_ref = list(map(lambda x: id(x), data_ref_list))\n",
    "    tmp_scores = list(map(lambda x: id(x), data_scores_list))\n",
    "    val_sys_out.append(tmp_data_sys[i])\n",
    "    val_ref.append( tmp_data_ref[i])\n",
    "    val_scores.append(tmp_scores[i])\n",
    "    if i + 1 == num_chunks:\n",
    "        test_sys_out.append(tmp_data_sys[1])\n",
    "        test_ref.append(tmp_data_ref[1])\n",
    "        test_scores.append(tmp_scores[1])\n",
    "    else:\n",
    "        test_sys_out.append(tmp_data_sys[i+1])\n",
    "        test_ref.append(tmp_data_ref[i+1])\n",
    "        test_scores.append(tmp_scores[i+1])\n",
    "    tmp_data_sys.remove(val_sys_out[0])\n",
    "    tmp_data_sys.remove(test_sys_out[0])\n",
    "    tmp_data_ref.remove(val_ref[0])\n",
    "    tmp_data_ref.remove(test_ref[0])\n",
    "    tmp_scores.remove(val_scores[0])\n",
    "    tmp_scores.remove(test_scores[0])\n",
    "    train_sys_out.extend(tmp_data_sys)\n",
    "    train_ref.extend(tmp_data_ref)\n",
    "    train_scores.extend(tmp_scores)\n",
    "    # read data\n",
    "    val_sys_out = read_data(val_sys_out, data_sys_out_list)\n",
    "    test_sys_out = read_data(test_sys_out, data_sys_out_list)\n",
    "    train_sys_out = read_data(train_sys_out, data_sys_out_list)\n",
    "    val_ref = read_data(val_ref, data_ref_list)\n",
    "    test_ref = read_data(test_ref, data_ref_list)\n",
    "    train_ref = read_data(train_ref, data_ref_list)\n",
    "    val_scores = read_data(val_scores, data_scores_list)\n",
    "    test_scores = read_data(test_scores, data_scores_list)\n",
    "    train_scores = read_data(train_scores, data_scores_list)\n",
    "    # change the type of the attribute if necessary\n",
    "    val_sys_out = torch.cat(val_sys_out)\n",
    "    test_sys_out = torch.cat(test_sys_out)\n",
    "    train_sys_out = torch.cat(train_sys_out)\n",
    "    val_ref = torch.cat(val_ref)\n",
    "    test_ref = torch.cat(test_ref)\n",
    "    train_ref = torch.cat(train_ref)\n",
    "    write_numpy(train_sys_out, out_train_sys_hidden+str(i))\n",
    "    write_numpy(train_ref, out_train_ref_hidden+str(i))\n",
    "    write_numpy(val_sys_out, out_val_sys_hidden+str(i))\n",
    "    write_numpy(val_ref, out_val_ref_hidden+str(i))\n",
    "    write_numpy(test_sys_out, out_test_sys_hidden+str(i))\n",
    "    write_numpy(test_ref, out_test_ref_hidden+str(i))\n",
    "    write_data(out_train_scores+str(i), train_scores)\n",
    "    write_data(out_val_scores+str(i), val_scores)\n",
    "    write_data(out_test_scores+str(i), test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plan B en-de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 先把分过的数据给综合在一起 val是重复数据，所以不用\n",
    "train_sys = '../data/MasterArbeit/plan_b_en.de/train_sys_hidden'\n",
    "train_ref = '../data/MasterArbeit/plan_b_en.de/train_ref_hidden'\n",
    "train_tgt = '../data/MasterArbeit/plan_b_en.de/train_scores'\n",
    "test_sys = '../data/MasterArbeit/plan_b_en.de/test_sys_hidden'\n",
    "test_ref = '../data/MasterArbeit/plan_b_en.de/test_ref_hidden'\n",
    "test_tgt = '../data/MasterArbeit/plan_b_en.de/test_scores'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8257\n",
      "8257\n",
      "8257\n"
     ]
    }
   ],
   "source": [
    "with file(train_sys) as fi:\n",
    "    train_sys_out = torch.from_numpy(numpy.load(fi))\n",
    "print(len(train_sys_out))\n",
    "with file(train_ref) as fi:\n",
    "    train_ref = torch.from_numpy(numpy.load(fi))\n",
    "print(len(train_ref))\n",
    "train_scores = []\n",
    "with open(train_tgt) as fi:\n",
    "    for item in fi:\n",
    "        train_scores.append(item)\n",
    "print(len(train_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626\n",
      "626\n",
      "626\n"
     ]
    }
   ],
   "source": [
    "with file(test_sys) as fi:\n",
    "    test_sys_out = torch.from_numpy(numpy.load(fi))\n",
    "print(len(test_sys_out))\n",
    "with file(test_ref) as fi:\n",
    "    test_ref = torch.from_numpy(numpy.load(fi))\n",
    "print(len(test_ref))\n",
    "test_scores = []\n",
    "with open(test_tgt) as fi:\n",
    "    for item in fi:\n",
    "        test_scores.append(item)\n",
    "print(len(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并数据\n",
    "data_sys_out = torch.cat((train_sys_out, test_sys_out), 0)\n",
    "data_ref = torch.cat((train_ref, test_ref), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores.extend(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scores = train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8883, 500])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "syses = ['C-3MA.4959','fbk-nmt-combination.4870','KIT.4950','LIUM-NMT.4900','LMU-nmt-reranked.4934','LMU-nmt-single.4893','online-A.0','online-B.0','online-F.0','online-G.0','PROMT-Rule-based.4735','RWTH-nmt-ensemble.4921','SYSTRAN.4847','TALP-UPC.4834','xmu.4910']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "seps = [628, 525, 532, 546, 600, 477, 585, 590, 590, 687, 610, 624, 630, 633, 626] #这是下个系统的首句所在位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sys = len(seps)\n",
    "for i in range(num_sys):\n",
    "    tmp = numpy.array(seps)[:num_sys - i]\n",
    "    seps[num_sys - i - 1] = sum(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "626"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_sys_out_list[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据，因为要使用到numpy的split方法，所以先转化为numpy.array后再进行划分\n",
    "data_sys_out = data_sys_out.numpy()\n",
    "data_ref = data_ref.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多维矩阵使用 vsplit， 单维使用array_split，各个chunk的大小如上所示\n",
    "data_sys_out_list = numpy.vsplit(data_sys_out, seps)[:-1]\n",
    "data_ref_list = numpy.vsplit(data_ref, seps)[:-1]\n",
    "data_scores_list = numpy.array_split(data_scores, seps)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始cross咯， 原理很简单，就是一个个抽离，剩下的就是给train的， 程序是前面复制下来的，\n",
    "# 和前面不同的是，这里的数据已近被换成是numpy.ndarray了，而前面的是tensor\n",
    "# 还有就是这里要输出系统名字的，所以要多一个步骤\n",
    "# 所以为了同步，就先进行转化咯\n",
    "data_sys_out_list = map(lambda x: torch.Tensor(x), data_sys_out_list)\n",
    "data_ref_list = map(lambda x: torch.Tensor(x), data_ref_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_train_sys_hidden = '../data/MasterArbeit/plan_b_en.de_cross/train_sys_hidden_'\n",
    "out_train_ref_hidden = '../data/MasterArbeit/plan_b_en.de_cross/train_ref_hidden_'\n",
    "out_train_scores = '../data/MasterArbeit/plan_b_en.de_cross/train_scores_'\n",
    "\n",
    "out_val_sys_hidden = '../data/MasterArbeit/plan_b_en.de_cross/val_sys_hidden_'\n",
    "out_val_ref_hidden = '../data/MasterArbeit/plan_b_en.de_cross/val_ref_hidden_'\n",
    "out_val_scores = '../data/MasterArbeit/plan_b_en.de_cross/val_scores_'\n",
    "\n",
    "out_test_sys_hidden = '../data/MasterArbeit/plan_b_en.de_cross/test_sys_hidden_'\n",
    "out_test_ref_hidden = '../data/MasterArbeit/plan_b_en.de_cross/test_ref_hidden_'\n",
    "out_test_scores = '../data/MasterArbeit/plan_b_en.de_cross/test_scores_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chunks = len(data_sys_out_list)\n",
    "for i in range(num_chunks):\n",
    "    j = i + 1\n",
    "    # attributes to hold the data\n",
    "    val_sys_out = []\n",
    "    val_ref = []\n",
    "    val_scores = []\n",
    "    test_sys_out = []\n",
    "    test_ref = []\n",
    "    test_scores = []\n",
    "    train_sys_out = []\n",
    "    train_ref = []\n",
    "    train_scores = []\n",
    "    # distribute index\n",
    "    tmp_data_sys = list(map(lambda x: id(x), data_sys_out_list))\n",
    "    tmp_data_ref = list(map(lambda x: id(x), data_ref_list))\n",
    "    tmp_scores = list(map(lambda x: id(x), data_scores_list))\n",
    "    val_sys_out.append(tmp_data_sys[i])\n",
    "    val_ref.append( tmp_data_ref[i])\n",
    "    val_scores.append(tmp_scores[i])\n",
    "    if i + 1 == num_chunks:\n",
    "        j = 1\n",
    "        test_sys_out.append(tmp_data_sys[1])\n",
    "        test_ref.append(tmp_data_ref[1])\n",
    "        test_scores.append(tmp_scores[1])\n",
    "    else:\n",
    "        test_sys_out.append(tmp_data_sys[i+1])\n",
    "        test_ref.append(tmp_data_ref[i+1])\n",
    "        test_scores.append(tmp_scores[i+1])\n",
    "    tmp_data_sys.remove(val_sys_out[0])\n",
    "    tmp_data_sys.remove(test_sys_out[0])\n",
    "    tmp_data_ref.remove(val_ref[0])\n",
    "    tmp_data_ref.remove(test_ref[0])\n",
    "    tmp_scores.remove(val_scores[0])\n",
    "    tmp_scores.remove(test_scores[0])\n",
    "    train_sys_out.extend(tmp_data_sys)\n",
    "    train_ref.extend(tmp_data_ref)\n",
    "    train_scores.extend(tmp_scores)\n",
    "    # read data\n",
    "    val_sys_out = read_data(val_sys_out, data_sys_out_list)\n",
    "    test_sys_out = read_data(test_sys_out, data_sys_out_list)\n",
    "    train_sys_out = read_data(train_sys_out, data_sys_out_list)\n",
    "    val_ref = read_data(val_ref, data_ref_list)\n",
    "    test_ref = read_data(test_ref, data_ref_list)\n",
    "    train_ref = read_data(train_ref, data_ref_list)\n",
    "    val_scores = read_data(val_scores, data_scores_list)\n",
    "    test_scores = read_data(test_scores, data_scores_list)\n",
    "    train_scores = read_data(train_scores, data_scores_list)\n",
    "    # change the type of the attribute if necessary\n",
    "    val_sys_out = torch.cat(val_sys_out)\n",
    "    test_sys_out = torch.cat(test_sys_out)\n",
    "    train_sys_out = torch.cat(train_sys_out)\n",
    "    val_ref = torch.cat(val_ref)\n",
    "    test_ref = torch.cat(test_ref)\n",
    "    train_ref = torch.cat(train_ref)\n",
    "    write_numpy(train_sys_out, out_train_sys_hidden+syses[i]+\"_\"+ syses[j])\n",
    "    write_numpy(train_ref, out_train_ref_hidden+syses[i]+\"_\"+ syses[j])\n",
    "    write_numpy(val_sys_out, out_val_sys_hidden+syses[i]+\"_\"+ syses[j])\n",
    "    write_numpy(val_ref, out_val_ref_hidden+syses[i]+\"_\"+ syses[j])\n",
    "    write_numpy(test_sys_out, out_test_sys_hidden+syses[i]+\"_\"+ syses[j])\n",
    "    write_numpy(test_ref, out_test_ref_hidden+syses[i]+\"_\"+ syses[j])\n",
    "    write_data(out_train_scores+syses[i]+\"_\"+ syses[j], train_scores)\n",
    "    write_data(out_val_scores+syses[i]+\"_\"+ syses[j], val_scores)\n",
    "    write_data(out_test_scores+syses[i]+\"_\"+ syses[j], test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/MasterArbeit/plan_a_en.de_cross/train_sys_hidden'"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_train_sys_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan b de.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sys_out = '../data/MasterArbeit/plan_b_de.en/train_sys_hidden'\n",
    "train_ref = '../data/MasterArbeit/plan_b_de.en/train_ref_hidden'\n",
    "train_tgt = '../data/MasterArbeit/plan_b_de.en/train_scores'\n",
    "test_sys_out = '../data/MasterArbeit/plan_b_de.en/test_sys_hidden'\n",
    "test_ref = '../data/MasterArbeit/plan_b_de.en/test_ref_hidden'\n",
    "test_tgt = '../data/MasterArbeit/plan_b_de.en/test_scores'\n",
    "val_sys_out = '../data/MasterArbeit/plan_b_de.en/val_sys_hidden'\n",
    "val_ref = '../data/MasterArbeit/plan_b_de.en/val_ref_hidden'\n",
    "val_tgt = '../data/MasterArbeit/plan_b_de.en/val_scores'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22144\n",
      "22144\n",
      "22144\n"
     ]
    }
   ],
   "source": [
    "with file(train_sys_out) as fi:\n",
    "    train_sys_out = torch.from_numpy(numpy.load(fi))\n",
    "print(len(train_sys_out))\n",
    "with file(train_ref) as fi:\n",
    "    train_ref = torch.from_numpy(numpy.load(fi))\n",
    "print(len(train_ref))\n",
    "train_scores = []\n",
    "with open(train_tgt) as fi:\n",
    "    for item in fi:\n",
    "        train_scores.append(item)\n",
    "print(len(train_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2185\n",
      "2185\n",
      "2185\n"
     ]
    }
   ],
   "source": [
    "with file(test_sys_out) as fi:\n",
    "    test_sys_out = torch.from_numpy(numpy.load(fi))\n",
    "print(len(test_sys_out))\n",
    "with file(test_ref) as fi:\n",
    "    test_ref = torch.from_numpy(numpy.load(fi))\n",
    "print(len(test_ref))\n",
    "test_scores = []\n",
    "with open(test_tgt) as fi:\n",
    "    for item in fi:\n",
    "        test_scores.append(item)\n",
    "print(len(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2528\n",
      "2528\n",
      "2528\n"
     ]
    }
   ],
   "source": [
    "with file(val_sys_out) as fi:\n",
    "    val_sys_out = torch.from_numpy(numpy.load(fi))\n",
    "print(len(val_sys_out))\n",
    "with file(val_ref) as fi:\n",
    "    val_ref = torch.from_numpy(numpy.load(fi))\n",
    "print(len(val_ref))\n",
    "val_scores = []\n",
    "with open(val_tgt) as fi:\n",
    "    for item in fi:\n",
    "        val_scores.append(item)\n",
    "print(len(val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并数据\n",
    "data_sys_out = torch.cat((train_sys_out, test_sys_out, val_sys_out), 0)\n",
    "data_ref = torch.cat((train_ref, test_ref, val_ref), 0)\n",
    "train_scores.extend(test_scores)\n",
    "train_scores.extend(val_scores)\n",
    "data_scores = train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "syses = ['C-3MA.4958',\n",
    "       'KIT.4951',\n",
    "       'LIUM-NMT.4733',\n",
    "       'online-A.0',\n",
    "       'online-B.0',\n",
    "       'online-F.0',\n",
    "       'online-G.0',\n",
    "       'RWTH-nmt-ensemble.4920',\n",
    "       'SYSTRAN.4846',\n",
    "       'uedin-nmt.4723',\n",
    "       'TALP-UPC.483',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seps = [2513, 2319, 2488, 2450, 2331, 2779, 2727, 2163, 2374, 2185, 2528]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_sys = len(seps)\n",
    "for i in range(num_sys):\n",
    "    tmp = numpy.array(seps)[:num_sys - i]\n",
    "    seps[num_sys - i - 1] = sum(tmp)\n",
    "seps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据，因为要使用到numpy的split方法，所以先转化为numpy.array后再进行划分\n",
    "data_sys_out = data_sys_out.numpy()\n",
    "data_ref = data_ref.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多维矩阵使用 vsplit， 单维使用array_split，各个chunk的大小如上所示\n",
    "data_sys_out_list = numpy.vsplit(data_sys_out, seps)[:-1]\n",
    "data_ref_list = numpy.vsplit(data_ref, seps)[:-1]\n",
    "data_scores_list = numpy.array_split(data_scores, seps)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 开始cross咯， 原理很简单，就是一个个抽离，剩下的就是给train的， 程序是前面复制下来的，\n",
    "# 和前面不同的是，这里的数据已近被换成是numpy.ndarray了，而前面的是tensor\n",
    "# 还有就是这里要输出系统名字的，所以要多一个步骤\n",
    "# 所以为了同步，就先进行转化咯\n",
    "data_sys_out_list = map(lambda x: torch.Tensor(x), data_sys_out_list)\n",
    "data_ref_list = map(lambda x: torch.Tensor(x), data_ref_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2374, 500])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sys_out_list[8].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_train_sys_hidden = '../data/MasterArbeit/plan_b_de.en_cross/train_sys_hidden_'\n",
    "out_train_ref_hidden = '../data/MasterArbeit/plan_b_de.en_cross/train_ref_hidden_'\n",
    "out_train_scores = '../data/MasterArbeit/plan_b_de.en_cross/train_scores_'\n",
    "\n",
    "out_val_sys_hidden = '../data/MasterArbeit/plan_b_de.en_cross/val_sys_hidden_'\n",
    "out_val_ref_hidden = '../data/MasterArbeit/plan_b_de.en_cross/val_ref_hidden_'\n",
    "out_val_scores = '../data/MasterArbeit/plan_b_de.en_cross/val_scores_'\n",
    "\n",
    "out_test_sys_hidden = '../data/MasterArbeit/plan_b_de.en_cross/test_sys_hidden_'\n",
    "out_test_ref_hidden = '../data/MasterArbeit/plan_b_de.en_cross/test_ref_hidden_'\n",
    "out_test_scores = '../data/MasterArbeit/plan_b_de.en_cross/test_scores_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(a, b):\n",
    "    return [x for x in b if id(x) in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_numpy(src, tgt):\n",
    "    with open(tgt,'w') as fi:\n",
    "        tmp = src.numpy()\n",
    "        numpy.save(fi, tmp)\n",
    "def write_data(filename, li):\n",
    "    with open(filename, 'w') as fi:\n",
    "        for line in li:\n",
    "            fi.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chunks = len(data_sys_out_list)\n",
    "for i in range(num_chunks):\n",
    "    j = i + 1\n",
    "    # attributes to hold the data\n",
    "    val_sys_out = []\n",
    "    val_ref = []\n",
    "    val_scores = []\n",
    "    test_sys_out = []\n",
    "    test_ref = []\n",
    "    test_scores = []\n",
    "    train_sys_out = []\n",
    "    train_ref = []\n",
    "    train_scores = []\n",
    "    # distribute index\n",
    "    tmp_data_sys = list(map(lambda x: id(x), data_sys_out_list))\n",
    "    tmp_data_ref = list(map(lambda x: id(x), data_ref_list))\n",
    "    tmp_scores = list(map(lambda x: id(x), data_scores_list))\n",
    "    val_sys_out.append(tmp_data_sys[i])\n",
    "    val_ref.append( tmp_data_ref[i])\n",
    "    val_scores.append(tmp_scores[i])\n",
    "    if i + 1 == num_chunks:\n",
    "        j = 1\n",
    "        test_sys_out.append(tmp_data_sys[1])\n",
    "        test_ref.append(tmp_data_ref[1])\n",
    "        test_scores.append(tmp_scores[1])\n",
    "    else:\n",
    "        test_sys_out.append(tmp_data_sys[i+1])\n",
    "        test_ref.append(tmp_data_ref[i+1])\n",
    "        test_scores.append(tmp_scores[i+1])\n",
    "    tmp_data_sys.remove(val_sys_out[0])\n",
    "    tmp_data_sys.remove(test_sys_out[0])\n",
    "    tmp_data_ref.remove(val_ref[0])\n",
    "    tmp_data_ref.remove(test_ref[0])\n",
    "    tmp_scores.remove(val_scores[0])\n",
    "    tmp_scores.remove(test_scores[0])\n",
    "    train_sys_out.extend(tmp_data_sys)\n",
    "    train_ref.extend(tmp_data_ref)\n",
    "    train_scores.extend(tmp_scores)\n",
    "    # read data\n",
    "    val_sys_out = read_data(val_sys_out, data_sys_out_list)\n",
    "    test_sys_out = read_data(test_sys_out, data_sys_out_list)\n",
    "    train_sys_out = read_data(train_sys_out, data_sys_out_list)\n",
    "    val_ref = read_data(val_ref, data_ref_list)\n",
    "    test_ref = read_data(test_ref, data_ref_list)\n",
    "    train_ref = read_data(train_ref, data_ref_list)\n",
    "    val_scores = read_data(val_scores, data_scores_list)\n",
    "    test_scores = read_data(test_scores, data_scores_list)\n",
    "    train_scores = read_data(train_scores, data_scores_list)\n",
    "    # change the type of the attribute if necessary\n",
    "    val_sys_out = torch.cat(val_sys_out)\n",
    "    test_sys_out = torch.cat(test_sys_out)\n",
    "    train_sys_out = torch.cat(train_sys_out)\n",
    "    val_ref = torch.cat(val_ref)\n",
    "    test_ref = torch.cat(test_ref)\n",
    "    train_ref = torch.cat(train_ref)\n",
    "    write_numpy(train_sys_out, out_train_sys_hidden+syses[i]+\"_\"+ syses[j])\n",
    "    write_numpy(train_ref, out_train_ref_hidden+syses[i]+\"_\"+ syses[j])\n",
    "    write_numpy(val_sys_out, out_val_sys_hidden+syses[i]+\"_\"+ syses[j])\n",
    "    write_numpy(val_ref, out_val_ref_hidden+syses[i]+\"_\"+ syses[j])\n",
    "    write_numpy(test_sys_out, out_test_sys_hidden+syses[i]+\"_\"+ syses[j])\n",
    "    write_numpy(test_ref, out_test_ref_hidden+syses[i]+\"_\"+ syses[j])\n",
    "    write_data(out_train_scores+syses[i]+\"_\"+ syses[j], train_scores)\n",
    "    write_data(out_val_scores+syses[i]+\"_\"+ syses[j], val_scores)\n",
    "    write_data(out_test_scores+syses[i]+\"_\"+ syses[j], test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py27",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
