{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_sys = file(\"./data/hidden_sys\")\n",
    "data_sys = np.load(file_sys)\n",
    "data_sys.shape\n",
    "file_sys.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_ref = open(\"./data/hidden_ref\")\n",
    "data_ref = np.load(file_ref)\n",
    "data_ref.shape\n",
    "file_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_scores = []\n",
    "with open(\"./data/data_scores\") as fi:\n",
    "    for line in fi:\n",
    "        data_scores.append(float(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.9131\n",
       " 0.1423\n",
       " 0.1597\n",
       "   ⋮   \n",
       " 1.0628\n",
       " 1.1250\n",
       " 0.8761\n",
       "[torch.FloatTensor of size 9392]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.1317e-01  1.9135e-01  4.8339e-02  ...   3.3562e-01  2.1015e-01 -3.0384e-01\n",
       " 6.9478e-01  6.4986e-01 -2.1220e-01  ...  -3.8425e-01 -6.4973e-01 -2.3927e-01\n",
       " 2.5970e-01  5.3346e-01  8.0853e-02  ...  -4.2903e-01 -3.2311e-01 -8.9193e-02\n",
       "                ...                   ⋱                   ...                \n",
       " 6.6741e-01  6.7923e-01  1.4909e-01  ...  -2.2978e-01 -3.1571e-01  1.3677e-01\n",
       " 2.5324e-02  1.3155e-01 -6.5003e-03  ...   4.0089e-01 -2.2887e-01 -3.4650e-01\n",
       " 4.1332e-01  5.0622e-01 -4.5596e-01  ...  -5.0268e-01 -3.7340e-01 -2.6541e-01\n",
       "[torch.FloatTensor of size 9392x1000]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(data_scores)\n",
    "b = torch.from_numpy(data_ref)\n",
    "c = torch.from_numpy(data_sys)\n",
    "d = torch.cat((c,b), 1)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(3248)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = range(len(data_scores))\n",
    "random.shuffle(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb = zip(d, a, tmp)\n",
    "comb = sorted(comb, key = lambda x: x[-1])\n",
    "d, a, tmp = zip(*comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.9131\n",
       " 0.1423\n",
       " 0.1597\n",
       "   ⋮   \n",
       " 1.0628\n",
       " 1.1250\n",
       " 0.8761\n",
       "[torch.FloatTensor of size 9392]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 3.1889e-01  6.3258e-01  1.1316e-01  ...  -4.0196e-01 -4.5356e-01 -4.0905e-01\n",
       " 4.2669e-01  5.7952e-01 -1.5267e-01  ...  -7.3717e-01 -5.4875e-01 -4.3146e-01\n",
       " 2.3961e-01  4.4815e-01 -3.0775e-01  ...  -7.1228e-01 -6.1418e-01 -2.2865e-01\n",
       "                ...                   ⋱                   ...                \n",
       " 3.0726e-01  4.2501e-01 -6.7688e-02  ...  -3.7334e-01 -6.1822e-01 -2.2931e-01\n",
       " 4.6479e-01  4.5037e-01  4.2272e-02  ...  -5.3935e-01 -3.9767e-01 -6.4714e-02\n",
       " 4.3281e-01  4.3685e-01 -4.6474e-02  ...  -6.4254e-01 -2.9456e-01 -4.9992e-01\n",
       "[torch.FloatTensor of size 9392x1000]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = d[0].view(1, -1)\n",
    "for i in range(1, len(d)):\n",
    "    tmp = torch.cat((tmp, d[i].view(1, -1)), 0)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 3.1889e-01  6.3258e-01  1.1316e-01  ...  -4.0196e-01 -4.5356e-01 -4.0905e-01\n",
       " 4.2669e-01  5.7952e-01 -1.5267e-01  ...  -7.3717e-01 -5.4875e-01 -4.3146e-01\n",
       " 2.3961e-01  4.4815e-01 -3.0775e-01  ...  -7.1228e-01 -6.1418e-01 -2.2865e-01\n",
       "                ...                   ⋱                   ...                \n",
       " 3.0726e-01  4.2501e-01 -6.7688e-02  ...  -3.7334e-01 -6.1822e-01 -2.2931e-01\n",
       " 4.6479e-01  4.5037e-01  4.2272e-02  ...  -5.3935e-01 -3.9767e-01 -6.4714e-02\n",
       " 4.3281e-01  4.3685e-01 -4.6474e-02  ...  -6.4254e-01 -2.9456e-01 -4.9992e-01\n",
       "[torch.FloatTensor of size 9392x1000]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'view'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-0706f0478fb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'view'"
     ]
    }
   ],
   "source": [
    "tmp = d[0][0].view(1, -1)\n",
    "for i in range(1, len(d)):\n",
    "    tmp = torch.cat((tmp, d[i][0].view(1, -1)), 0)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 8.8883e-23  1.4013e-45  7.8276e-23\n",
       "[torch.FloatTensor of size 1x3]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0][0].view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.Tensor(20, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = a[0:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.6434e-43  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.5593e-43  0.0000e+00  1.2916e+26 -1.2851e+17\n",
       " 6.2487e-29  1.4013e-45  8.8666e-23  1.4013e-45\n",
       "-3.1784e+15  1.4013e-45  0.0000e+00  1.4013e-45\n",
       "[torch.FloatTensor of size 10x4]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = a[10:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "-2.5641e+04  4.5863e-41  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "-2.5641e+04  4.5863e-41 -2.5641e+04  4.5863e-41\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.4472e-43  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00 -1.0898e+17  4.7161e-01\n",
       " 4.8357e-29  1.4013e-45  4.2008e-19  1.4013e-45\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "[torch.FloatTensor of size 10x4]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.6434e-43  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.5593e-43  0.0000e+00  1.2916e+26 -1.2851e+17\n",
       " 6.2487e-29  1.4013e-45  8.8666e-23  1.4013e-45\n",
       "-3.1784e+15  1.4013e-45  0.0000e+00  1.4013e-45\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "-2.5641e+04  4.5863e-41  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "-2.5641e+04  4.5863e-41 -2.5641e+04  4.5863e-41\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.4472e-43  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00 -1.0898e+17  4.7161e-01\n",
       " 4.8357e-29  1.4013e-45  4.2008e-19  1.4013e-45\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "[torch.FloatTensor of size 20x4]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 9\n",
    "b = 2\n",
    "c = round(a/b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = torch.Tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    a.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = torch.cat(a, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fmin\n",
    "import Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Params.Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'opt': 0, 'basic_drop_out_rate': 0.5683040090088415, 'basic_dim3': 3, 'basic_dim2': 1, 'basic_act_func': 2, 'basic_tgt': 0, 'basic_bn_momentum': 0.19338528925355508, 'basic_act_func_out': 2, 'basic_batch_size': 2, 'basic_lr': 0.011904082335539058"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic Linear\n",
    "pas = {'tgt': '../data/MasterArbeit/data/record_prepronce_cleaned', 'src_sys': '../data/MasterArbeit/data/hidden_value_pred', 'src_ref': '../data/MasterArbeit/data/hidden_value_ref', 'optim': 'Adam','loss_fn': 'MSELoss', 'batch_size': 100, 'dim2': 100, 'dim3': 10, 'lr': 0.00592636698766986, 'act_func': 'LeakyReLU', 'act_func_out': None, 'model': './model/LinearModel', 'type': 'linear', 'momentum': 0.19338528925355508, 'drop_out_rate': 0.5683040090088415}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bi Linear\n",
    "pas1 = {'dim2': 10, 'act_func_out': None, 'tgt': '../data/MasterArbeit/data/data_scores', 'src_sys': '../data/MasterArbeit/data/sys_hidden', 'src_ref': '../data/MasterArbeit/data/ref_hidden', 'batch_size': 100, 'lr': 0.01592636698766986, 'act_func': 'LeakyReLU', 'act_func_out': None , 'model': 'BiLinear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Masked\n",
    "pas2 = {'dim2': 10, 'tgt': '../data/MasterArbeit/data/data_scores', 'src_sys': '../data/MasterArbeit/data/sys_hidden', 'src_ref': '../data/MasterArbeit/data/ref_hidden', 'batch_size': 100, 'lr': 0.005592636698766986, 'act_func': 'Tanh', 'model': 'MaskedModel1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BasicLinear_dropout\n",
    "pas3 = {'tgt': '../data/MasterArbeit/data/data_scores', 'src_sys': '../data/MasterArbeit/data/sys_hidden', 'src_ref': '../data/MasterArbeit/data/ref_hidden', 'batch_size': 100, 'dim2': 100, 'dim3': 10, 'lr': 0.01592636698766986, 'act_func': 'LeakyReLU', 'act_func_out': None, 'model': 'BasicLinearDropout', 'type': 'linear', 'momentum': 0.19338528925355508, 'drop_out_rate': 0.5683040090088415}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MultiHeadLSTMModel\n",
    "pas = {'model': 'MultiHeadAttnLSTMModel',\n",
    "       'tgt': '../data/MasterArbeit/data2/record_NIST_dev2015_clean', \n",
    "       'src_sys': '../data/MasterArbeit/data2/hidden_pred_preprodev2015',\n",
    "       'src_ref': '../data/MasterArbeit/data2/hidden_ref_preprodev2015',\n",
    "       'val_tgt': '../data/MasterArbeit/data2/record_NIST_tst2016_clean',\n",
    "       'src_val_sys': '../data/MasterArbeit/data2/hidden_pred_preprotst2016',\n",
    "       'src_val_ref': '../data/MasterArbeit/data2/hidden_ref_preprotst2016',\n",
    "       'test_tgt': '../data/MasterArbeit/data2/record_NIST_tst2016_clean',\n",
    "       'src_test_sys': '../data/MasterArbeit/data2/hidden_pred_preprotst2016',\n",
    "       'src_test_ref': '../data/MasterArbeit/data2/hidden_ref_preprotst2016',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Test\n",
    "pas = {\n",
    "      'tgt': '../data/MasterArbeit/test/train_scores',\n",
    "      'src_sys': '../data/MasterArbeit/test/train_sys_hidden',\n",
    "      'src_ref': '../data/MasterArbeit/test/train_ref_hidden',\n",
    "      'tgt_val': '../data/MasterArbeit/test/val_scores',\n",
    "      'src_val_sys': '../data/MasterArbeit/test/val_sys_hidden',\n",
    "      'src_val_ref': '../data/MasterArbeit/test/val_ref_hidden',\n",
    "      'tgt_test': '../data/MasterArbeit/test/test_scores',\n",
    "      'src_test_sys': '../data/MasterArbeit/test/test_sys_hidden',\n",
    "      'src_test_ref': '../data/MasterArbeit/test/test_ref_hidden',\n",
    "      'optim': 'Adam',\n",
    "      'loss_fn': 'MSELoss', \n",
    "      'batch_size': 100, \n",
    "      'dim2': 100, \n",
    "      'dim3': 10, \n",
    "      'lr': 0.00592636698766986, \n",
    "      'act_func': 'LeakyReLU', \n",
    "      'act_func_out': None, \n",
    "      'model': 'MaskedModel1',\n",
    "      'type': 'linear', \n",
    "      'momentum': 0.19338528925355508, \n",
    "      'drop_out_rate': 0.5683040090088415,\n",
    "     # 'isRandom': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# R\n",
    "pas = {\n",
    "      'tgt': '../data/MasterArbeit/test2/train_scores',\n",
    "      'src_sys': '../data/MasterArbeit/test2/train_sys_hidden',\n",
    "      'src_ref': '../data/MasterArbeit/test2/train_ref_hidden',\n",
    "      'tgt_val': '../data/MasterArbeit/test2/val_scores',\n",
    "      'src_val_sys': '../data/MasterArbeit/test2/val_sys_hidden',\n",
    "      'src_val_ref': '../data/MasterArbeit/test2/val_ref_hidden',\n",
    "      'tgt_test': '../data/MasterArbeit/test2/test_scores',\n",
    "      'src_test_sys': '../data/MasterArbeit/test2/test_sys_hidden',\n",
    "      'src_test_ref': '../data/MasterArbeit/test2/test_ref_hidden',\n",
    "      'model': 'MultiHeadAttnConvModel',\n",
    "     # 'isRandom': True\n",
    "      'num_dim_k': 16,\n",
    "      'num_dim_v': 16,\n",
    "      'num_head': 4,\n",
    "      'kernel_size1': 2,\n",
    "      'stride1': 1,\n",
    "      'kernel_size2': 3,\n",
    "      'stride2': 1,\n",
    "      'batch_size': 20,\n",
    "      'debug': True,\n",
    "      'loss_fn': 'CorrLoss'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_head = opt.num_head, num_dim_k = opt.num_dim_k, num_dim_v = opt.num_dim_v, d_rate_attn = opt.d_rate_attn, act_func1 = opt.act_func1, dim2 = opt.dim2, act_func2 = opt.act_func2)<br>\n",
    "pas1 = {'dim2': 10, 'act_func_out': None, 'tgt': '../data/MasterArbeit/data/normalized_data_scores', 'src_sys': '../data/MasterArbeit/data/sys_hidden', 'src_ref': '../data/MasterArbeit/data/ref_hidden', 'batch_size': 100, 'lr': 0.01592636698766986, 'act_func': 'Tanh', 'model': 'BasicLinearDropout'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt.set_params(pas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MultiHeadAttnConvModel'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('act_func1', 'LeakyReLU')\n",
      "('act_func_out', None)\n",
      "('tgt', '../data/MasterArbeit/test/train_scores')\n",
      "('loss_fn', 'MSELoss')\n",
      "('isRandom', False)\n",
      "('src_test_sys', '../data/MasterArbeit/test/test_sys_hidden')\n",
      "('dim2', 100)\n",
      "('dim3', 10)\n",
      "('dim1', 20)\n",
      "('weight_decay', 0)\n",
      "('out', './pred')\n",
      "('kernel_size2', 3)\n",
      "('kernel_size1', 3)\n",
      "('src_test_ref', '../data/MasterArbeit/test/test_ref_hidden')\n",
      "('tgt_test', '../data/MasterArbeit/test/test_scores')\n",
      "('checkpoint', './checkpoints/cp1')\n",
      "('num_dim_k', 64)\n",
      "('tgt_val', '../data/MasterArbeit/test/val_scores')\n",
      "('lr', 0.00592636698766986)\n",
      "('act_func', 'LeakyReLU')\n",
      "('drop_out_rate', 0.5683040090088415)\n",
      "('type', 'linear')\n",
      "('momentum', 0.19338528925355508)\n",
      "('src_val_ref', '../data/MasterArbeit/test/val_ref_hidden')\n",
      "('resume', False)\n",
      "('optim', 'Adam')\n",
      "('batch_size', 100)\n",
      "('src_val_sys', '../data/MasterArbeit/test/val_sys_hidden')\n",
      "('num_head', 8)\n",
      "('num_dim_v', 64)\n",
      "('stride2', 2)\n",
      "('src_sys', '../data/MasterArbeit/test/train_sys_hidden')\n",
      "('act_func2', 'LeakyReLU')\n",
      "('src_ref', '../data/MasterArbeit/test/train_ref_hidden')\n",
      "('eps', 1e-08)\n",
      "('d_rate_attn', 0.1)\n",
      "('stride1', 2)\n",
      "('cuda', False)\n",
      "('debug', False)\n",
      "('model', 'MaskedModel1')\n",
      "MaskedModel1 (\n",
      "  (li_mask): Linear (500 -> 500)\n",
      "  (sf): Softmax ()\n",
      "  (li_1): Linear (500 -> 100)\n",
      "  (act_func): LeakyReLU (0.01)\n",
      "  (li_out): Linear (100 -> 1)\n",
      ")\n",
      "initializing the model...\n",
      "=> initializing Linear model\n",
      "Linear (500 -> 500)\n",
      "=> spring the self defined model\n",
      "Softmax ()\n",
      "=> initializing Linear model\n",
      "Linear (500 -> 100)\n",
      "=> spring the self defined model\n",
      "LeakyReLU (0.01)\n",
      "=> initializing Linear model\n",
      "Linear (100 -> 1)\n",
      "=> spring the self defined model\n",
      "MaskedModel1 (\n",
      "  (li_mask): Linear (500 -> 500)\n",
      "  (sf): Softmax ()\n",
      "  (li_1): Linear (500 -> 100)\n",
      "  (act_func): LeakyReLU (0.01)\n",
      "  (li_out): Linear (100 -> 1)\n",
      ")\n",
      "number of batch is 75 \n",
      "number of val batch 9 \n",
      "number of test batch 9\n",
      "evaluate 0\n",
      "the correlation coeffizient is : -0.060961\n",
      "the mean loss is 1.885485\n",
      "save checkpoint 0\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 1\n",
      "the correlation coeffizient is : -0.147742\n",
      "the mean loss is 0.961498\n",
      "save checkpoint 1\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 2\n",
      "the correlation coeffizient is : -0.044087\n",
      "the mean loss is 1.086704\n",
      "save checkpoint 2\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 3\n",
      "the correlation coeffizient is : 0.144456\n",
      "the mean loss is 0.913215\n",
      "save checkpoint 3\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 4\n",
      "the correlation coeffizient is : 0.075579\n",
      "the mean loss is 0.919426\n",
      "save checkpoint 4\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 5\n",
      "the correlation coeffizient is : 0.052773\n",
      "the mean loss is 1.195140\n",
      "save checkpoint 5\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 6\n",
      "the correlation coeffizient is : 0.164713\n",
      "the mean loss is 1.051164\n",
      "save checkpoint 6\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 7\n",
      "the correlation coeffizient is : -0.035088\n",
      "the mean loss is 0.790743\n",
      "save checkpoint 7\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 8\n",
      "the correlation coeffizient is : 0.049652\n",
      "the mean loss is 0.951549\n",
      "save checkpoint 8\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 9\n",
      "the correlation coeffizient is : 0.152493\n",
      "the mean loss is 1.062195\n",
      "save checkpoint 9\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 10\n",
      "the correlation coeffizient is : 0.320730\n",
      "the mean loss is 0.842692\n",
      "save checkpoint 10\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 11\n",
      "the correlation coeffizient is : 0.206644\n",
      "the mean loss is 0.937387\n",
      "save checkpoint 11\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 12\n",
      "the correlation coeffizient is : 0.223042\n",
      "the mean loss is 0.885416\n",
      "save checkpoint 12\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 13\n",
      "the correlation coeffizient is : 0.143682\n",
      "the mean loss is 0.910168\n",
      "save checkpoint 13\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 14\n",
      "the correlation coeffizient is : 0.182934\n",
      "the mean loss is 1.140503\n",
      "save checkpoint 14\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 15\n",
      "the correlation coeffizient is : 0.246644\n",
      "the mean loss is 1.018461\n",
      "save checkpoint 15\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 16\n",
      "the correlation coeffizient is : 0.188695\n",
      "the mean loss is 0.755991\n",
      "save checkpoint 16\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 17\n",
      "the correlation coeffizient is : 0.237032\n",
      "the mean loss is 0.927991\n",
      "save checkpoint 17\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 18\n",
      "the correlation coeffizient is : 0.374682\n",
      "the mean loss is 0.933131\n",
      "save checkpoint 18\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 19\n",
      "the correlation coeffizient is : 0.258086\n",
      "the mean loss is 0.855352\n",
      "save checkpoint 19\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 20\n",
      "the correlation coeffizient is : 0.265423\n",
      "the mean loss is 0.902190\n",
      "save checkpoint 20\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 21\n",
      "the correlation coeffizient is : 0.357861\n",
      "the mean loss is 0.826963\n",
      "save checkpoint 21\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 22\n",
      "the correlation coeffizient is : 0.205813\n",
      "the mean loss is 0.885759\n",
      "save checkpoint 22\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 23\n",
      "the correlation coeffizient is : 0.258643\n",
      "the mean loss is 1.114816\n",
      "save checkpoint 23\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 24\n",
      "the correlation coeffizient is : 0.279023\n",
      "the mean loss is 1.040152\n",
      "save checkpoint 24\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 25\n",
      "the correlation coeffizient is : 0.256371\n",
      "the mean loss is 0.869434\n",
      "save checkpoint 25\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 26\n",
      "the correlation coeffizient is : 0.266979\n",
      "the mean loss is 0.958170\n",
      "save checkpoint 26\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 27\n",
      "the correlation coeffizient is : 0.309299\n",
      "the mean loss is 0.922335\n",
      "save checkpoint 27\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 28\n",
      "the correlation coeffizient is : 0.340984\n",
      "the mean loss is 0.803278\n",
      "save checkpoint 28\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 29\n",
      "the correlation coeffizient is : 0.317657\n",
      "the mean loss is 0.906198\n",
      "save checkpoint 29\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 30\n",
      "the correlation coeffizient is : 0.295495\n",
      "the mean loss is 0.870220\n",
      "save checkpoint 30\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 31\n",
      "the correlation coeffizient is : 0.147276\n",
      "the mean loss is 0.928745\n",
      "save checkpoint 31\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 32\n",
      "the correlation coeffizient is : 0.328105\n",
      "the mean loss is 1.125605\n",
      "save checkpoint 32\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 33\n",
      "the correlation coeffizient is : 0.341445\n",
      "the mean loss is 0.950775\n",
      "save checkpoint 33\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 34\n",
      "the correlation coeffizient is : 0.268183\n",
      "the mean loss is 0.768873\n",
      "save checkpoint 34\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 35\n",
      "the correlation coeffizient is : 0.253921\n",
      "the mean loss is 0.918372\n",
      "save checkpoint 35\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 36\n",
      "the correlation coeffizient is : 0.327724\n",
      "the mean loss is 0.944068\n",
      "save checkpoint 36\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 37\n",
      "the correlation coeffizient is : 0.369084\n",
      "the mean loss is 0.781919\n",
      "save checkpoint 37\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 38\n",
      "the correlation coeffizient is : 0.335225\n",
      "the mean loss is 0.862730\n",
      "save checkpoint 38\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 39\n",
      "the correlation coeffizient is : 0.295832\n",
      "the mean loss is 0.871404\n",
      "save checkpoint 39\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 40\n",
      "the correlation coeffizient is : 0.256132\n",
      "the mean loss is 0.865770\n",
      "save checkpoint 40\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 41\n",
      "the correlation coeffizient is : 0.358435\n",
      "the mean loss is 1.058448\n",
      "save checkpoint 41\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 42\n",
      "the correlation coeffizient is : 0.381462\n",
      "the mean loss is 0.910324\n",
      "save checkpoint 42\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 43\n",
      "the correlation coeffizient is : 0.286793\n",
      "the mean loss is 0.832328\n",
      "save checkpoint 43\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 44\n",
      "the correlation coeffizient is : 0.290044\n",
      "the mean loss is 0.888857\n",
      "save checkpoint 44\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 45\n",
      "the correlation coeffizient is : 0.330803\n",
      "the mean loss is 0.904708\n",
      "save checkpoint 45\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 46\n",
      "the correlation coeffizient is : 0.354785\n",
      "the mean loss is 0.873137\n",
      "save checkpoint 46\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 47\n",
      "the correlation coeffizient is : 0.377109\n",
      "the mean loss is 0.833322\n",
      "save checkpoint 47\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 48\n",
      "the correlation coeffizient is : 0.281492\n",
      "the mean loss is 0.866716\n",
      "save checkpoint 48\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 49\n",
      "the correlation coeffizient is : 0.281657\n",
      "the mean loss is 0.872168\n",
      "save checkpoint 49\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 50\n",
      "the correlation coeffizient is : 0.326219\n",
      "the mean loss is 1.062045\n",
      "save checkpoint 50\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 51\n",
      "the correlation coeffizient is : 0.389412\n",
      "the mean loss is 0.906125\n",
      "save checkpoint 51\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 52\n",
      "the correlation coeffizient is : 0.267651\n",
      "the mean loss is 0.771816\n",
      "save checkpoint 52\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 53\n",
      "the correlation coeffizient is : 0.323408\n",
      "the mean loss is 0.869190\n",
      "save checkpoint 53\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 54\n",
      "the correlation coeffizient is : 0.332878\n",
      "the mean loss is 1.003936\n",
      "save checkpoint 54\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 55\n",
      "the correlation coeffizient is : 0.312056\n",
      "the mean loss is 0.847896\n",
      "save checkpoint 55\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 56\n",
      "the correlation coeffizient is : 0.306590\n",
      "the mean loss is 0.898780\n",
      "save checkpoint 56\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 57\n",
      "the correlation coeffizient is : 0.270438\n",
      "the mean loss is 0.880915\n",
      "save checkpoint 57\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 58\n",
      "the correlation coeffizient is : 0.318711\n",
      "the mean loss is 0.868132\n",
      "save checkpoint 58\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 59\n",
      "the correlation coeffizient is : 0.345691\n",
      "the mean loss is 1.050738\n",
      "save checkpoint 59\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 60\n",
      "the correlation coeffizient is : 0.348286\n",
      "the mean loss is 0.954494\n",
      "save checkpoint 60\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 61\n",
      "the correlation coeffizient is : 0.316711\n",
      "the mean loss is 0.746862\n",
      "save checkpoint 61\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 62\n",
      "the correlation coeffizient is : 0.318219\n",
      "the mean loss is 0.897217\n",
      "save checkpoint 62\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 63\n",
      "the correlation coeffizient is : 0.326934\n",
      "the mean loss is 0.932387\n",
      "save checkpoint 63\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 64\n",
      "the correlation coeffizient is : 0.349586\n",
      "the mean loss is 0.838752\n",
      "save checkpoint 64\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 65\n",
      "the correlation coeffizient is : 0.373255\n",
      "the mean loss is 0.836572\n",
      "save checkpoint 65\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 66\n",
      "the correlation coeffizient is : 0.330235\n",
      "the mean loss is 0.846678\n",
      "save checkpoint 66\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 67\n",
      "the correlation coeffizient is : 0.309620\n",
      "the mean loss is 0.861395\n",
      "save checkpoint 67\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 68\n",
      "the correlation coeffizient is : 0.348699\n",
      "the mean loss is 1.066822\n",
      "save checkpoint 68\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 69\n",
      "the correlation coeffizient is : 0.348122\n",
      "the mean loss is 0.955876\n",
      "save checkpoint 69\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 70\n",
      "the correlation coeffizient is : 0.327356\n",
      "the mean loss is 0.735919\n",
      "save checkpoint 70\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 71\n",
      "the correlation coeffizient is : 0.298535\n",
      "the mean loss is 1.002744\n",
      "save checkpoint 71\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 72\n",
      "the correlation coeffizient is : 0.356820\n",
      "the mean loss is 0.911406\n",
      "save checkpoint 72\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 73\n",
      "the correlation coeffizient is : 0.338002\n",
      "the mean loss is 0.817701\n",
      "save checkpoint 73\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 74\n",
      "the correlation coeffizient is : 0.397355\n",
      "the mean loss is 0.822274\n",
      "save checkpoint 74\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 75\n",
      "the correlation coeffizient is : 0.299775\n",
      "the mean loss is 0.955928\n",
      "save checkpoint 75\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 76\n",
      "the correlation coeffizient is : 0.296786\n",
      "the mean loss is 0.921779\n",
      "save checkpoint 76\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 77\n",
      "the correlation coeffizient is : 0.300196\n",
      "the mean loss is 1.133886\n",
      "save checkpoint 77\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 78\n",
      "the correlation coeffizient is : 0.396199\n",
      "the mean loss is 0.917613\n",
      "save checkpoint 78\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 79\n",
      "the correlation coeffizient is : 0.363061\n",
      "the mean loss is 0.783464\n",
      "save checkpoint 79\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 80\n",
      "the correlation coeffizient is : 0.296656\n",
      "the mean loss is 0.906330\n",
      "save checkpoint 80\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 81\n",
      "the correlation coeffizient is : 0.356381\n",
      "the mean loss is 0.930891\n",
      "save checkpoint 81\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 82\n",
      "the correlation coeffizient is : 0.307614\n",
      "the mean loss is 0.852624\n",
      "save checkpoint 82\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 83\n",
      "the correlation coeffizient is : 0.376117\n",
      "the mean loss is 0.879485\n",
      "save checkpoint 83\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 84\n",
      "the correlation coeffizient is : 0.307568\n",
      "the mean loss is 0.920119\n",
      "save checkpoint 84\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 85\n",
      "the correlation coeffizient is : 0.316492\n",
      "the mean loss is 0.875466\n",
      "save checkpoint 85\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 86\n",
      "the correlation coeffizient is : 0.332320\n",
      "the mean loss is 1.091633\n",
      "save checkpoint 86\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 87\n",
      "the correlation coeffizient is : 0.418337\n",
      "the mean loss is 0.889542\n",
      "save checkpoint 87\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 88\n",
      "the correlation coeffizient is : 0.349184\n",
      "the mean loss is 0.716734\n",
      "save checkpoint 88\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 89\n",
      "the correlation coeffizient is : 0.345493\n",
      "the mean loss is 0.940041\n",
      "save checkpoint 89\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 90\n",
      "the correlation coeffizient is : 0.368440\n",
      "the mean loss is 0.887574\n",
      "save checkpoint 90\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 91\n",
      "the correlation coeffizient is : 0.315691\n",
      "the mean loss is 0.874232\n",
      "save checkpoint 91\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 92\n",
      "the correlation coeffizient is : 0.404336\n",
      "the mean loss is 0.840910\n",
      "save checkpoint 92\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 93\n",
      "the correlation coeffizient is : 0.259840\n",
      "the mean loss is 1.005544\n",
      "save checkpoint 93\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 94\n",
      "the correlation coeffizient is : 0.366360\n",
      "the mean loss is 0.819676\n",
      "save checkpoint 94\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 95\n",
      "the correlation coeffizient is : 0.331403\n",
      "the mean loss is 1.104679\n",
      "save checkpoint 95\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 96\n",
      "the correlation coeffizient is : 0.377137\n",
      "the mean loss is 0.942962\n",
      "save checkpoint 96\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 97\n",
      "the correlation coeffizient is : 0.320535\n",
      "the mean loss is 0.751826\n",
      "save checkpoint 97\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 98\n",
      "the correlation coeffizient is : 0.358414\n",
      "the mean loss is 0.846670\n",
      "save checkpoint 98\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 99\n",
      "the correlation coeffizient is : 0.403241\n",
      "the mean loss is 0.858881\n",
      "save checkpoint 99\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 100\n",
      "the correlation coeffizient is : 0.318453\n",
      "the mean loss is 0.921978\n",
      "save checkpoint 100\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 101\n",
      "the correlation coeffizient is : 0.382198\n",
      "the mean loss is 0.937480\n",
      "save checkpoint 101\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 102\n",
      "the correlation coeffizient is : 0.269745\n",
      "the mean loss is 1.000595\n",
      "save checkpoint 102\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 103\n",
      "the correlation coeffizient is : 0.375438\n",
      "the mean loss is 0.805656\n",
      "save checkpoint 103\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 104\n",
      "the correlation coeffizient is : 0.314614\n",
      "the mean loss is 1.099339\n",
      "save checkpoint 104\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 105\n",
      "the correlation coeffizient is : 0.415385\n",
      "the mean loss is 0.945121\n",
      "save checkpoint 105\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 106\n",
      "the correlation coeffizient is : 0.224176\n",
      "the mean loss is 0.891875\n",
      "save checkpoint 106\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 107\n",
      "the correlation coeffizient is : 0.365528\n",
      "the mean loss is 0.831171\n",
      "save checkpoint 107\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 108\n",
      "the correlation coeffizient is : 0.399067\n",
      "the mean loss is 0.981214\n",
      "save checkpoint 108\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 109\n",
      "the correlation coeffizient is : 0.366613\n",
      "the mean loss is 0.856307\n",
      "save checkpoint 109\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 110\n",
      "the correlation coeffizient is : 0.329961\n",
      "the mean loss is 1.045472\n",
      "save checkpoint 110\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 111\n",
      "the correlation coeffizient is : 0.287280\n",
      "the mean loss is 0.953469\n",
      "save checkpoint 111\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 112\n",
      "the correlation coeffizient is : 0.378617\n",
      "the mean loss is 0.800425\n",
      "save checkpoint 112\n",
      "please remove the comment sign before saving a checkpoint\n",
      "the correlation coeffizient is : 0.418954\n",
      "the correlation coeffizient is : 0.304014\n",
      "the correlation coeffizient is : 0.365551\n",
      "the correlation coeffizient is : 0.401556\n",
      "the correlation coeffizient is : 0.472508\n",
      "the correlation coeffizient is : 0.407318\n",
      "the correlation coeffizient is : 0.396841\n",
      "the correlation coeffizient is : 0.222219\n",
      "the correlation coeffizient is : 0.323805\n",
      "the correlation coeffizient is : 0.418954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.62682802498273482"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmin.o_func(pas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import fmin\n",
    "import Params\n",
    "opt = Params.Params()\n",
    "# MultiHeadLSTMModel\n",
    "pas = {'model': 'MultiHeadAttnConvModel',\n",
    "       'tgt': '../data/MasterArbeit/data2/record_NIST_dev2015_clean', \n",
    "       'src_sys': '../data/MasterArbeit/data2/hidden_pred_preprodev2015',\n",
    "       'src_ref': '../data/MasterArbeit/data2/hidden_ref_preprodev2015',\n",
    "       'val_tgt': '../data/MasterArbeit/data2/record_NIST_tst2016_clean',\n",
    "       'src_val_sys': '../data/MasterArbeit/data2/hidden_pred_preprotst2016',\n",
    "       'src_val_ref': '../data/MasterArbeit/data2/hidden_ref_preprotst2016',\n",
    "       'test_tgt': '../data/MasterArbeit/data2/record_NIST_tst2016_clean',\n",
    "       'src_test_sys': '../data/MasterArbeit/data2/hidden_pred_preprotst2016',\n",
    "       'src_test_ref': '../data/MasterArbeit/data2/hidden_ref_preprotst2016',\n",
    "       'resume': False,\n",
    "       'checkpoint': './checkpoints/cp0',\n",
    "       'num_dim_k': 0,\n",
    "       'num_dim_v': 3,\n",
    "       'num_head': 1,\n",
    "       'kernel_size1': 0,\n",
    "       'stride1': 1,\n",
    "       'kernel_size2': 3,\n",
    "       'stride2': 1\n",
    "    }\n",
    "opt.set_params(pas)\n",
    "fmin.o_func(pas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-07546b744fd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfmin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ihuangyiran/Documents/Workplace_Python/MasterArbeit/fmin.py\u001b[0m in \u001b[0;36mget_best\u001b[0;34m()\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfullHiddenModel_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim_algo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             max_evals = 500)\n\u001b[0m\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ihuangyiran/anaconda2/envs/py27/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     domain = base.Domain(fn, space,\n\u001b[0;32m--> 314\u001b[0;31m                          pass_expr_memo_ctrl=pass_expr_memo_ctrl)\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     rval = FMinIter(algo, domain, trials, max_evals=max_evals,\n",
      "\u001b[0;32m/Users/ihuangyiran/anaconda2/envs/py27/lib/python2.7/site-packages/hyperopt/base.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fn, expr, workdir, pass_expr_memo_ctrl, name, loss_target)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0mbefore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;31m# -- raises exception if expr contains cycles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m         \u001b[0mpyll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoposort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m         \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectorizeHelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms_new_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0;31m# -- raises exception if v_expr contains cycles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ihuangyiran/anaconda2/envs/py27/lib/python2.7/site-packages/hyperopt/pyll/base.pyc\u001b[0m in \u001b[0;36mtoposort\u001b[0;34m(expr)\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn_in\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopological_sort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "import fmin\n",
    "import Params\n",
    "\n",
    "fmin.get_best()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fmin\n",
    "import Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Params.Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pas = {'tgt': '../data/MasterArbeit/data/data_scores', 'src_sys': '../data/MasterArbeit/data/sys_hidden', 'src_ref': '../data/MasterArbeit/data/ref_hidden', 'batch_size': 100, 'dim2': 100, 'dim3': 10, 'lr': 0.01592636698766986, 'act_func': 'LeakyReLU', 'act_func_out': None, 'model': './model/LinearModel', 'type': 'linear', 'momentum': 0.19338528925355508, 'drop_out_rate': 0.5683040090088415}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt.set_params(pas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./utils/\")\n",
    "from data import DataUtil\n",
    "data = DataUtil(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.1317e-01  1.9135e-01  4.8339e-02  ...   3.3562e-01  2.1015e-01 -3.0384e-01\n",
       "-7.8419e-02 -6.2597e-02 -3.2062e-01  ...  -2.0042e-01 -4.3326e-02 -1.9184e-01\n",
       "-1.4486e-01 -3.4520e-01 -2.9599e-01  ...  -5.4923e-01 -2.9880e-01 -9.2808e-02\n",
       "                ...                   ⋱                   ...                \n",
       " 5.6298e-02  6.2424e-02  1.5753e-01  ...   2.7108e-01  5.2202e-02  4.0222e-01\n",
       " 2.5324e-02  1.3155e-01 -6.5003e-03  ...   4.0089e-01 -2.2887e-01 -3.4650e-01\n",
       " 9.4739e-02 -3.0009e-01 -3.0777e-01  ...   2.3748e-02  3.1988e-02 -8.6498e-02\n",
       "[torch.FloatTensor of size 9392x1000]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.normalize_minmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.0263e-01  1.8456e-01  3.4689e-02  ...   3.3574e-01  2.0426e-01 -3.3436e-01\n",
       "-9.8142e-02 -8.1562e-02 -3.5195e-01  ...  -2.2599e-01 -6.1368e-02 -2.1700e-01\n",
       "-1.6777e-01 -3.7771e-01 -3.2614e-01  ...  -5.9152e-01 -3.2909e-01 -1.1322e-01\n",
       "                ...                   ⋱                   ...                \n",
       " 4.3030e-02  4.9449e-02  1.4911e-01  ...   2.6810e-01  3.8737e-02  4.0552e-01\n",
       " 1.0572e-02  1.2189e-01 -2.2778e-02  ...   4.0414e-01 -2.5581e-01 -3.7906e-01\n",
       " 8.3313e-02 -3.3044e-01 -3.3848e-01  ...   8.9200e-03  1.7555e-02 -1.0661e-01\n",
       "[torch.FloatTensor of size 9392x1000]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = getattr(torch.nn, 'ReLU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.nn.ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.activation.ReLU"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "DuplicateLabel",
     "evalue": "linear_act_func",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDuplicateLabel\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f0aeffc33b9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfmin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ihuangyiran/Documents/Workplace_Python/MasterArbeit/fmin.pyc\u001b[0m in \u001b[0;36mget_best\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mli_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim_algo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             max_evals = 500)\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ihuangyiran/anaconda2/envs/py27/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     domain = base.Domain(fn, space,\n\u001b[0;32m--> 314\u001b[0;31m                          pass_expr_memo_ctrl=pass_expr_memo_ctrl)\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     rval = FMinIter(algo, domain, trials, max_evals=max_evals,\n",
      "\u001b[0;32m/Users/ihuangyiran/anaconda2/envs/py27/lib/python2.7/site-packages/hyperopt/base.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fn, expr, workdir, pass_expr_memo_ctrl, name, loss_target)\u001b[0m\n\u001b[1;32m    774\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mDuplicateLabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'obj'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDuplicateLabel\u001b[0m: linear_act_func"
     ]
    }
   ],
   "source": [
    "fmin.get_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32/10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "x = float('nan')\n",
    "math.isnan(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## normalize scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.70434875861064,\n",
       " 1.12727142153235,\n",
       " -0.872401325076093,\n",
       " -0.520636691467046,\n",
       " 0.0293189192586597,\n",
       " -1.67083618888355,\n",
       " -1.54107458193584,\n",
       " -1.26716970413938,\n",
       " 1.14801144278375,\n",
       " -0.126473141789861,\n",
       " 1.08998382718802,\n",
       " -1.45083864991872,\n",
       " -1.30334660957726,\n",
       " 0.909684951356344,\n",
       " -0.865310032116374,\n",
       " -1.04805674497439,\n",
       " 1.03362830429051,\n",
       " -1.30334660957726,\n",
       " 0.473968273650239,\n",
       " 0.0655234422069162,\n",
       " -2.31501818674212,\n",
       " -1.30040055102541,\n",
       " -1.26443616430169,\n",
       " 1.24609931070437,\n",
       " 0.0048710057016938,\n",
       " 0.339556020247105,\n",
       " -0.553215740838215,\n",
       " -0.284941429727458,\n",
       " -0.740862210579549,\n",
       " -1.44105725859061,\n",
       " -0.264247987380428,\n",
       " 0.0386786043300455,\n",
       " 0.71831182779596,\n",
       " -1.26443616430169,\n",
       " 1.10910099750817,\n",
       " 0.0686014628819244,\n",
       " 1.11418127557441,\n",
       " 0.253071201445601,\n",
       " 0.419182111938213,\n",
       " -1.80918239815969,\n",
       " -0.229408504480094,\n",
       " -0.123356240182688,\n",
       " -0.0496745081911503,\n",
       " 1.22217430718766,\n",
       " -1.1248553785731,\n",
       " -0.985337863893415,\n",
       " -1.15989655423098,\n",
       " -0.0139082445291922,\n",
       " -1.54107458193584,\n",
       " -0.434365786127364,\n",
       " 0.564354763650173,\n",
       " -0.625664260181483,\n",
       " 0.00479229747097395,\n",
       " -1.00060178914239,\n",
       " -0.541165306892952,\n",
       " 1.37707956533788,\n",
       " 1.19092537160453,\n",
       " 1.12500429027107,\n",
       " -0.0269699547415003,\n",
       " 0.439961524610728,\n",
       " 1.16851268433334,\n",
       " 1.15399058740957,\n",
       " 0.0196085297921715,\n",
       " -2.00803966495828,\n",
       " -0.779261527378905,\n",
       " -1.80242807284352,\n",
       " -0.637772075862252,\n",
       " 1.24475737737332,\n",
       " -1.34225705485283,\n",
       " 0.37271797660176,\n",
       " 0.330892091996744,\n",
       " 0.955074894851372,\n",
       " 1.13791095964253,\n",
       " -2.09778641339656,\n",
       " -0.823820570438701,\n",
       " 1.16851268433334,\n",
       " -0.500696803050913,\n",
       " 0.384805693494673,\n",
       " -0.932247035025456,\n",
       " 1.24475737737332,\n",
       " -1.26868535215846,\n",
       " 0.0788671043790961,\n",
       " -0.27777460080266,\n",
       " -0.397358539254111,\n",
       " -0.602958594616973,\n",
       " 1.12727142153235,\n",
       " -2.03295160375887,\n",
       " 0.347025990290812,\n",
       " -1.57571972650626,\n",
       " -1.30219792188555,\n",
       " 0.993248980926827,\n",
       " -1.90283357720715,\n",
       " 1.21000101759139,\n",
       " -0.379648013438239,\n",
       " -0.992027214946222,\n",
       " -1.02774905479782,\n",
       " -0.486227258790259,\n",
       " 0.719043156989968,\n",
       " -1.80918239815969,\n",
       " -2.00373462453755,\n",
       " -0.0582123607589716,\n",
       " 0.972182822522608,\n",
       " 0.382861811868042,\n",
       " 1.16851268433334,\n",
       " -0.447165611587295,\n",
       " 0.674241034792515,\n",
       " -0.866534515433376,\n",
       " -0.0287202722561164,\n",
       " -1.27105218589777,\n",
       " -0.123356240182688,\n",
       " -0.856060160977616,\n",
       " -0.430871108981201,\n",
       " 0.443748066717318,\n",
       " 0.23927090856685,\n",
       " 0.778513503941099,\n",
       " 1.31592111393706,\n",
       " -0.75860037571926,\n",
       " -2.06453839447977,\n",
       " 1.33820803399917,\n",
       " -0.482802158719479,\n",
       " 0.20779127437812,\n",
       " -0.173912076323135,\n",
       " 0.343579268244777,\n",
       " 0.994257260766243,\n",
       " 0.00479229747097395,\n",
       " -0.444034451401381,\n",
       " -0.548865626582772,\n",
       " -1.00060178914239,\n",
       " 0.0271241254075607,\n",
       " -0.281845171077426,\n",
       " -0.695735501030716,\n",
       " 0.690942402274422,\n",
       " -0.252764587136829,\n",
       " -1.80918239815969,\n",
       " 0.751045204576369,\n",
       " -0.63848432233684,\n",
       " 0.262822929695734,\n",
       " -1.20165401217182,\n",
       " -1.08645606177375,\n",
       " -0.291675032412401,\n",
       " -1.94336634123875,\n",
       " 1.10910099750817,\n",
       " 0.943144249829505,\n",
       " -1.70434875861064,\n",
       " -1.67083618888355,\n",
       " 0.756711144595315,\n",
       " -0.847686178890694,\n",
       " -0.0590320517207384,\n",
       " 1.06188186411476,\n",
       " 0.449516610200471,\n",
       " -2.08483829855699,\n",
       " 0.461460279450232,\n",
       " -0.537212341742857,\n",
       " 0.607304031883433,\n",
       " 0.0112417995560491,\n",
       " -2.56555146682984,\n",
       " 0.439961524610728,\n",
       " -0.260215120221697,\n",
       " 0.23915411187824,\n",
       " 0.0585189750677431,\n",
       " 0.994279345865177,\n",
       " -0.00359956318197308,\n",
       " -1.33519147480243,\n",
       " -0.397358539254111,\n",
       " 0.439961524610728,\n",
       " -0.429989807649004,\n",
       " 1.24320555951971,\n",
       " -0.496517149884582,\n",
       " -0.599201778713575,\n",
       " 0.26029264897955,\n",
       " 0.989797466710602,\n",
       " 0.50373844696225,\n",
       " -1.73786132833773,\n",
       " 0.597195595525027,\n",
       " -1.92591373398641,\n",
       " 1.10910099750817,\n",
       " 1.13808643198301,\n",
       " -2.08155551508869,\n",
       " -0.75860037571926,\n",
       " -1.05899799038095,\n",
       " 0.339556020247105,\n",
       " 0.439961524610728,\n",
       " 0.334625776914176,\n",
       " 0.953459216405889,\n",
       " -0.0448634541906483,\n",
       " -0.535467414373893,\n",
       " 1.10933155370155,\n",
       " -0.52513770406583,\n",
       " 1.11438695101786,\n",
       " 0.842606540648234,\n",
       " -1.26868535215846,\n",
       " -1.28276570388248,\n",
       " -1.80327153195803,\n",
       " 0.876119110375324,\n",
       " 0.422144355491307,\n",
       " -0.746508634549636,\n",
       " -1.75756247178124,\n",
       " 0.473968273650239,\n",
       " 1.10933155370155,\n",
       " -0.510937573326197,\n",
       " 1.27826994710041,\n",
       " 0.185662513653259,\n",
       " -0.0582123607589716,\n",
       " -0.486227258790259,\n",
       " -1.75756247178124,\n",
       " 1.27667406097425,\n",
       " -1.59466782113548,\n",
       " 0.262822929695734,\n",
       " -1.70434875861064,\n",
       " 0.989797466710602,\n",
       " -0.295087858940278,\n",
       " 1.0701905522326,\n",
       " 0.719996544752459,\n",
       " -1.77027195288412,\n",
       " -0.781053698110154,\n",
       " 0.598727039920146,\n",
       " 1.27405959353085,\n",
       " -0.564093519025504,\n",
       " 0.642175654201316,\n",
       " -0.564048149341402,\n",
       " 1.0701905522326,\n",
       " -0.341824903278122,\n",
       " -1.96482417926198,\n",
       " 1.28467217835392,\n",
       " 0.706598918332718,\n",
       " 0.579274529984365,\n",
       " -0.102207934526366,\n",
       " 0.900709118925694,\n",
       " -0.376135420884919,\n",
       " 1.40949953018436,\n",
       " 0.926520122082437,\n",
       " -0.379685237733824,\n",
       " 0.634684332724337,\n",
       " 0.497609811563913,\n",
       " 0.0383048671980643,\n",
       " 0.829239603209405,\n",
       " 0.564354763650173,\n",
       " 0.48653387309903,\n",
       " -0.971258111375682,\n",
       " 0.23927090856685,\n",
       " 0.253071201445601,\n",
       " -0.581544630256631,\n",
       " -0.535129524307294,\n",
       " -1.4027362817954,\n",
       " -0.164872458589217,\n",
       " -0.953152602097117,\n",
       " 0.408712982547887,\n",
       " -0.213854141861258,\n",
       " -0.733801051217404,\n",
       " -1.48333542610263,\n",
       " -0.783441247075023,\n",
       " 0.641513194197249,\n",
       " 0.972099966217012,\n",
       " -1.46774305829811,\n",
       " 0.175250310894458,\n",
       " -1.22552571902612,\n",
       " -1.4027362817954,\n",
       " 0.419182111938213,\n",
       " -1.23285982636747,\n",
       " 0.265014180998248,\n",
       " 1.07403731052786,\n",
       " -0.460406660165596,\n",
       " -1.17071299050689,\n",
       " 0.755948714560977,\n",
       " -0.992063047372689,\n",
       " 1.0701905522326,\n",
       " 0.313082023708868,\n",
       " 1.03362830429051,\n",
       " -1.09024692596408,\n",
       " -1.99067343624685,\n",
       " 1.28191560319977,\n",
       " 0.968798289594455,\n",
       " -1.80918239815969,\n",
       " 0.855357038545309,\n",
       " -1.4328260350607,\n",
       " -0.596075155191685,\n",
       " 1.13808643198301,\n",
       " 0.814969791723953,\n",
       " -1.14770482847498,\n",
       " -0.246525665219529,\n",
       " 0.369802537272315,\n",
       " 0.0585189750677431,\n",
       " -1.12623472156049,\n",
       " -0.00996362436460503,\n",
       " 1.40949953018436,\n",
       " -0.779261527378905,\n",
       " 0.296070948612527,\n",
       " -0.216896895197801,\n",
       " 1.06281053932284,\n",
       " 0.28470623969371,\n",
       " -0.932858794576327,\n",
       " 0.978296273700086,\n",
       " 1.31592111393706,\n",
       " -2.12268477597773,\n",
       " -1.19999504666178,\n",
       " 1.10212913917881,\n",
       " -1.62317166694938,\n",
       " -0.717049409583369,\n",
       " 1.10230499578951,\n",
       " 0.0300867972781843,\n",
       " -0.0193019154834,\n",
       " -1.14685515734813,\n",
       " -2.19614552194098,\n",
       " -1.02571718725709,\n",
       " 0.978296273700086,\n",
       " -2.08155551508869,\n",
       " -0.430871108981201,\n",
       " -0.0150395288217961,\n",
       " 1.06077538369876,\n",
       " -1.30219792188555,\n",
       " 0.528581349166527,\n",
       " -0.992027214946222,\n",
       " -2.36691624176049,\n",
       " -1.14770482847498,\n",
       " 1.14801144278375,\n",
       " 0.876119110375324,\n",
       " -1.1087943831994,\n",
       " 1.27826994710041,\n",
       " 0.304296724621513,\n",
       " -1.55189857268501,\n",
       " 0.179978776659988,\n",
       " 0.440455703923149,\n",
       " 0.175250310894458,\n",
       " -0.621512892217109,\n",
       " 0.540367028974351,\n",
       " -1.26868535215846,\n",
       " -0.329814008843717,\n",
       " 0.0468204923308349,\n",
       " -1.30516983311103,\n",
       " -0.0696572594721942,\n",
       " -2.31501818674212,\n",
       " 0.0718174369251547,\n",
       " 0.875638325854746,\n",
       " -0.63848432233684,\n",
       " 0.0718174369251547,\n",
       " 1.31592111393706,\n",
       " 0.11459886653771,\n",
       " -0.900350648128308,\n",
       " 0.979734698812601,\n",
       " -0.0112751913917948,\n",
       " 0.0300867972781843,\n",
       " -0.379685237733824,\n",
       " 0.791352364108435,\n",
       " 0.657839617230895,\n",
       " 0.408712982547887,\n",
       " 0.495559062113284,\n",
       " 0.00479229747097395,\n",
       " 0.907023179435717,\n",
       " -1.46700226365005,\n",
       " 0.875638325854746,\n",
       " 1.05066505346354,\n",
       " -1.05899799038095,\n",
       " -1.20774914964979,\n",
       " 0.48653387309903,\n",
       " 0.603265208925745,\n",
       " 0.291981646721172,\n",
       " 0.758394347826551,\n",
       " 1.12727142153235,\n",
       " -1.43204991296795,\n",
       " 0.607304031883433,\n",
       " 0.544922191177836,\n",
       " -0.09699274989249,\n",
       " 1.13929835840446,\n",
       " -0.48427166364237,\n",
       " -0.172712233230048,\n",
       " 0.163078872945356,\n",
       " 1.16851268433334,\n",
       " 0.755948714560977,\n",
       " -0.637772075862252,\n",
       " 0.180721392604983,\n",
       " 1.12084246222882,\n",
       " 1.27590424447258,\n",
       " 0.14098017266066,\n",
       " -0.581544630256631,\n",
       " 0.534697724358764,\n",
       " 0.926520122082437,\n",
       " -1.35650092356657,\n",
       " -1.18502879913206,\n",
       " -2.12046596036426,\n",
       " -0.797510820994831,\n",
       " 0.376903944426195,\n",
       " -1.10987484581602,\n",
       " 0.253071201445601,\n",
       " 0.0718174369251547,\n",
       " -1.26868535215846,\n",
       " -1.23346354811633,\n",
       " -0.402789060597252,\n",
       " -0.218130719983525,\n",
       " 0.334625776914176,\n",
       " 1.14801144278375,\n",
       " 1.04302389002484,\n",
       " -1.33386905247995,\n",
       " -1.16325469537246,\n",
       " -1.30334660957726,\n",
       " -0.344545128191809,\n",
       " 0.23927090856685,\n",
       " -1.42413519480213,\n",
       " 1.0701905522326,\n",
       " -1.07059230219275,\n",
       " -1.4704492297673,\n",
       " 1.04468167218798,\n",
       " -1.34074852588581,\n",
       " 0.607304031883433,\n",
       " 0.872111010835791,\n",
       " 0.800113538039163,\n",
       " -0.190769976503235,\n",
       " -1.4324833364275,\n",
       " 0.451707688042341,\n",
       " -1.30700947870196,\n",
       " 0.914548771130317,\n",
       " -0.481354147843781,\n",
       " -1.73786132833773,\n",
       " -0.121529922887002,\n",
       " 0.468317777199008,\n",
       " 1.4059348392863,\n",
       " 0.0585189750677431,\n",
       " 1.05066505346354,\n",
       " -0.291675032412401,\n",
       " 0.540367028974351,\n",
       " -1.15989655423098,\n",
       " 0.136339865618886,\n",
       " -0.652761827800241,\n",
       " 1.12727142153235,\n",
       " 1.03128010695703,\n",
       " -1.1087943831994,\n",
       " -0.559919235090311,\n",
       " 0.406493023156187,\n",
       " -2.24434244131896,\n",
       " 0.875638325854746,\n",
       " 1.31592111393706,\n",
       " -0.0112751913917948,\n",
       " -0.866534515433376,\n",
       " -0.833021945706286,\n",
       " -1.09958954229816,\n",
       " -1.18723448071181,\n",
       " -0.430871108981201,\n",
       " -1.3763272186606,\n",
       " 1.40949953018436,\n",
       " 1.16851268433334,\n",
       " -1.26799312743916,\n",
       " -0.953152602097117,\n",
       " -0.246525665219529,\n",
       " 0.829759829702995,\n",
       " 1.01138250984028,\n",
       " 0.603113877397893,\n",
       " -1.86383893371079,\n",
       " -1.62317166694938,\n",
       " 0.180721392604983,\n",
       " 0.884241954570418,\n",
       " 0.719996544752459,\n",
       " 1.02921009516021,\n",
       " -0.0908001402654495,\n",
       " -2.19828685091541,\n",
       " -1.73786132833773,\n",
       " -1.23695139427351,\n",
       " 0.367028727303907,\n",
       " -0.296345507389176,\n",
       " 0.926520122082437,\n",
       " -0.304619423058557,\n",
       " 0.961031326948384,\n",
       " -0.397358539254111,\n",
       " 0.495914170923356,\n",
       " 0.41403413162775,\n",
       " -1.99583308993905,\n",
       " 0.922342675157862,\n",
       " 1.09563279213051,\n",
       " -0.63398929618739,\n",
       " 1.15937063285942,\n",
       " 1.38478199035282,\n",
       " -1.02571718725709,\n",
       " 0.914548771130317,\n",
       " -0.833021945706286,\n",
       " -0.904579217166058,\n",
       " 0.690942402274422,\n",
       " -0.631030521934587,\n",
       " 0.681086099476888,\n",
       " -0.0850246435223168,\n",
       " 0.291981646721172,\n",
       " 0.525444318374602,\n",
       " 0.418940575899193,\n",
       " 0.756711144595315,\n",
       " 0.876119110375324,\n",
       " -1.30334660957726,\n",
       " -1.09958954229816,\n",
       " 0.670641625528527,\n",
       " 0.700639537036547,\n",
       " -0.865310032116374,\n",
       " 1.01290466180783,\n",
       " 1.06281053932284,\n",
       " -2.45573327887905,\n",
       " 0.577192147961468,\n",
       " -1.40935238415628,\n",
       " 0.989797466710602,\n",
       " -1.08862345996662,\n",
       " -0.88169378228938,\n",
       " 0.681086099476888,\n",
       " -0.631030521934587,\n",
       " -1.38485265117887,\n",
       " 1.47720793355067,\n",
       " -2.15959033354874,\n",
       " -1.59466782113548,\n",
       " 1.0701905522326,\n",
       " -1.59022989529419,\n",
       " -1.62054791291846,\n",
       " 0.0783099145510313,\n",
       " 0.37271797660176,\n",
       " 0.608326484276941,\n",
       " 0.586294255246056,\n",
       " 0.741178037701597,\n",
       " -1.7020225684799,\n",
       " 0.515021160981687,\n",
       " -1.21524266829661,\n",
       " -1.18738825351849,\n",
       " -0.356869042585994,\n",
       " -1.26700502030908,\n",
       " 0.910308411792737,\n",
       " 0.71831182779596,\n",
       " -0.677766865960105,\n",
       " -1.22966642103051,\n",
       " -0.746331126250924,\n",
       " -0.252764587136829,\n",
       " -1.68921921850741,\n",
       " 0.977384239780983,\n",
       " 1.37707956533788,\n",
       " -1.67083618888355,\n",
       " 0.86318702926281,\n",
       " 0.585925829502245,\n",
       " 0.291981646721172,\n",
       " 0.165513106866101,\n",
       " 0.272619017338022,\n",
       " -1.54724786336601,\n",
       " -0.340255970190741,\n",
       " -0.971258111375682,\n",
       " -1.18723448071181,\n",
       " -1.1330580437527,\n",
       " 0.525444318374602,\n",
       " 0.920352322992141,\n",
       " -0.434019278718319,\n",
       " 0.0870105983706088,\n",
       " 0.219120709404338,\n",
       " -0.246525665219529,\n",
       " 0.875638325854746,\n",
       " 1.1740437247872,\n",
       " 0.586294255246056,\n",
       " 0.483313793502665,\n",
       " 0.0885164203515176,\n",
       " 0.500709442737836,\n",
       " -0.241671092187928,\n",
       " -0.548865626582772,\n",
       " 0.107884006505189,\n",
       " -1.80897244437611,\n",
       " -0.0885287116111344,\n",
       " 0.291981646721172,\n",
       " 0.961031326948384,\n",
       " -0.195940003025553,\n",
       " -0.823820570438701,\n",
       " 1.72007680147304,\n",
       " -1.26700502030908,\n",
       " 1.15937063285942,\n",
       " 0.214160756170029,\n",
       " 0.603265208925745,\n",
       " 1.22246729466657,\n",
       " -1.23116964849535,\n",
       " -1.36733755393449,\n",
       " 0.229574910778941,\n",
       " 0.334318659802405,\n",
       " -0.779261527378905,\n",
       " 1.3101425624288,\n",
       " 0.99236966168146,\n",
       " -0.284648153582344,\n",
       " -0.0492461679878697,\n",
       " -0.136033251310115,\n",
       " -1.63732361915646,\n",
       " -0.75860037571926,\n",
       " 0.972182822522608,\n",
       " -1.66855406702536,\n",
       " -0.0458777306939917,\n",
       " -1.30628756393234,\n",
       " -1.65218305936452,\n",
       " 0.987107045391448,\n",
       " -1.03384980805919,\n",
       " -0.63848432233684,\n",
       " -1.65983045654172,\n",
       " -0.790341698554976,\n",
       " 0.382983283095002,\n",
       " 1.0255063621908,\n",
       " 0.92999271151655,\n",
       " 0.292347609402157,\n",
       " -1.87440001422189,\n",
       " 0.23927090856685,\n",
       " -1.77027195288412,\n",
       " -1.43398521737853,\n",
       " 1.12923014071007,\n",
       " -0.397358539254111,\n",
       " 1.02752736478197,\n",
       " 0.00479229747097395,\n",
       " 1.06617184637462,\n",
       " -1.42007794540398,\n",
       " 1.16851268433334,\n",
       " 0.876119110375324,\n",
       " 1.40949953018436,\n",
       " -1.70434875861064,\n",
       " 0.291981646721172,\n",
       " 0.330892091996744,\n",
       " 1.09563279213051,\n",
       " -1.05899799038095,\n",
       " 0.419182111938213,\n",
       " 0.382861811868042,\n",
       " 0.473430026065269,\n",
       " -1.00965742817504,\n",
       " -0.52513770406583,\n",
       " 0.564354763650173,\n",
       " 0.214160756170029,\n",
       " 0.23915411187824,\n",
       " -1.52561359361464,\n",
       " -1.14770482847498,\n",
       " -0.258510043347204,\n",
       " 1.18692188805932,\n",
       " -0.0599155859935225,\n",
       " 0.225900885807531,\n",
       " 0.473968273650239,\n",
       " 0.257520026203694,\n",
       " -1.65272776646046,\n",
       " 1.40949953018436,\n",
       " 0.439592583267062,\n",
       " -1.77767808741152,\n",
       " 0.701947740974723,\n",
       " 0.932817422593748,\n",
       " 0.763375274232797,\n",
       " 0.330892091996744,\n",
       " -0.0285974957528473,\n",
       " 0.30120187818858,\n",
       " -0.559919235090311,\n",
       " -0.257268568254085,\n",
       " -1.34225705485283,\n",
       " -0.856060160977616,\n",
       " -0.992063047372689,\n",
       " -1.03097349264826,\n",
       " -0.402789060597252,\n",
       " -0.564048149341402,\n",
       " -1.14770482847498,\n",
       " 0.411117293401116,\n",
       " 0.272619017338022,\n",
       " -1.2355846352725,\n",
       " 0.0783099145510313,\n",
       " 0.331646285081327,\n",
       " 0.373024521701646,\n",
       " -2.27610774146655,\n",
       " -1.70434875861064,\n",
       " 1.16851268433334,\n",
       " 0.525444318374602,\n",
       " 1.16256503549545,\n",
       " -0.779261527378905,\n",
       " 1.0255063621908,\n",
       " -0.304619423058557,\n",
       " -0.174943696585686,\n",
       " -0.932247035025456,\n",
       " -0.0885287116111344,\n",
       " 0.222208368527447,\n",
       " 1.34930179720262,\n",
       " -0.932858794576327,\n",
       " -1.09773497636255,\n",
       " -0.430871108981201,\n",
       " -0.81766084417826,\n",
       " 1.08994759708681,\n",
       " -1.70434875861064,\n",
       " 0.621594397640184,\n",
       " -0.262877005934635,\n",
       " 0.913092906777817,\n",
       " -0.992063047372689,\n",
       " 0.813281151747804,\n",
       " 0.909684951356344,\n",
       " 0.0196085297921715,\n",
       " -1.77767808741152,\n",
       " -1.98116499583196,\n",
       " 1.12923014071007,\n",
       " 1.28467217835392,\n",
       " -0.299546735766103,\n",
       " 0.147166550128454,\n",
       " 0.707709536247056,\n",
       " -0.00996362436460503,\n",
       " 0.972182822522608,\n",
       " 0.719996544752459,\n",
       " 0.221082543490581,\n",
       " 0.573835530428892,\n",
       " 0.349987581279877,\n",
       " 1.12727142153235,\n",
       " 0.071808008610776,\n",
       " -1.56814856266174,\n",
       " -1.65354061705741,\n",
       " 1.16851268433334,\n",
       " -0.999184037934538,\n",
       " -0.130434065718029,\n",
       " 0.876119110375324,\n",
       " 0.292347609402157,\n",
       " 1.23783376309809,\n",
       " 0.429063024279698,\n",
       " 0.105276510065317,\n",
       " 1.33466174502193,\n",
       " -1.06988393792383,\n",
       " -0.702462893780194,\n",
       " 0.304296724621513,\n",
       " 1.0701905522326,\n",
       " -1.77767808741152,\n",
       " 1.40949953018436,\n",
       " -1.06612104084362,\n",
       " 0.861287270198005,\n",
       " 0.473968273650239,\n",
       " -0.719689930443688,\n",
       " -1.99019804198158,\n",
       " -1.14511008600648,\n",
       " -0.274241375533518,\n",
       " -0.910440724305693,\n",
       " 1.51818018465465,\n",
       " -1.49932207289429,\n",
       " -0.548865626582772,\n",
       " -0.894459477776971,\n",
       " -0.481354147843781,\n",
       " -0.341824903278122,\n",
       " -0.568377543224087,\n",
       " -1.40473269744839,\n",
       " -0.43021951320734,\n",
       " -1.35525127936924,\n",
       " -0.689242921649265,\n",
       " -0.308296499795993,\n",
       " -0.0162341031651332,\n",
       " 0.842606540648234,\n",
       " 1.16851268433334,\n",
       " 0.607304031883433,\n",
       " -1.97409080552784,\n",
       " -0.43021951320734,\n",
       " -0.206376342480928,\n",
       " -2.66712411643915,\n",
       " -0.430871108981201,\n",
       " 0.257520026203694,\n",
       " 1.05335462461849,\n",
       " -0.515949037009763,\n",
       " -0.218130719983525,\n",
       " -1.26799312743916,\n",
       " -1.22076013144799,\n",
       " 1.67969747810936,\n",
       " 1.07403731052786,\n",
       " 0.418940575899193,\n",
       " 0.09658283511177,\n",
       " -0.268982875926372,\n",
       " -1.70084513056344,\n",
       " 1.06281053932284,\n",
       " -0.834897040453163,\n",
       " -0.0620659972073883,\n",
       " 1.37707956533788,\n",
       " 1.09402340261556,\n",
       " -1.26680619562754,\n",
       " -1.46774305829811,\n",
       " -1.30040055102541,\n",
       " 0.884241954570418,\n",
       " 1.24475737737332,\n",
       " 0.993248980926827,\n",
       " -1.30219792188555,\n",
       " -1.67083618888355,\n",
       " -0.39526835938535,\n",
       " 0.681086099476888,\n",
       " 1.10910099750817,\n",
       " 1.24475737737332,\n",
       " 0.962998784292824,\n",
       " -0.719689930443688,\n",
       " 0.0655234422069162,\n",
       " -0.833021945706286,\n",
       " -1.27194458854253,\n",
       " 0.841583542065221,\n",
       " -0.482802158719479,\n",
       " -1.80897244437611,\n",
       " -0.0492461679878697,\n",
       " 0.914548771130317,\n",
       " 0.962998784292824,\n",
       " 0.0655234422069162,\n",
       " -0.641869039892545,\n",
       " 0.395815005362906,\n",
       " 0.993248980926827,\n",
       " -0.697967524843669,\n",
       " -0.09699274989249,\n",
       " -1.51626202555283,\n",
       " -0.369495922963544,\n",
       " -2.58256778141511,\n",
       " -1.66855406702536,\n",
       " 0.565946659941896,\n",
       " -0.831137946148934,\n",
       " 1.0701905522326,\n",
       " 0.447623427823459,\n",
       " -1.23346354811633,\n",
       " -0.284941429727458,\n",
       " -1.22966642103051,\n",
       " -0.184027794053265,\n",
       " 0.814969791723953,\n",
       " 0.884241954570418,\n",
       " -1.66855406702536,\n",
       " -2.17050352364416,\n",
       " -0.460406660165596,\n",
       " 0.291981646721172,\n",
       " 1.08994759708681,\n",
       " 0.758906990028031,\n",
       " 0.00479229747097395,\n",
       " -0.225492548362466,\n",
       " 0.564714560598538,\n",
       " -1.26868535215846,\n",
       " 0.595303118863663,\n",
       " 0.642175654201316,\n",
       " -0.856060160977616,\n",
       " 0.657567349510425,\n",
       " -1.1087943831994,\n",
       " 0.809093970921143,\n",
       " -1.61016992863868,\n",
       " -0.126473141789861,\n",
       " -0.695735501030716,\n",
       " 0.330892091996744,\n",
       " -1.30219792188555,\n",
       " -0.559919235090311,\n",
       " -0.971258111375682,\n",
       " 1.1497599683492,\n",
       " 0.408111519585134,\n",
       " -0.162471501571012,\n",
       " 0.32931896752932,\n",
       " -1.65354061705741,\n",
       " 1.40949953018436,\n",
       " -2.62630174894669,\n",
       " -1.10987484581602,\n",
       " -0.564048149341402,\n",
       " 1.63931815474568,\n",
       " -0.548865626582772,\n",
       " 1.27367351292414,\n",
       " -0.274241375533518,\n",
       " -1.63231414856146,\n",
       " -0.559919235090311,\n",
       " 0.640772533337974,\n",
       " 0.968798289594455,\n",
       " -0.430871108981201,\n",
       " -1.4704492297673,\n",
       " 0.440455703923149,\n",
       " -2.66712411643915,\n",
       " 0.0686014628819244,\n",
       " -1.1248553785731,\n",
       " 0.628444531108159,\n",
       " -0.992063047372689,\n",
       " -0.965715536479997,\n",
       " 1.31592111393706,\n",
       " 0.835750085171348,\n",
       " -1.0110088439584,\n",
       " -0.397358539254111,\n",
       " -0.965715536479997,\n",
       " 1.17626855661063,\n",
       " -2.1175079387829,\n",
       " 0.0686014628819244,\n",
       " -0.430871108981201,\n",
       " -1.70434875861064,\n",
       " 0.993248980926827,\n",
       " -0.520636691467046,\n",
       " 0.14528319028958,\n",
       " -1.3455701075556,\n",
       " -0.363506516973987,\n",
       " -1.44748460421017,\n",
       " 0.989797466710602,\n",
       " 1.40949953018436,\n",
       " 0.841963787058399,\n",
       " -1.08314219382245,\n",
       " 0.473968273650239,\n",
       " 0.865130426150909,\n",
       " 1.26338865075756,\n",
       " -1.14770482847498,\n",
       " -0.363282510298258,\n",
       " 0.640772533337974,\n",
       " 0.70061479017368,\n",
       " 0.706598918332718,\n",
       " -1.51864198975974,\n",
       " 1.47780086129097,\n",
       " 0.707709536247056,\n",
       " -1.28276570388248,\n",
       " -1.10987484581602,\n",
       " -1.20165401217182,\n",
       " -1.06609651062077,\n",
       " -1.57571972650626,\n",
       " 0.69320389664261,\n",
       " 0.977384239780983,\n",
       " 1.37707956533788,\n",
       " 1.06281053932284,\n",
       " 0.837204646485788,\n",
       " -1.38485265117887,\n",
       " 0.500709442737836,\n",
       " 0.103922759006272,\n",
       " -1.24649160387974,\n",
       " 1.33466174502193,\n",
       " 0.99236966168146,\n",
       " -2.66712411643915,\n",
       " 1.01107645710647,\n",
       " 0.607304031883433,\n",
       " 0.48653387309903,\n",
       " 0.876119110375324,\n",
       " -1.62054791291846,\n",
       " 0.138745011519858,\n",
       " -2.04264506981312,\n",
       " -0.169401316222573,\n",
       " -2.08125974412258,\n",
       " 1.12923014071007,\n",
       " -0.0582123607589716,\n",
       " -1.06612104084362,\n",
       " 1.25649604667355,\n",
       " -0.468659405814178,\n",
       " 0.00479229747097395,\n",
       " 0.291981646721172,\n",
       " 0.642175654201316,\n",
       " 0.129422940519542,\n",
       " 1.31592111393706,\n",
       " 0.257520026203694,\n",
       " 1.03362830429051,\n",
       " -0.356869042585994,\n",
       " 0.384805693494673,\n",
       " -0.00359956318197308,\n",
       " 1.19514559774522,\n",
       " -1.69881018639504,\n",
       " 1.27826994710041,\n",
       " 0.239150515883481,\n",
       " 0.695047175614041,\n",
       " 0.382202121221773,\n",
       " -2.00373462453755,\n",
       " 0.30120187818858,\n",
       " -0.81766084417826,\n",
       " -1.19843375478667,\n",
       " 1.14801144278375,\n",
       " -1.34875177416652,\n",
       " -0.763315239935053,\n",
       " -0.167093798857664,\n",
       " -1.47847546258359,\n",
       " -1.73191860151754,\n",
       " -1.06612104084362,\n",
       " 0.0947402695193354,\n",
       " -0.971258111375682,\n",
       " -1.53257009181108,\n",
       " 0.500709442737836,\n",
       " -0.00996362436460503,\n",
       " -0.0850246435223168,\n",
       " 0.306800483744294,\n",
       " -0.809006505715899,\n",
       " 0.180721392604983,\n",
       " -0.664063576980838,\n",
       " -0.397358539254111,\n",
       " 0.257520026203694,\n",
       " 0.758394347826551,\n",
       " 0.640772533337974,\n",
       " -1.10647583398445,\n",
       " 1.28191560319977,\n",
       " -0.397358539254111,\n",
       " -0.756331953206634,\n",
       " 1.40949953018436,\n",
       " -2.56332895987681,\n",
       " 0.914548771130317,\n",
       " 0.408712982547887,\n",
       " 1.24475737737332,\n",
       " 0.32931896752932,\n",
       " 0.140542876799583,\n",
       " 0.253071201445601,\n",
       " 1.12500429027107,\n",
       " -0.396751011752799,\n",
       " 1.03362830429051,\n",
       " -1.26799312743916,\n",
       " -0.229408504480094,\n",
       " -0.363506516973987,\n",
       " -0.688183878486488,\n",
       " -0.894459477776971,\n",
       " -0.447316813514687,\n",
       " 1.37707956533788,\n",
       " 0.841963787058399,\n",
       " -2.09806992039415,\n",
       " 0.253457304110579,\n",
       " 1.10212913917881,\n",
       " -0.756331953206634,\n",
       " 1.14801144278375,\n",
       " -0.797510820994831,\n",
       " -1.10647583398445,\n",
       " 1.40949953018436,\n",
       " 1.0701905522326,\n",
       " -0.229408504480094,\n",
       " 1.01138250984028,\n",
       " 0.103922759006272,\n",
       " -0.510937573326197,\n",
       " -0.674549859665813,\n",
       " -0.0620659972073883,\n",
       " 1.0701905522326,\n",
       " -0.442071604220517,\n",
       " -0.402137448640123,\n",
       " 0.295919343003049,\n",
       " 1.14801144278375,\n",
       " 0.841963787058399,\n",
       " -1.19746581154428,\n",
       " 0.607304031883433,\n",
       " 0.92062304968959,\n",
       " -1.14685515734813,\n",
       " -1.2408362182553,\n",
       " -1.62054791291846,\n",
       " -0.683895173702397,\n",
       " 0.909631680102414,\n",
       " 0.291981646721172,\n",
       " -1.70434875861064,\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt = '../data/MasterArbeit/data/data_scores'\n",
    "data_tgt = []\n",
    "with open(tgt) as fi:\n",
    "    for line in fi:\n",
    "        data_tgt.append(float(line.strip()))\n",
    "data_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.17366603836231"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(data_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.mean(a)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8722813232690143"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = np.std(a)\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.5666989 , -1.21854359, -0.87038828, -0.52223297, -0.17407766,\n",
       "        0.17407766,  0.52223297,  0.87038828,  1.21854359,  1.5666989 ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = (a-mean)/std\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min = np.min(a)\n",
    "min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max = np.max(a)\n",
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./utils')\n",
    "sys.path.append('./models')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from LinearModel import BasicLinear, BasicLinear_dropout, BiLinear\n",
    "from FullHiddenModel import MultiHeadAttnMlpModel, MultiHeadAttnLSTMModel, MultiHeadAttnConvModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nnInit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers = nn.Sequential()\n",
    "layers.add_module('fc1', nn.Linear(4,2))\n",
    "layers.add_module('fc2', nn.Linear(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers.add_module('bili', MultiHeadAttnLSTMModel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> initializing Linear model\n",
      "Linear (4 -> 2)\n",
      "=> initializing Linear model\n",
      "Linear (2 -> 1)\n",
      "=> initializing Linear model\n",
      "Linear (512 -> 500)\n",
      "=> initializing rnn\n",
      "LSTM(500, 500, num_layers=2)\n",
      "('num layers: ', 4)\n",
      "=> initializing Linear model\n",
      "Linear (500 -> 100)\n",
      "=> initializing BatchNorm1d\n",
      "BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "=> initializing Linear model\n",
      "Linear (100 -> 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential (\n",
       "  (fc1): Linear (4 -> 2)\n",
       "  (fc2): Linear (2 -> 1)\n",
       "  (bili): MultiHeadAttnLSTMModel (\n",
       "    (attn): MultiHeadAttention (\n",
       "      (attention): ScaledDotProductAttention (\n",
       "        (dropout): Dropout (p = 0.1)\n",
       "        (softmax): Softmax ()\n",
       "      )\n",
       "      (project): Linear (\n",
       "        (li): Linear (512 -> 500)\n",
       "      )\n",
       "      (dropout): Dropout (p = 0.1)\n",
       "    )\n",
       "    (rnn): LSTM(500, 500, num_layers=2)\n",
       "    (mlp): Sequential (\n",
       "      (fc1): Linear (500 -> 100)\n",
       "      (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (act_fun2): LeakyReLU (0.01)\n",
       "      (fc3): Linear (100 -> 1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.apply(nnInit.weight_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py27",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
