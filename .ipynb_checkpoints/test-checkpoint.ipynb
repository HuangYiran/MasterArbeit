{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_sys = file(\"./data/hidden_sys\")\n",
    "data_sys = np.load(file_sys)\n",
    "data_sys.shape\n",
    "file_sys.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_ref = open(\"./data/hidden_ref\")\n",
    "data_ref = np.load(file_ref)\n",
    "data_ref.shape\n",
    "file_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_scores = []\n",
    "with open(\"./data/data_scores\") as fi:\n",
    "    for line in fi:\n",
    "        data_scores.append(float(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.9131\n",
       " 0.1423\n",
       " 0.1597\n",
       "   ⋮   \n",
       " 1.0628\n",
       " 1.1250\n",
       " 0.8761\n",
       "[torch.FloatTensor of size 9392]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.1317e-01  1.9135e-01  4.8339e-02  ...   3.3562e-01  2.1015e-01 -3.0384e-01\n",
       " 6.9478e-01  6.4986e-01 -2.1220e-01  ...  -3.8425e-01 -6.4973e-01 -2.3927e-01\n",
       " 2.5970e-01  5.3346e-01  8.0853e-02  ...  -4.2903e-01 -3.2311e-01 -8.9193e-02\n",
       "                ...                   ⋱                   ...                \n",
       " 6.6741e-01  6.7923e-01  1.4909e-01  ...  -2.2978e-01 -3.1571e-01  1.3677e-01\n",
       " 2.5324e-02  1.3155e-01 -6.5003e-03  ...   4.0089e-01 -2.2887e-01 -3.4650e-01\n",
       " 4.1332e-01  5.0622e-01 -4.5596e-01  ...  -5.0268e-01 -3.7340e-01 -2.6541e-01\n",
       "[torch.FloatTensor of size 9392x1000]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(data_scores)\n",
    "b = torch.from_numpy(data_ref)\n",
    "c = torch.from_numpy(data_sys)\n",
    "d = torch.cat((c,b), 1)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(3248)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = range(len(data_scores))\n",
    "random.shuffle(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb = zip(d, a, tmp)\n",
    "comb = sorted(comb, key = lambda x: x[-1])\n",
    "d, a, tmp = zip(*comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.9131\n",
       " 0.1423\n",
       " 0.1597\n",
       "   ⋮   \n",
       " 1.0628\n",
       " 1.1250\n",
       " 0.8761\n",
       "[torch.FloatTensor of size 9392]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 3.1889e-01  6.3258e-01  1.1316e-01  ...  -4.0196e-01 -4.5356e-01 -4.0905e-01\n",
       " 4.2669e-01  5.7952e-01 -1.5267e-01  ...  -7.3717e-01 -5.4875e-01 -4.3146e-01\n",
       " 2.3961e-01  4.4815e-01 -3.0775e-01  ...  -7.1228e-01 -6.1418e-01 -2.2865e-01\n",
       "                ...                   ⋱                   ...                \n",
       " 3.0726e-01  4.2501e-01 -6.7688e-02  ...  -3.7334e-01 -6.1822e-01 -2.2931e-01\n",
       " 4.6479e-01  4.5037e-01  4.2272e-02  ...  -5.3935e-01 -3.9767e-01 -6.4714e-02\n",
       " 4.3281e-01  4.3685e-01 -4.6474e-02  ...  -6.4254e-01 -2.9456e-01 -4.9992e-01\n",
       "[torch.FloatTensor of size 9392x1000]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = d[0].view(1, -1)\n",
    "for i in range(1, len(d)):\n",
    "    tmp = torch.cat((tmp, d[i].view(1, -1)), 0)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 3.1889e-01  6.3258e-01  1.1316e-01  ...  -4.0196e-01 -4.5356e-01 -4.0905e-01\n",
       " 4.2669e-01  5.7952e-01 -1.5267e-01  ...  -7.3717e-01 -5.4875e-01 -4.3146e-01\n",
       " 2.3961e-01  4.4815e-01 -3.0775e-01  ...  -7.1228e-01 -6.1418e-01 -2.2865e-01\n",
       "                ...                   ⋱                   ...                \n",
       " 3.0726e-01  4.2501e-01 -6.7688e-02  ...  -3.7334e-01 -6.1822e-01 -2.2931e-01\n",
       " 4.6479e-01  4.5037e-01  4.2272e-02  ...  -5.3935e-01 -3.9767e-01 -6.4714e-02\n",
       " 4.3281e-01  4.3685e-01 -4.6474e-02  ...  -6.4254e-01 -2.9456e-01 -4.9992e-01\n",
       "[torch.FloatTensor of size 9392x1000]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'view'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-0706f0478fb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'view'"
     ]
    }
   ],
   "source": [
    "tmp = d[0][0].view(1, -1)\n",
    "for i in range(1, len(d)):\n",
    "    tmp = torch.cat((tmp, d[i][0].view(1, -1)), 0)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 8.8883e-23  1.4013e-45  7.8276e-23\n",
       "[torch.FloatTensor of size 1x3]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0][0].view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.Tensor(20, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = a[0:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.6434e-43  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.5593e-43  0.0000e+00  1.2916e+26 -1.2851e+17\n",
       " 6.2487e-29  1.4013e-45  8.8666e-23  1.4013e-45\n",
       "-3.1784e+15  1.4013e-45  0.0000e+00  1.4013e-45\n",
       "[torch.FloatTensor of size 10x4]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = a[10:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "-2.5641e+04  4.5863e-41  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "-2.5641e+04  4.5863e-41 -2.5641e+04  4.5863e-41\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.4472e-43  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00 -1.0898e+17  4.7161e-01\n",
       " 4.8357e-29  1.4013e-45  4.2008e-19  1.4013e-45\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "[torch.FloatTensor of size 10x4]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.6434e-43  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.5593e-43  0.0000e+00  1.2916e+26 -1.2851e+17\n",
       " 6.2487e-29  1.4013e-45  8.8666e-23  1.4013e-45\n",
       "-3.1784e+15  1.4013e-45  0.0000e+00  1.4013e-45\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "-2.5641e+04  4.5863e-41  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "-2.5641e+04  4.5863e-41 -2.5641e+04  4.5863e-41\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.4472e-43  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00 -1.0898e+17  4.7161e-01\n",
       " 4.8357e-29  1.4013e-45  4.2008e-19  1.4013e-45\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "[torch.FloatTensor of size 20x4]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 9\n",
    "b = 2\n",
    "c = round(a/b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = torch.Tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    a.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = torch.cat(a, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt = Params.Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pas = {'tgt': '../data/MasterArbeit/data/data_scores', 'src_sys': '../data/MasterArbeit/data/sys_hidden', 'src_ref': '../data/MasterArbeit/data/ref_hidden', 'batch_size': 100, 'dim2': 100, 'dim3': 10, 'lr': 0.01592636698766986, 'act_func': 'LeakyReLU', 'act_func_out': 'Tanh', 'model': './model/LinearModel', 'type': 'linear', 'momentum': 0.7919209839255212, 'drop_out_rate': 0.44618529671927565}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pas1 = {'dim2': 10, 'act_func_out': 'Tanh', 'tgt': '../data/MasterArbeit/data/normalized_data_scores', 'src_sys': '../data/MasterArbeit/data/sys_hidden', 'src_ref': '../data/MasterArbeit/data/ref_hidden', 'batch_size': 100, 'lr': 0.01592636698766986, 'act_func': 'Tanh', 'act_func_out': None, 'model': 'BiLinear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt.set_params(pas1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BiLinear'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('act_func_out', None)\n",
      "('tgt', '../data/MasterArbeit/data/normalized_data_scores')\n",
      "('src_sys', '../data/MasterArbeit/data/sys_hidden')\n",
      "('src_ref', '../data/MasterArbeit/data/ref_hidden')\n",
      "('eps', 1e-08)\n",
      "('batch_size', 100)\n",
      "('dim2', 10)\n",
      "('dim3', None)\n",
      "('lr', 0.01592636698766986)\n",
      "('act_func', 'Tanh')\n",
      "('model', 'BiLinear')\n",
      "('weight_decay', 0)\n",
      "('drop_out_rate', 0.5)\n",
      "('momentum', 0.1)\n",
      "('out', './test_data/pred')\n",
      "BiLinear (\n",
      "  (li_sys): Linear (500 -> 500)\n",
      "  (li_ref): Linear (500 -> 500)\n",
      "  (act_func): Tanh ()\n",
      "  (fc): Linear (500 -> 10)\n",
      "  (li_out): Linear (10 -> 1)\n",
      ")\n",
      "number of batch is 93\n",
      "evaluate 0\n",
      "the correlation coeffizient is : 0.018057\n",
      "evaluate 1\n",
      "the correlation coeffizient is : 0.198749\n",
      "evaluate 2\n",
      "the correlation coeffizient is : -0.029391\n",
      "evaluate 3\n",
      "the correlation coeffizient is : -0.081388\n",
      "evaluate 4\n",
      "the correlation coeffizient is : -0.189308\n",
      "evaluate 5\n",
      "the correlation coeffizient is : 0.034694\n",
      "evaluate 6\n",
      "the correlation coeffizient is : -0.235060\n",
      "evaluate 7\n",
      "the correlation coeffizient is : -0.002825\n",
      "evaluate 8\n",
      "the correlation coeffizient is : 0.105084\n",
      "evaluate 9\n",
      "the correlation coeffizient is : 0.027009\n",
      "evaluate 10\n",
      "the correlation coeffizient is : 0.114862\n",
      "evaluate 11\n",
      "the correlation coeffizient is : 0.116097\n",
      "evaluate 12\n",
      "the correlation coeffizient is : 0.069774\n",
      "evaluate 13\n",
      "the correlation coeffizient is : 0.012280\n",
      "evaluate 14\n",
      "the correlation coeffizient is : 0.003279\n",
      "evaluate 15\n",
      "the correlation coeffizient is : 0.106052\n",
      "evaluate 16\n",
      "the correlation coeffizient is : -0.038038\n",
      "evaluate 17\n",
      "the correlation coeffizient is : 0.107912\n",
      "evaluate 18\n",
      "the correlation coeffizient is : 0.118459\n",
      "evaluate 19\n",
      "the correlation coeffizient is : 0.087170\n",
      "evaluate 20\n",
      "the correlation coeffizient is : 0.103383\n",
      "evaluate 21\n",
      "the correlation coeffizient is : -0.005429\n",
      "evaluate 22\n",
      "the correlation coeffizient is : 0.099344\n",
      "evaluate 23\n",
      "the correlation coeffizient is : 0.220057\n",
      "evaluate 24\n",
      "the correlation coeffizient is : 0.166578\n",
      "evaluate 25\n",
      "the correlation coeffizient is : 0.106103\n",
      "evaluate 26\n",
      "the correlation coeffizient is : 0.156984\n",
      "evaluate 27\n",
      "the correlation coeffizient is : 0.168107\n",
      "evaluate 28\n",
      "the correlation coeffizient is : 0.241673\n",
      "evaluate 29\n",
      "the correlation coeffizient is : 0.156005\n",
      "evaluate 30\n",
      "the correlation coeffizient is : 0.121803\n",
      "evaluate 31\n",
      "the correlation coeffizient is : 0.291781\n",
      "evaluate 32\n",
      "the correlation coeffizient is : 0.286230\n",
      "evaluate 33\n",
      "the correlation coeffizient is : 0.230771\n",
      "evaluate 34\n",
      "the correlation coeffizient is : 0.145479\n",
      "evaluate 35\n",
      "the correlation coeffizient is : -0.027100\n",
      "evaluate 36\n",
      "the correlation coeffizient is : 0.216243\n",
      "evaluate 37\n",
      "the correlation coeffizient is : 0.219309\n",
      "evaluate 38\n",
      "the correlation coeffizient is : 0.104401\n",
      "evaluate 39\n",
      "the correlation coeffizient is : 0.303973\n",
      "evaluate 40\n",
      "the correlation coeffizient is : 0.299891\n",
      "evaluate 41\n",
      "the correlation coeffizient is : 0.309872\n",
      "evaluate 42\n",
      "the correlation coeffizient is : 0.437119\n",
      "evaluate 43\n",
      "the correlation coeffizient is : 0.251530\n",
      "evaluate 44\n",
      "the correlation coeffizient is : 0.255989\n",
      "evaluate 45\n",
      "the correlation coeffizient is : 0.234951\n",
      "evaluate 46\n",
      "the correlation coeffizient is : 0.194416\n",
      "evaluate 47\n",
      "the correlation coeffizient is : 0.225336\n",
      "evaluate 48\n",
      "the correlation coeffizient is : 0.263280\n",
      "evaluate 49\n",
      "the correlation coeffizient is : 0.493592\n",
      "evaluate 50\n",
      "the correlation coeffizient is : 0.293487\n",
      "evaluate 51\n",
      "the correlation coeffizient is : 0.400793\n",
      "evaluate 52\n",
      "the correlation coeffizient is : 0.327716\n",
      "evaluate 53\n",
      "the correlation coeffizient is : 0.246281\n",
      "evaluate 54\n",
      "the correlation coeffizient is : 0.296059\n",
      "evaluate 55\n",
      "the correlation coeffizient is : 0.312933\n",
      "evaluate 56\n",
      "the correlation coeffizient is : 0.442903\n",
      "evaluate 57\n",
      "the correlation coeffizient is : 0.380074\n",
      "evaluate 58\n",
      "the correlation coeffizient is : 0.416857\n",
      "evaluate 59\n",
      "the correlation coeffizient is : 0.454033\n",
      "evaluate 60\n",
      "the correlation coeffizient is : 0.352914\n",
      "evaluate 61\n",
      "the correlation coeffizient is : 0.450117\n",
      "evaluate 62\n",
      "the correlation coeffizient is : 0.299061\n",
      "evaluate 63\n",
      "the correlation coeffizient is : 0.294894\n",
      "evaluate 64\n",
      "the correlation coeffizient is : 0.426710\n",
      "evaluate 65\n",
      "the correlation coeffizient is : 0.455555\n",
      "evaluate 66\n",
      "the correlation coeffizient is : 0.338595\n",
      "evaluate 67\n",
      "the correlation coeffizient is : 0.401535\n",
      "evaluate 68\n",
      "the correlation coeffizient is : 0.401620\n",
      "evaluate 69\n",
      "the correlation coeffizient is : 0.368357\n",
      "evaluate 70\n",
      "the correlation coeffizient is : 0.488416\n",
      "evaluate 71\n",
      "the correlation coeffizient is : 0.308038\n",
      "evaluate 72\n",
      "the correlation coeffizient is : 0.295089\n",
      "evaluate 73\n",
      "the correlation coeffizient is : 0.178192\n",
      "evaluate 74\n",
      "the correlation coeffizient is : 0.318204\n",
      "evaluate 75\n",
      "the correlation coeffizient is : 0.335355\n",
      "evaluate 76\n",
      "the correlation coeffizient is : 0.350338\n",
      "evaluate 77\n",
      "the correlation coeffizient is : 0.405509\n",
      "evaluate 78\n",
      "the correlation coeffizient is : 0.394531\n",
      "evaluate 79\n",
      "the correlation coeffizient is : 0.562791\n",
      "evaluate 80\n",
      "the correlation coeffizient is : 0.313895\n",
      "evaluate 81\n",
      "the correlation coeffizient is : 0.192975\n",
      "evaluate 82\n",
      "the correlation coeffizient is : 0.456313\n",
      "evaluate 83\n",
      "the correlation coeffizient is : 0.420942\n",
      "evaluate 84\n",
      "the correlation coeffizient is : 0.473827\n",
      "evaluate 85\n",
      "the correlation coeffizient is : 0.354332\n",
      "evaluate 86\n",
      "the correlation coeffizient is : 0.435614\n",
      "evaluate 87\n",
      "the correlation coeffizient is : 0.512192\n",
      "evaluate 88\n",
      "the correlation coeffizient is : 0.488687\n",
      "evaluate 89\n",
      "the correlation coeffizient is : 0.431007\n",
      "evaluate 90\n",
      "the correlation coeffizient is : 0.281976\n",
      "evaluate 91\n",
      "the correlation coeffizient is : 0.342067\n",
      "evaluate 92\n",
      "the correlation coeffizient is : 0.210409\n",
      "evaluate 93\n",
      "the correlation coeffizient is : 0.381540\n",
      "evaluate 94\n",
      "the correlation coeffizient is : 0.524697\n",
      "evaluate 95\n",
      "the correlation coeffizient is : 0.415106\n",
      "evaluate 96\n",
      "the correlation coeffizient is : 0.433792\n",
      "evaluate 97\n",
      "the correlation coeffizient is : 0.408134\n",
      "evaluate 98\n",
      "the correlation coeffizient is : 0.457743\n",
      "evaluate 99\n",
      "the correlation coeffizient is : 0.269927\n",
      "evaluate 100\n",
      "the correlation coeffizient is : 0.453137\n",
      "evaluate 101\n",
      "the correlation coeffizient is : 0.429796\n",
      "evaluate 102\n",
      "the correlation coeffizient is : 0.494126\n",
      "evaluate 103\n",
      "the correlation coeffizient is : 0.511180\n",
      "evaluate 104\n",
      "the correlation coeffizient is : 0.256800\n",
      "evaluate 105\n",
      "the correlation coeffizient is : 0.450735\n",
      "evaluate 106\n",
      "the correlation coeffizient is : 0.390904\n",
      "evaluate 107\n",
      "the correlation coeffizient is : 0.358623\n",
      "evaluate 108\n",
      "the correlation coeffizient is : 0.479523\n",
      "evaluate 109\n",
      "the correlation coeffizient is : 0.561200\n",
      "evaluate 110\n",
      "the correlation coeffizient is : 0.320993\n",
      "evaluate 111\n",
      "the correlation coeffizient is : 0.460835\n",
      "evaluate 112\n",
      "the correlation coeffizient is : 0.537753\n",
      "evaluate 113\n",
      "the correlation coeffizient is : 0.423540\n",
      "evaluate 114\n",
      "the correlation coeffizient is : 0.590874\n",
      "evaluate 115\n",
      "the correlation coeffizient is : 0.353035\n",
      "evaluate 116\n",
      "the correlation coeffizient is : 0.492251\n",
      "evaluate 117\n",
      "the correlation coeffizient is : 0.432910\n",
      "evaluate 118\n",
      "the correlation coeffizient is : 0.573778\n",
      "evaluate 119\n",
      "the correlation coeffizient is : 0.473199\n",
      "evaluate 120\n",
      "the correlation coeffizient is : 0.429192\n",
      "evaluate 121\n",
      "the correlation coeffizient is : 0.490773\n",
      "evaluate 122\n",
      "the correlation coeffizient is : 0.522458\n",
      "evaluate 123\n",
      "the correlation coeffizient is : 0.414049\n",
      "evaluate 124\n",
      "the correlation coeffizient is : 0.391281\n",
      "evaluate 125\n",
      "the correlation coeffizient is : 0.425396\n",
      "evaluate 126\n",
      "the correlation coeffizient is : 0.292819\n",
      "evaluate 127\n",
      "the correlation coeffizient is : 0.565105\n",
      "evaluate 128\n",
      "the correlation coeffizient is : 0.498706\n",
      "evaluate 129\n",
      "the correlation coeffizient is : 0.490791\n",
      "evaluate 130\n",
      "the correlation coeffizient is : 0.471085\n",
      "evaluate 131\n",
      "the correlation coeffizient is : 0.513429\n",
      "evaluate 132\n",
      "the correlation coeffizient is : 0.501434\n",
      "evaluate 133\n",
      "the correlation coeffizient is : 0.409549\n",
      "evaluate 134\n",
      "the correlation coeffizient is : 0.427221\n",
      "evaluate 135\n",
      "the correlation coeffizient is : 0.458129\n",
      "evaluate 136\n",
      "the correlation coeffizient is : 0.533272\n",
      "evaluate 137\n",
      "the correlation coeffizient is : 0.526650\n",
      "evaluate 138\n",
      "the correlation coeffizient is : 0.479307\n",
      "evaluate 139\n",
      "the correlation coeffizient is : 0.401587\n",
      "evaluate 140\n",
      "the correlation coeffizient is : 0.357331\n",
      "evaluate 141\n",
      "the correlation coeffizient is : 0.421840\n",
      "evaluate 142\n",
      "the correlation coeffizient is : 0.457497\n",
      "evaluate 143\n",
      "the correlation coeffizient is : 0.598997\n",
      "evaluate 144\n",
      "the correlation coeffizient is : 0.579609\n",
      "evaluate 145\n",
      "the correlation coeffizient is : 0.512961\n",
      "evaluate 146\n",
      "the correlation coeffizient is : 0.459988\n",
      "evaluate 147\n",
      "the correlation coeffizient is : 0.558264\n",
      "evaluate 148\n",
      "the correlation coeffizient is : 0.501511\n",
      "evaluate 149\n",
      "the correlation coeffizient is : 0.550356\n",
      "evaluate 150\n",
      "the correlation coeffizient is : 0.582405\n",
      "evaluate 151\n",
      "the correlation coeffizient is : 0.632349\n",
      "evaluate 152\n",
      "the correlation coeffizient is : 0.610998\n",
      "evaluate 153\n",
      "the correlation coeffizient is : 0.519807\n",
      "evaluate 154\n",
      "the correlation coeffizient is : 0.354689\n",
      "evaluate 155\n",
      "the correlation coeffizient is : 0.559924\n",
      "evaluate 156\n",
      "the correlation coeffizient is : 0.594727\n",
      "evaluate 157\n",
      "the correlation coeffizient is : 0.474386\n",
      "evaluate 158\n",
      "the correlation coeffizient is : 0.414829\n",
      "evaluate 159\n",
      "the correlation coeffizient is : 0.387958\n",
      "evaluate 160\n",
      "the correlation coeffizient is : 0.552594\n",
      "evaluate 161\n",
      "the correlation coeffizient is : 0.488827\n",
      "evaluate 162\n",
      "the correlation coeffizient is : 0.635760\n",
      "evaluate 163\n",
      "the correlation coeffizient is : 0.560213\n",
      "evaluate 164\n",
      "the correlation coeffizient is : 0.459858\n",
      "evaluate 165\n",
      "the correlation coeffizient is : 0.439667\n",
      "evaluate 166\n",
      "the correlation coeffizient is : 0.535042\n",
      "evaluate 167\n",
      "the correlation coeffizient is : 0.576689\n",
      "evaluate 168\n",
      "the correlation coeffizient is : 0.567329\n",
      "evaluate 169\n",
      "the correlation coeffizient is : 0.671617\n",
      "evaluate 170\n",
      "the correlation coeffizient is : 0.545689\n",
      "evaluate 171\n",
      "the correlation coeffizient is : 0.625204\n",
      "evaluate 172\n",
      "the correlation coeffizient is : 0.502675\n",
      "evaluate 173\n",
      "the correlation coeffizient is : 0.552966\n",
      "evaluate 174\n",
      "the correlation coeffizient is : 0.562027\n",
      "evaluate 175\n",
      "the correlation coeffizient is : 0.405809\n",
      "evaluate 176\n",
      "the correlation coeffizient is : 0.528032\n",
      "evaluate 177\n",
      "the correlation coeffizient is : 0.505425\n",
      "evaluate 178\n",
      "the correlation coeffizient is : 0.460568\n",
      "evaluate 179\n",
      "the correlation coeffizient is : 0.601977\n",
      "evaluate 180\n",
      "the correlation coeffizient is : 0.694545\n",
      "evaluate 181\n",
      "the correlation coeffizient is : 0.681447\n",
      "evaluate 182\n",
      "the correlation coeffizient is : 0.546936\n",
      "evaluate 183\n",
      "the correlation coeffizient is : 0.648796\n",
      "evaluate 184\n",
      "the correlation coeffizient is : 0.585868\n",
      "evaluate 185\n",
      "the correlation coeffizient is : 0.504020\n",
      "evaluate 186\n",
      "the correlation coeffizient is : 0.565980\n",
      "evaluate 187\n",
      "the correlation coeffizient is : 0.593306\n",
      "evaluate 188\n",
      "the correlation coeffizient is : 0.529115\n",
      "evaluate 189\n",
      "the correlation coeffizient is : 0.618059\n",
      "evaluate 190\n",
      "the correlation coeffizient is : 0.508463\n",
      "evaluate 191\n",
      "the correlation coeffizient is : 0.530062\n",
      "evaluate 192\n",
      "the correlation coeffizient is : 0.515582\n",
      "evaluate 193\n",
      "the correlation coeffizient is : 0.625008\n",
      "evaluate 194\n",
      "the correlation coeffizient is : 0.630788\n",
      "evaluate 195\n",
      "the correlation coeffizient is : 0.531844\n",
      "evaluate 196\n",
      "the correlation coeffizient is : 0.692066\n",
      "evaluate 197\n",
      "the correlation coeffizient is : 0.506237\n",
      "evaluate 198\n",
      "the correlation coeffizient is : 0.619994\n",
      "evaluate 199\n",
      "the correlation coeffizient is : 0.621887\n",
      "evaluate 200\n",
      "the correlation coeffizient is : 0.415534\n",
      "evaluate 201\n",
      "the correlation coeffizient is : 0.584407\n",
      "evaluate 202\n",
      "the correlation coeffizient is : 0.558252\n",
      "evaluate 203\n",
      "the correlation coeffizient is : 0.566668\n",
      "evaluate 204\n",
      "the correlation coeffizient is : 0.487397\n",
      "evaluate 205\n",
      "the correlation coeffizient is : 0.503913\n",
      "evaluate 206\n",
      "the correlation coeffizient is : 0.689419\n",
      "evaluate 207\n",
      "the correlation coeffizient is : 0.475881\n",
      "evaluate 208\n",
      "the correlation coeffizient is : 0.686651\n",
      "evaluate 209\n",
      "the correlation coeffizient is : 0.583700\n",
      "evaluate 210\n",
      "the correlation coeffizient is : 0.614960\n",
      "evaluate 211\n",
      "the correlation coeffizient is : 0.550510\n",
      "evaluate 212\n",
      "the correlation coeffizient is : 0.624288\n",
      "evaluate 213\n",
      "the correlation coeffizient is : 0.617043\n",
      "evaluate 214\n",
      "the correlation coeffizient is : 0.579487\n",
      "evaluate 215\n",
      "the correlation coeffizient is : 0.561259\n",
      "evaluate 216\n",
      "the correlation coeffizient is : 0.546940\n",
      "evaluate 217\n",
      "the correlation coeffizient is : 0.609601\n",
      "evaluate 218\n",
      "the correlation coeffizient is : 0.608630\n",
      "evaluate 219\n",
      "the correlation coeffizient is : 0.646950\n",
      "evaluate 220\n",
      "the correlation coeffizient is : 0.529106\n",
      "evaluate 221\n",
      "the correlation coeffizient is : 0.666262\n",
      "evaluate 222\n",
      "the correlation coeffizient is : 0.660338\n",
      "evaluate 223\n",
      "the correlation coeffizient is : 0.543244\n",
      "evaluate 224\n",
      "the correlation coeffizient is : 0.642807\n",
      "evaluate 225\n",
      "the correlation coeffizient is : 0.519278\n",
      "evaluate 226\n",
      "the correlation coeffizient is : 0.697344\n",
      "evaluate 227\n",
      "the correlation coeffizient is : 0.704142\n",
      "evaluate 228\n",
      "the correlation coeffizient is : 0.549528\n",
      "evaluate 229\n",
      "the correlation coeffizient is : 0.462966\n",
      "evaluate 230\n",
      "the correlation coeffizient is : 0.605364\n",
      "evaluate 231\n",
      "the correlation coeffizient is : 0.632590\n",
      "evaluate 232\n",
      "the correlation coeffizient is : 0.698086\n",
      "evaluate 233\n",
      "the correlation coeffizient is : 0.549952\n",
      "evaluate 234\n",
      "the correlation coeffizient is : 0.697860\n",
      "evaluate 235\n",
      "the correlation coeffizient is : 0.658729\n",
      "evaluate 236\n",
      "the correlation coeffizient is : 0.508251\n",
      "evaluate 237\n",
      "the correlation coeffizient is : 0.624522\n",
      "evaluate 238\n",
      "the correlation coeffizient is : 0.562725\n",
      "evaluate 239\n",
      "the correlation coeffizient is : 0.629946\n",
      "evaluate 240\n",
      "the correlation coeffizient is : 0.515875\n",
      "evaluate 241\n",
      "the correlation coeffizient is : 0.621767\n",
      "evaluate 242\n",
      "the correlation coeffizient is : 0.537087\n",
      "evaluate 243\n",
      "the correlation coeffizient is : 0.523408\n",
      "evaluate 244\n",
      "the correlation coeffizient is : 0.638841\n",
      "evaluate 245\n",
      "the correlation coeffizient is : 0.633328\n",
      "evaluate 246\n",
      "the correlation coeffizient is : 0.589986\n",
      "evaluate 247\n",
      "the correlation coeffizient is : 0.599009\n",
      "evaluate 248\n",
      "the correlation coeffizient is : 0.654968\n",
      "evaluate 249\n",
      "the correlation coeffizient is : 0.636250\n",
      "evaluate 250\n",
      "the correlation coeffizient is : 0.549473\n",
      "evaluate 251\n",
      "the correlation coeffizient is : 0.409352\n",
      "evaluate 252\n",
      "the correlation coeffizient is : 0.630905\n",
      "evaluate 253\n",
      "the correlation coeffizient is : 0.510926\n",
      "evaluate 254\n",
      "the correlation coeffizient is : 0.606683\n",
      "evaluate 255\n",
      "the correlation coeffizient is : 0.557732\n",
      "evaluate 256\n",
      "the correlation coeffizient is : 0.656226\n",
      "evaluate 257\n",
      "the correlation coeffizient is : 0.496529\n",
      "evaluate 258\n",
      "the correlation coeffizient is : 0.584485\n",
      "evaluate 259\n",
      "the correlation coeffizient is : 0.639834\n",
      "evaluate 260\n",
      "the correlation coeffizient is : 0.586056\n",
      "evaluate 261\n",
      "the correlation coeffizient is : 0.606766\n",
      "evaluate 262\n",
      "the correlation coeffizient is : 0.606906\n",
      "evaluate 263\n",
      "the correlation coeffizient is : 0.556992\n",
      "evaluate 264\n",
      "the correlation coeffizient is : 0.680479\n",
      "evaluate 265\n",
      "the correlation coeffizient is : 0.700038\n",
      "evaluate 266\n",
      "the correlation coeffizient is : 0.657171\n",
      "evaluate 267\n",
      "the correlation coeffizient is : 0.705275\n",
      "evaluate 268\n",
      "the correlation coeffizient is : 0.600240\n",
      "evaluate 269\n",
      "the correlation coeffizient is : 0.742207\n",
      "evaluate 270\n",
      "the correlation coeffizient is : 0.643428\n",
      "evaluate 271\n",
      "the correlation coeffizient is : 0.737635\n",
      "evaluate 272\n",
      "the correlation coeffizient is : 0.620906\n",
      "evaluate 273\n",
      "the correlation coeffizient is : 0.655629\n",
      "evaluate 274\n",
      "the correlation coeffizient is : 0.625168\n",
      "evaluate 275\n",
      "the correlation coeffizient is : 0.600563\n",
      "evaluate 276\n",
      "the correlation coeffizient is : 0.540483\n",
      "evaluate 277\n",
      "the correlation coeffizient is : 0.631431\n",
      "evaluate 278\n",
      "the correlation coeffizient is : 0.692480\n",
      "evaluate 279\n",
      "the correlation coeffizient is : 0.671915\n",
      "evaluate 280\n",
      "the correlation coeffizient is : 0.639972\n",
      "evaluate 281\n",
      "the correlation coeffizient is : 0.688553\n",
      "evaluate 282\n",
      "the correlation coeffizient is : 0.583651\n",
      "evaluate 283\n",
      "the correlation coeffizient is : 0.608042\n",
      "evaluate 284\n",
      "the correlation coeffizient is : 0.502218\n",
      "evaluate 285\n",
      "the correlation coeffizient is : 0.622677\n",
      "evaluate 286\n",
      "the correlation coeffizient is : 0.713289\n",
      "evaluate 287\n",
      "the correlation coeffizient is : 0.671436\n",
      "evaluate 288\n",
      "the correlation coeffizient is : 0.611564\n",
      "evaluate 289\n",
      "the correlation coeffizient is : 0.677548\n",
      "evaluate 290\n",
      "the correlation coeffizient is : 0.615300\n",
      "evaluate 291\n",
      "the correlation coeffizient is : 0.634131\n",
      "evaluate 292\n",
      "the correlation coeffizient is : 0.629938\n",
      "evaluate 293\n",
      "the correlation coeffizient is : 0.453269\n",
      "evaluate 294\n",
      "the correlation coeffizient is : 0.545067\n",
      "evaluate 295\n",
      "the correlation coeffizient is : 0.730534\n",
      "evaluate 296\n",
      "the correlation coeffizient is : 0.636465\n",
      "evaluate 297\n",
      "the correlation coeffizient is : 0.667462\n",
      "evaluate 298\n",
      "the correlation coeffizient is : 0.727531\n",
      "evaluate 299\n",
      "the correlation coeffizient is : 0.668268\n",
      "evaluate 300\n",
      "the correlation coeffizient is : 0.641608\n",
      "evaluate 301\n",
      "the correlation coeffizient is : 0.580967\n",
      "evaluate 302\n",
      "the correlation coeffizient is : 0.637491\n",
      "evaluate 303\n",
      "the correlation coeffizient is : 0.667633\n",
      "evaluate 304\n",
      "the correlation coeffizient is : 0.647755\n",
      "evaluate 305\n",
      "the correlation coeffizient is : 0.588573\n",
      "evaluate 306\n",
      "the correlation coeffizient is : 0.682129\n",
      "evaluate 307\n",
      "the correlation coeffizient is : 0.697250\n",
      "evaluate 308\n",
      "the correlation coeffizient is : 0.683484\n",
      "evaluate 309\n",
      "the correlation coeffizient is : 0.637923\n",
      "evaluate 310\n",
      "the correlation coeffizient is : 0.683422\n",
      "evaluate 311\n",
      "the correlation coeffizient is : 0.697782\n",
      "evaluate 312\n",
      "the correlation coeffizient is : 0.685246\n",
      "evaluate 313\n",
      "the correlation coeffizient is : 0.611488\n",
      "evaluate 314\n",
      "the correlation coeffizient is : 0.554561\n",
      "evaluate 315\n",
      "the correlation coeffizient is : 0.721646\n",
      "evaluate 316\n",
      "the correlation coeffizient is : 0.632658\n",
      "evaluate 317\n",
      "the correlation coeffizient is : 0.713073\n",
      "evaluate 318\n",
      "the correlation coeffizient is : 0.591906\n",
      "evaluate 319\n",
      "the correlation coeffizient is : 0.700998\n",
      "evaluate 320\n",
      "the correlation coeffizient is : 0.640411\n",
      "evaluate 321\n",
      "the correlation coeffizient is : 0.647599\n",
      "evaluate 322\n",
      "the correlation coeffizient is : 0.716420\n",
      "evaluate 323\n",
      "the correlation coeffizient is : 0.641694\n",
      "evaluate 324\n",
      "the correlation coeffizient is : 0.681650\n",
      "evaluate 325\n",
      "the correlation coeffizient is : 0.624920\n",
      "evaluate 326\n",
      "the correlation coeffizient is : 0.742583\n",
      "evaluate 327\n",
      "the correlation coeffizient is : 0.629878\n",
      "evaluate 328\n",
      "the correlation coeffizient is : 0.670547\n",
      "evaluate 329\n",
      "the correlation coeffizient is : 0.639435\n",
      "evaluate 330\n",
      "the correlation coeffizient is : 0.641888\n",
      "evaluate 331\n",
      "the correlation coeffizient is : 0.525020\n",
      "evaluate 332\n",
      "the correlation coeffizient is : 0.551960\n",
      "evaluate 333\n",
      "the correlation coeffizient is : 0.556288\n",
      "evaluate 334\n",
      "the correlation coeffizient is : 0.534393\n",
      "evaluate 335\n",
      "the correlation coeffizient is : 0.562877\n",
      "evaluate 336\n",
      "the correlation coeffizient is : 0.742544\n",
      "evaluate 337\n",
      "the correlation coeffizient is : 0.632131\n",
      "evaluate 338\n",
      "the correlation coeffizient is : 0.672972\n",
      "evaluate 339\n",
      "the correlation coeffizient is : 0.647483\n",
      "evaluate 340\n",
      "the correlation coeffizient is : 0.644801\n",
      "evaluate 341\n",
      "the correlation coeffizient is : 0.563834\n",
      "evaluate 342\n",
      "the correlation coeffizient is : 0.623555\n",
      "evaluate 343\n",
      "the correlation coeffizient is : 0.594975\n"
     ]
    }
   ],
   "source": [
    "fmin.o_func(pas1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = getattr(torch.nn, 'ReLU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = torch.nn.ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.activation.ReLU"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "DuplicateLabel",
     "evalue": "linear_act_func",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDuplicateLabel\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f0aeffc33b9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfmin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ihuangyiran/Documents/Workplace_Python/MasterArbeit/fmin.pyc\u001b[0m in \u001b[0;36mget_best\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mli_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim_algo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             max_evals = 500)\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ihuangyiran/anaconda2/envs/py27/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     domain = base.Domain(fn, space,\n\u001b[0;32m--> 314\u001b[0;31m                          pass_expr_memo_ctrl=pass_expr_memo_ctrl)\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     rval = FMinIter(algo, domain, trials, max_evals=max_evals,\n",
      "\u001b[0;32m/Users/ihuangyiran/anaconda2/envs/py27/lib/python2.7/site-packages/hyperopt/base.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fn, expr, workdir, pass_expr_memo_ctrl, name, loss_target)\u001b[0m\n\u001b[1;32m    774\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mDuplicateLabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'obj'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDuplicateLabel\u001b[0m: linear_act_func"
     ]
    }
   ],
   "source": [
    "fmin.get_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32/10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "x = float('nan')\n",
    "math.isnan(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## normalize scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.70434875861064,\n",
       " 1.12727142153235,\n",
       " -0.872401325076093,\n",
       " -0.520636691467046,\n",
       " 0.0293189192586597,\n",
       " -1.67083618888355,\n",
       " -1.54107458193584,\n",
       " -1.26716970413938,\n",
       " 1.14801144278375,\n",
       " -0.126473141789861,\n",
       " 1.08998382718802,\n",
       " -1.45083864991872,\n",
       " -1.30334660957726,\n",
       " 0.909684951356344,\n",
       " -0.865310032116374,\n",
       " -1.04805674497439,\n",
       " 1.03362830429051,\n",
       " -1.30334660957726,\n",
       " 0.473968273650239,\n",
       " 0.0655234422069162,\n",
       " -2.31501818674212,\n",
       " -1.30040055102541,\n",
       " -1.26443616430169,\n",
       " 1.24609931070437,\n",
       " 0.0048710057016938,\n",
       " 0.339556020247105,\n",
       " -0.553215740838215,\n",
       " -0.284941429727458,\n",
       " -0.740862210579549,\n",
       " -1.44105725859061,\n",
       " -0.264247987380428,\n",
       " 0.0386786043300455,\n",
       " 0.71831182779596,\n",
       " -1.26443616430169,\n",
       " 1.10910099750817,\n",
       " 0.0686014628819244,\n",
       " 1.11418127557441,\n",
       " 0.253071201445601,\n",
       " 0.419182111938213,\n",
       " -1.80918239815969,\n",
       " -0.229408504480094,\n",
       " -0.123356240182688,\n",
       " -0.0496745081911503,\n",
       " 1.22217430718766,\n",
       " -1.1248553785731,\n",
       " -0.985337863893415,\n",
       " -1.15989655423098,\n",
       " -0.0139082445291922,\n",
       " -1.54107458193584,\n",
       " -0.434365786127364,\n",
       " 0.564354763650173,\n",
       " -0.625664260181483,\n",
       " 0.00479229747097395,\n",
       " -1.00060178914239,\n",
       " -0.541165306892952,\n",
       " 1.37707956533788,\n",
       " 1.19092537160453,\n",
       " 1.12500429027107,\n",
       " -0.0269699547415003,\n",
       " 0.439961524610728,\n",
       " 1.16851268433334,\n",
       " 1.15399058740957,\n",
       " 0.0196085297921715,\n",
       " -2.00803966495828,\n",
       " -0.779261527378905,\n",
       " -1.80242807284352,\n",
       " -0.637772075862252,\n",
       " 1.24475737737332,\n",
       " -1.34225705485283,\n",
       " 0.37271797660176,\n",
       " 0.330892091996744,\n",
       " 0.955074894851372,\n",
       " 1.13791095964253,\n",
       " -2.09778641339656,\n",
       " -0.823820570438701,\n",
       " 1.16851268433334,\n",
       " -0.500696803050913,\n",
       " 0.384805693494673,\n",
       " -0.932247035025456,\n",
       " 1.24475737737332,\n",
       " -1.26868535215846,\n",
       " 0.0788671043790961,\n",
       " -0.27777460080266,\n",
       " -0.397358539254111,\n",
       " -0.602958594616973,\n",
       " 1.12727142153235,\n",
       " -2.03295160375887,\n",
       " 0.347025990290812,\n",
       " -1.57571972650626,\n",
       " -1.30219792188555,\n",
       " 0.993248980926827,\n",
       " -1.90283357720715,\n",
       " 1.21000101759139,\n",
       " -0.379648013438239,\n",
       " -0.992027214946222,\n",
       " -1.02774905479782,\n",
       " -0.486227258790259,\n",
       " 0.719043156989968,\n",
       " -1.80918239815969,\n",
       " -2.00373462453755,\n",
       " -0.0582123607589716,\n",
       " 0.972182822522608,\n",
       " 0.382861811868042,\n",
       " 1.16851268433334,\n",
       " -0.447165611587295,\n",
       " 0.674241034792515,\n",
       " -0.866534515433376,\n",
       " -0.0287202722561164,\n",
       " -1.27105218589777,\n",
       " -0.123356240182688,\n",
       " -0.856060160977616,\n",
       " -0.430871108981201,\n",
       " 0.443748066717318,\n",
       " 0.23927090856685,\n",
       " 0.778513503941099,\n",
       " 1.31592111393706,\n",
       " -0.75860037571926,\n",
       " -2.06453839447977,\n",
       " 1.33820803399917,\n",
       " -0.482802158719479,\n",
       " 0.20779127437812,\n",
       " -0.173912076323135,\n",
       " 0.343579268244777,\n",
       " 0.994257260766243,\n",
       " 0.00479229747097395,\n",
       " -0.444034451401381,\n",
       " -0.548865626582772,\n",
       " -1.00060178914239,\n",
       " 0.0271241254075607,\n",
       " -0.281845171077426,\n",
       " -0.695735501030716,\n",
       " 0.690942402274422,\n",
       " -0.252764587136829,\n",
       " -1.80918239815969,\n",
       " 0.751045204576369,\n",
       " -0.63848432233684,\n",
       " 0.262822929695734,\n",
       " -1.20165401217182,\n",
       " -1.08645606177375,\n",
       " -0.291675032412401,\n",
       " -1.94336634123875,\n",
       " 1.10910099750817,\n",
       " 0.943144249829505,\n",
       " -1.70434875861064,\n",
       " -1.67083618888355,\n",
       " 0.756711144595315,\n",
       " -0.847686178890694,\n",
       " -0.0590320517207384,\n",
       " 1.06188186411476,\n",
       " 0.449516610200471,\n",
       " -2.08483829855699,\n",
       " 0.461460279450232,\n",
       " -0.537212341742857,\n",
       " 0.607304031883433,\n",
       " 0.0112417995560491,\n",
       " -2.56555146682984,\n",
       " 0.439961524610728,\n",
       " -0.260215120221697,\n",
       " 0.23915411187824,\n",
       " 0.0585189750677431,\n",
       " 0.994279345865177,\n",
       " -0.00359956318197308,\n",
       " -1.33519147480243,\n",
       " -0.397358539254111,\n",
       " 0.439961524610728,\n",
       " -0.429989807649004,\n",
       " 1.24320555951971,\n",
       " -0.496517149884582,\n",
       " -0.599201778713575,\n",
       " 0.26029264897955,\n",
       " 0.989797466710602,\n",
       " 0.50373844696225,\n",
       " -1.73786132833773,\n",
       " 0.597195595525027,\n",
       " -1.92591373398641,\n",
       " 1.10910099750817,\n",
       " 1.13808643198301,\n",
       " -2.08155551508869,\n",
       " -0.75860037571926,\n",
       " -1.05899799038095,\n",
       " 0.339556020247105,\n",
       " 0.439961524610728,\n",
       " 0.334625776914176,\n",
       " 0.953459216405889,\n",
       " -0.0448634541906483,\n",
       " -0.535467414373893,\n",
       " 1.10933155370155,\n",
       " -0.52513770406583,\n",
       " 1.11438695101786,\n",
       " 0.842606540648234,\n",
       " -1.26868535215846,\n",
       " -1.28276570388248,\n",
       " -1.80327153195803,\n",
       " 0.876119110375324,\n",
       " 0.422144355491307,\n",
       " -0.746508634549636,\n",
       " -1.75756247178124,\n",
       " 0.473968273650239,\n",
       " 1.10933155370155,\n",
       " -0.510937573326197,\n",
       " 1.27826994710041,\n",
       " 0.185662513653259,\n",
       " -0.0582123607589716,\n",
       " -0.486227258790259,\n",
       " -1.75756247178124,\n",
       " 1.27667406097425,\n",
       " -1.59466782113548,\n",
       " 0.262822929695734,\n",
       " -1.70434875861064,\n",
       " 0.989797466710602,\n",
       " -0.295087858940278,\n",
       " 1.0701905522326,\n",
       " 0.719996544752459,\n",
       " -1.77027195288412,\n",
       " -0.781053698110154,\n",
       " 0.598727039920146,\n",
       " 1.27405959353085,\n",
       " -0.564093519025504,\n",
       " 0.642175654201316,\n",
       " -0.564048149341402,\n",
       " 1.0701905522326,\n",
       " -0.341824903278122,\n",
       " -1.96482417926198,\n",
       " 1.28467217835392,\n",
       " 0.706598918332718,\n",
       " 0.579274529984365,\n",
       " -0.102207934526366,\n",
       " 0.900709118925694,\n",
       " -0.376135420884919,\n",
       " 1.40949953018436,\n",
       " 0.926520122082437,\n",
       " -0.379685237733824,\n",
       " 0.634684332724337,\n",
       " 0.497609811563913,\n",
       " 0.0383048671980643,\n",
       " 0.829239603209405,\n",
       " 0.564354763650173,\n",
       " 0.48653387309903,\n",
       " -0.971258111375682,\n",
       " 0.23927090856685,\n",
       " 0.253071201445601,\n",
       " -0.581544630256631,\n",
       " -0.535129524307294,\n",
       " -1.4027362817954,\n",
       " -0.164872458589217,\n",
       " -0.953152602097117,\n",
       " 0.408712982547887,\n",
       " -0.213854141861258,\n",
       " -0.733801051217404,\n",
       " -1.48333542610263,\n",
       " -0.783441247075023,\n",
       " 0.641513194197249,\n",
       " 0.972099966217012,\n",
       " -1.46774305829811,\n",
       " 0.175250310894458,\n",
       " -1.22552571902612,\n",
       " -1.4027362817954,\n",
       " 0.419182111938213,\n",
       " -1.23285982636747,\n",
       " 0.265014180998248,\n",
       " 1.07403731052786,\n",
       " -0.460406660165596,\n",
       " -1.17071299050689,\n",
       " 0.755948714560977,\n",
       " -0.992063047372689,\n",
       " 1.0701905522326,\n",
       " 0.313082023708868,\n",
       " 1.03362830429051,\n",
       " -1.09024692596408,\n",
       " -1.99067343624685,\n",
       " 1.28191560319977,\n",
       " 0.968798289594455,\n",
       " -1.80918239815969,\n",
       " 0.855357038545309,\n",
       " -1.4328260350607,\n",
       " -0.596075155191685,\n",
       " 1.13808643198301,\n",
       " 0.814969791723953,\n",
       " -1.14770482847498,\n",
       " -0.246525665219529,\n",
       " 0.369802537272315,\n",
       " 0.0585189750677431,\n",
       " -1.12623472156049,\n",
       " -0.00996362436460503,\n",
       " 1.40949953018436,\n",
       " -0.779261527378905,\n",
       " 0.296070948612527,\n",
       " -0.216896895197801,\n",
       " 1.06281053932284,\n",
       " 0.28470623969371,\n",
       " -0.932858794576327,\n",
       " 0.978296273700086,\n",
       " 1.31592111393706,\n",
       " -2.12268477597773,\n",
       " -1.19999504666178,\n",
       " 1.10212913917881,\n",
       " -1.62317166694938,\n",
       " -0.717049409583369,\n",
       " 1.10230499578951,\n",
       " 0.0300867972781843,\n",
       " -0.0193019154834,\n",
       " -1.14685515734813,\n",
       " -2.19614552194098,\n",
       " -1.02571718725709,\n",
       " 0.978296273700086,\n",
       " -2.08155551508869,\n",
       " -0.430871108981201,\n",
       " -0.0150395288217961,\n",
       " 1.06077538369876,\n",
       " -1.30219792188555,\n",
       " 0.528581349166527,\n",
       " -0.992027214946222,\n",
       " -2.36691624176049,\n",
       " -1.14770482847498,\n",
       " 1.14801144278375,\n",
       " 0.876119110375324,\n",
       " -1.1087943831994,\n",
       " 1.27826994710041,\n",
       " 0.304296724621513,\n",
       " -1.55189857268501,\n",
       " 0.179978776659988,\n",
       " 0.440455703923149,\n",
       " 0.175250310894458,\n",
       " -0.621512892217109,\n",
       " 0.540367028974351,\n",
       " -1.26868535215846,\n",
       " -0.329814008843717,\n",
       " 0.0468204923308349,\n",
       " -1.30516983311103,\n",
       " -0.0696572594721942,\n",
       " -2.31501818674212,\n",
       " 0.0718174369251547,\n",
       " 0.875638325854746,\n",
       " -0.63848432233684,\n",
       " 0.0718174369251547,\n",
       " 1.31592111393706,\n",
       " 0.11459886653771,\n",
       " -0.900350648128308,\n",
       " 0.979734698812601,\n",
       " -0.0112751913917948,\n",
       " 0.0300867972781843,\n",
       " -0.379685237733824,\n",
       " 0.791352364108435,\n",
       " 0.657839617230895,\n",
       " 0.408712982547887,\n",
       " 0.495559062113284,\n",
       " 0.00479229747097395,\n",
       " 0.907023179435717,\n",
       " -1.46700226365005,\n",
       " 0.875638325854746,\n",
       " 1.05066505346354,\n",
       " -1.05899799038095,\n",
       " -1.20774914964979,\n",
       " 0.48653387309903,\n",
       " 0.603265208925745,\n",
       " 0.291981646721172,\n",
       " 0.758394347826551,\n",
       " 1.12727142153235,\n",
       " -1.43204991296795,\n",
       " 0.607304031883433,\n",
       " 0.544922191177836,\n",
       " -0.09699274989249,\n",
       " 1.13929835840446,\n",
       " -0.48427166364237,\n",
       " -0.172712233230048,\n",
       " 0.163078872945356,\n",
       " 1.16851268433334,\n",
       " 0.755948714560977,\n",
       " -0.637772075862252,\n",
       " 0.180721392604983,\n",
       " 1.12084246222882,\n",
       " 1.27590424447258,\n",
       " 0.14098017266066,\n",
       " -0.581544630256631,\n",
       " 0.534697724358764,\n",
       " 0.926520122082437,\n",
       " -1.35650092356657,\n",
       " -1.18502879913206,\n",
       " -2.12046596036426,\n",
       " -0.797510820994831,\n",
       " 0.376903944426195,\n",
       " -1.10987484581602,\n",
       " 0.253071201445601,\n",
       " 0.0718174369251547,\n",
       " -1.26868535215846,\n",
       " -1.23346354811633,\n",
       " -0.402789060597252,\n",
       " -0.218130719983525,\n",
       " 0.334625776914176,\n",
       " 1.14801144278375,\n",
       " 1.04302389002484,\n",
       " -1.33386905247995,\n",
       " -1.16325469537246,\n",
       " -1.30334660957726,\n",
       " -0.344545128191809,\n",
       " 0.23927090856685,\n",
       " -1.42413519480213,\n",
       " 1.0701905522326,\n",
       " -1.07059230219275,\n",
       " -1.4704492297673,\n",
       " 1.04468167218798,\n",
       " -1.34074852588581,\n",
       " 0.607304031883433,\n",
       " 0.872111010835791,\n",
       " 0.800113538039163,\n",
       " -0.190769976503235,\n",
       " -1.4324833364275,\n",
       " 0.451707688042341,\n",
       " -1.30700947870196,\n",
       " 0.914548771130317,\n",
       " -0.481354147843781,\n",
       " -1.73786132833773,\n",
       " -0.121529922887002,\n",
       " 0.468317777199008,\n",
       " 1.4059348392863,\n",
       " 0.0585189750677431,\n",
       " 1.05066505346354,\n",
       " -0.291675032412401,\n",
       " 0.540367028974351,\n",
       " -1.15989655423098,\n",
       " 0.136339865618886,\n",
       " -0.652761827800241,\n",
       " 1.12727142153235,\n",
       " 1.03128010695703,\n",
       " -1.1087943831994,\n",
       " -0.559919235090311,\n",
       " 0.406493023156187,\n",
       " -2.24434244131896,\n",
       " 0.875638325854746,\n",
       " 1.31592111393706,\n",
       " -0.0112751913917948,\n",
       " -0.866534515433376,\n",
       " -0.833021945706286,\n",
       " -1.09958954229816,\n",
       " -1.18723448071181,\n",
       " -0.430871108981201,\n",
       " -1.3763272186606,\n",
       " 1.40949953018436,\n",
       " 1.16851268433334,\n",
       " -1.26799312743916,\n",
       " -0.953152602097117,\n",
       " -0.246525665219529,\n",
       " 0.829759829702995,\n",
       " 1.01138250984028,\n",
       " 0.603113877397893,\n",
       " -1.86383893371079,\n",
       " -1.62317166694938,\n",
       " 0.180721392604983,\n",
       " 0.884241954570418,\n",
       " 0.719996544752459,\n",
       " 1.02921009516021,\n",
       " -0.0908001402654495,\n",
       " -2.19828685091541,\n",
       " -1.73786132833773,\n",
       " -1.23695139427351,\n",
       " 0.367028727303907,\n",
       " -0.296345507389176,\n",
       " 0.926520122082437,\n",
       " -0.304619423058557,\n",
       " 0.961031326948384,\n",
       " -0.397358539254111,\n",
       " 0.495914170923356,\n",
       " 0.41403413162775,\n",
       " -1.99583308993905,\n",
       " 0.922342675157862,\n",
       " 1.09563279213051,\n",
       " -0.63398929618739,\n",
       " 1.15937063285942,\n",
       " 1.38478199035282,\n",
       " -1.02571718725709,\n",
       " 0.914548771130317,\n",
       " -0.833021945706286,\n",
       " -0.904579217166058,\n",
       " 0.690942402274422,\n",
       " -0.631030521934587,\n",
       " 0.681086099476888,\n",
       " -0.0850246435223168,\n",
       " 0.291981646721172,\n",
       " 0.525444318374602,\n",
       " 0.418940575899193,\n",
       " 0.756711144595315,\n",
       " 0.876119110375324,\n",
       " -1.30334660957726,\n",
       " -1.09958954229816,\n",
       " 0.670641625528527,\n",
       " 0.700639537036547,\n",
       " -0.865310032116374,\n",
       " 1.01290466180783,\n",
       " 1.06281053932284,\n",
       " -2.45573327887905,\n",
       " 0.577192147961468,\n",
       " -1.40935238415628,\n",
       " 0.989797466710602,\n",
       " -1.08862345996662,\n",
       " -0.88169378228938,\n",
       " 0.681086099476888,\n",
       " -0.631030521934587,\n",
       " -1.38485265117887,\n",
       " 1.47720793355067,\n",
       " -2.15959033354874,\n",
       " -1.59466782113548,\n",
       " 1.0701905522326,\n",
       " -1.59022989529419,\n",
       " -1.62054791291846,\n",
       " 0.0783099145510313,\n",
       " 0.37271797660176,\n",
       " 0.608326484276941,\n",
       " 0.586294255246056,\n",
       " 0.741178037701597,\n",
       " -1.7020225684799,\n",
       " 0.515021160981687,\n",
       " -1.21524266829661,\n",
       " -1.18738825351849,\n",
       " -0.356869042585994,\n",
       " -1.26700502030908,\n",
       " 0.910308411792737,\n",
       " 0.71831182779596,\n",
       " -0.677766865960105,\n",
       " -1.22966642103051,\n",
       " -0.746331126250924,\n",
       " -0.252764587136829,\n",
       " -1.68921921850741,\n",
       " 0.977384239780983,\n",
       " 1.37707956533788,\n",
       " -1.67083618888355,\n",
       " 0.86318702926281,\n",
       " 0.585925829502245,\n",
       " 0.291981646721172,\n",
       " 0.165513106866101,\n",
       " 0.272619017338022,\n",
       " -1.54724786336601,\n",
       " -0.340255970190741,\n",
       " -0.971258111375682,\n",
       " -1.18723448071181,\n",
       " -1.1330580437527,\n",
       " 0.525444318374602,\n",
       " 0.920352322992141,\n",
       " -0.434019278718319,\n",
       " 0.0870105983706088,\n",
       " 0.219120709404338,\n",
       " -0.246525665219529,\n",
       " 0.875638325854746,\n",
       " 1.1740437247872,\n",
       " 0.586294255246056,\n",
       " 0.483313793502665,\n",
       " 0.0885164203515176,\n",
       " 0.500709442737836,\n",
       " -0.241671092187928,\n",
       " -0.548865626582772,\n",
       " 0.107884006505189,\n",
       " -1.80897244437611,\n",
       " -0.0885287116111344,\n",
       " 0.291981646721172,\n",
       " 0.961031326948384,\n",
       " -0.195940003025553,\n",
       " -0.823820570438701,\n",
       " 1.72007680147304,\n",
       " -1.26700502030908,\n",
       " 1.15937063285942,\n",
       " 0.214160756170029,\n",
       " 0.603265208925745,\n",
       " 1.22246729466657,\n",
       " -1.23116964849535,\n",
       " -1.36733755393449,\n",
       " 0.229574910778941,\n",
       " 0.334318659802405,\n",
       " -0.779261527378905,\n",
       " 1.3101425624288,\n",
       " 0.99236966168146,\n",
       " -0.284648153582344,\n",
       " -0.0492461679878697,\n",
       " -0.136033251310115,\n",
       " -1.63732361915646,\n",
       " -0.75860037571926,\n",
       " 0.972182822522608,\n",
       " -1.66855406702536,\n",
       " -0.0458777306939917,\n",
       " -1.30628756393234,\n",
       " -1.65218305936452,\n",
       " 0.987107045391448,\n",
       " -1.03384980805919,\n",
       " -0.63848432233684,\n",
       " -1.65983045654172,\n",
       " -0.790341698554976,\n",
       " 0.382983283095002,\n",
       " 1.0255063621908,\n",
       " 0.92999271151655,\n",
       " 0.292347609402157,\n",
       " -1.87440001422189,\n",
       " 0.23927090856685,\n",
       " -1.77027195288412,\n",
       " -1.43398521737853,\n",
       " 1.12923014071007,\n",
       " -0.397358539254111,\n",
       " 1.02752736478197,\n",
       " 0.00479229747097395,\n",
       " 1.06617184637462,\n",
       " -1.42007794540398,\n",
       " 1.16851268433334,\n",
       " 0.876119110375324,\n",
       " 1.40949953018436,\n",
       " -1.70434875861064,\n",
       " 0.291981646721172,\n",
       " 0.330892091996744,\n",
       " 1.09563279213051,\n",
       " -1.05899799038095,\n",
       " 0.419182111938213,\n",
       " 0.382861811868042,\n",
       " 0.473430026065269,\n",
       " -1.00965742817504,\n",
       " -0.52513770406583,\n",
       " 0.564354763650173,\n",
       " 0.214160756170029,\n",
       " 0.23915411187824,\n",
       " -1.52561359361464,\n",
       " -1.14770482847498,\n",
       " -0.258510043347204,\n",
       " 1.18692188805932,\n",
       " -0.0599155859935225,\n",
       " 0.225900885807531,\n",
       " 0.473968273650239,\n",
       " 0.257520026203694,\n",
       " -1.65272776646046,\n",
       " 1.40949953018436,\n",
       " 0.439592583267062,\n",
       " -1.77767808741152,\n",
       " 0.701947740974723,\n",
       " 0.932817422593748,\n",
       " 0.763375274232797,\n",
       " 0.330892091996744,\n",
       " -0.0285974957528473,\n",
       " 0.30120187818858,\n",
       " -0.559919235090311,\n",
       " -0.257268568254085,\n",
       " -1.34225705485283,\n",
       " -0.856060160977616,\n",
       " -0.992063047372689,\n",
       " -1.03097349264826,\n",
       " -0.402789060597252,\n",
       " -0.564048149341402,\n",
       " -1.14770482847498,\n",
       " 0.411117293401116,\n",
       " 0.272619017338022,\n",
       " -1.2355846352725,\n",
       " 0.0783099145510313,\n",
       " 0.331646285081327,\n",
       " 0.373024521701646,\n",
       " -2.27610774146655,\n",
       " -1.70434875861064,\n",
       " 1.16851268433334,\n",
       " 0.525444318374602,\n",
       " 1.16256503549545,\n",
       " -0.779261527378905,\n",
       " 1.0255063621908,\n",
       " -0.304619423058557,\n",
       " -0.174943696585686,\n",
       " -0.932247035025456,\n",
       " -0.0885287116111344,\n",
       " 0.222208368527447,\n",
       " 1.34930179720262,\n",
       " -0.932858794576327,\n",
       " -1.09773497636255,\n",
       " -0.430871108981201,\n",
       " -0.81766084417826,\n",
       " 1.08994759708681,\n",
       " -1.70434875861064,\n",
       " 0.621594397640184,\n",
       " -0.262877005934635,\n",
       " 0.913092906777817,\n",
       " -0.992063047372689,\n",
       " 0.813281151747804,\n",
       " 0.909684951356344,\n",
       " 0.0196085297921715,\n",
       " -1.77767808741152,\n",
       " -1.98116499583196,\n",
       " 1.12923014071007,\n",
       " 1.28467217835392,\n",
       " -0.299546735766103,\n",
       " 0.147166550128454,\n",
       " 0.707709536247056,\n",
       " -0.00996362436460503,\n",
       " 0.972182822522608,\n",
       " 0.719996544752459,\n",
       " 0.221082543490581,\n",
       " 0.573835530428892,\n",
       " 0.349987581279877,\n",
       " 1.12727142153235,\n",
       " 0.071808008610776,\n",
       " -1.56814856266174,\n",
       " -1.65354061705741,\n",
       " 1.16851268433334,\n",
       " -0.999184037934538,\n",
       " -0.130434065718029,\n",
       " 0.876119110375324,\n",
       " 0.292347609402157,\n",
       " 1.23783376309809,\n",
       " 0.429063024279698,\n",
       " 0.105276510065317,\n",
       " 1.33466174502193,\n",
       " -1.06988393792383,\n",
       " -0.702462893780194,\n",
       " 0.304296724621513,\n",
       " 1.0701905522326,\n",
       " -1.77767808741152,\n",
       " 1.40949953018436,\n",
       " -1.06612104084362,\n",
       " 0.861287270198005,\n",
       " 0.473968273650239,\n",
       " -0.719689930443688,\n",
       " -1.99019804198158,\n",
       " -1.14511008600648,\n",
       " -0.274241375533518,\n",
       " -0.910440724305693,\n",
       " 1.51818018465465,\n",
       " -1.49932207289429,\n",
       " -0.548865626582772,\n",
       " -0.894459477776971,\n",
       " -0.481354147843781,\n",
       " -0.341824903278122,\n",
       " -0.568377543224087,\n",
       " -1.40473269744839,\n",
       " -0.43021951320734,\n",
       " -1.35525127936924,\n",
       " -0.689242921649265,\n",
       " -0.308296499795993,\n",
       " -0.0162341031651332,\n",
       " 0.842606540648234,\n",
       " 1.16851268433334,\n",
       " 0.607304031883433,\n",
       " -1.97409080552784,\n",
       " -0.43021951320734,\n",
       " -0.206376342480928,\n",
       " -2.66712411643915,\n",
       " -0.430871108981201,\n",
       " 0.257520026203694,\n",
       " 1.05335462461849,\n",
       " -0.515949037009763,\n",
       " -0.218130719983525,\n",
       " -1.26799312743916,\n",
       " -1.22076013144799,\n",
       " 1.67969747810936,\n",
       " 1.07403731052786,\n",
       " 0.418940575899193,\n",
       " 0.09658283511177,\n",
       " -0.268982875926372,\n",
       " -1.70084513056344,\n",
       " 1.06281053932284,\n",
       " -0.834897040453163,\n",
       " -0.0620659972073883,\n",
       " 1.37707956533788,\n",
       " 1.09402340261556,\n",
       " -1.26680619562754,\n",
       " -1.46774305829811,\n",
       " -1.30040055102541,\n",
       " 0.884241954570418,\n",
       " 1.24475737737332,\n",
       " 0.993248980926827,\n",
       " -1.30219792188555,\n",
       " -1.67083618888355,\n",
       " -0.39526835938535,\n",
       " 0.681086099476888,\n",
       " 1.10910099750817,\n",
       " 1.24475737737332,\n",
       " 0.962998784292824,\n",
       " -0.719689930443688,\n",
       " 0.0655234422069162,\n",
       " -0.833021945706286,\n",
       " -1.27194458854253,\n",
       " 0.841583542065221,\n",
       " -0.482802158719479,\n",
       " -1.80897244437611,\n",
       " -0.0492461679878697,\n",
       " 0.914548771130317,\n",
       " 0.962998784292824,\n",
       " 0.0655234422069162,\n",
       " -0.641869039892545,\n",
       " 0.395815005362906,\n",
       " 0.993248980926827,\n",
       " -0.697967524843669,\n",
       " -0.09699274989249,\n",
       " -1.51626202555283,\n",
       " -0.369495922963544,\n",
       " -2.58256778141511,\n",
       " -1.66855406702536,\n",
       " 0.565946659941896,\n",
       " -0.831137946148934,\n",
       " 1.0701905522326,\n",
       " 0.447623427823459,\n",
       " -1.23346354811633,\n",
       " -0.284941429727458,\n",
       " -1.22966642103051,\n",
       " -0.184027794053265,\n",
       " 0.814969791723953,\n",
       " 0.884241954570418,\n",
       " -1.66855406702536,\n",
       " -2.17050352364416,\n",
       " -0.460406660165596,\n",
       " 0.291981646721172,\n",
       " 1.08994759708681,\n",
       " 0.758906990028031,\n",
       " 0.00479229747097395,\n",
       " -0.225492548362466,\n",
       " 0.564714560598538,\n",
       " -1.26868535215846,\n",
       " 0.595303118863663,\n",
       " 0.642175654201316,\n",
       " -0.856060160977616,\n",
       " 0.657567349510425,\n",
       " -1.1087943831994,\n",
       " 0.809093970921143,\n",
       " -1.61016992863868,\n",
       " -0.126473141789861,\n",
       " -0.695735501030716,\n",
       " 0.330892091996744,\n",
       " -1.30219792188555,\n",
       " -0.559919235090311,\n",
       " -0.971258111375682,\n",
       " 1.1497599683492,\n",
       " 0.408111519585134,\n",
       " -0.162471501571012,\n",
       " 0.32931896752932,\n",
       " -1.65354061705741,\n",
       " 1.40949953018436,\n",
       " -2.62630174894669,\n",
       " -1.10987484581602,\n",
       " -0.564048149341402,\n",
       " 1.63931815474568,\n",
       " -0.548865626582772,\n",
       " 1.27367351292414,\n",
       " -0.274241375533518,\n",
       " -1.63231414856146,\n",
       " -0.559919235090311,\n",
       " 0.640772533337974,\n",
       " 0.968798289594455,\n",
       " -0.430871108981201,\n",
       " -1.4704492297673,\n",
       " 0.440455703923149,\n",
       " -2.66712411643915,\n",
       " 0.0686014628819244,\n",
       " -1.1248553785731,\n",
       " 0.628444531108159,\n",
       " -0.992063047372689,\n",
       " -0.965715536479997,\n",
       " 1.31592111393706,\n",
       " 0.835750085171348,\n",
       " -1.0110088439584,\n",
       " -0.397358539254111,\n",
       " -0.965715536479997,\n",
       " 1.17626855661063,\n",
       " -2.1175079387829,\n",
       " 0.0686014628819244,\n",
       " -0.430871108981201,\n",
       " -1.70434875861064,\n",
       " 0.993248980926827,\n",
       " -0.520636691467046,\n",
       " 0.14528319028958,\n",
       " -1.3455701075556,\n",
       " -0.363506516973987,\n",
       " -1.44748460421017,\n",
       " 0.989797466710602,\n",
       " 1.40949953018436,\n",
       " 0.841963787058399,\n",
       " -1.08314219382245,\n",
       " 0.473968273650239,\n",
       " 0.865130426150909,\n",
       " 1.26338865075756,\n",
       " -1.14770482847498,\n",
       " -0.363282510298258,\n",
       " 0.640772533337974,\n",
       " 0.70061479017368,\n",
       " 0.706598918332718,\n",
       " -1.51864198975974,\n",
       " 1.47780086129097,\n",
       " 0.707709536247056,\n",
       " -1.28276570388248,\n",
       " -1.10987484581602,\n",
       " -1.20165401217182,\n",
       " -1.06609651062077,\n",
       " -1.57571972650626,\n",
       " 0.69320389664261,\n",
       " 0.977384239780983,\n",
       " 1.37707956533788,\n",
       " 1.06281053932284,\n",
       " 0.837204646485788,\n",
       " -1.38485265117887,\n",
       " 0.500709442737836,\n",
       " 0.103922759006272,\n",
       " -1.24649160387974,\n",
       " 1.33466174502193,\n",
       " 0.99236966168146,\n",
       " -2.66712411643915,\n",
       " 1.01107645710647,\n",
       " 0.607304031883433,\n",
       " 0.48653387309903,\n",
       " 0.876119110375324,\n",
       " -1.62054791291846,\n",
       " 0.138745011519858,\n",
       " -2.04264506981312,\n",
       " -0.169401316222573,\n",
       " -2.08125974412258,\n",
       " 1.12923014071007,\n",
       " -0.0582123607589716,\n",
       " -1.06612104084362,\n",
       " 1.25649604667355,\n",
       " -0.468659405814178,\n",
       " 0.00479229747097395,\n",
       " 0.291981646721172,\n",
       " 0.642175654201316,\n",
       " 0.129422940519542,\n",
       " 1.31592111393706,\n",
       " 0.257520026203694,\n",
       " 1.03362830429051,\n",
       " -0.356869042585994,\n",
       " 0.384805693494673,\n",
       " -0.00359956318197308,\n",
       " 1.19514559774522,\n",
       " -1.69881018639504,\n",
       " 1.27826994710041,\n",
       " 0.239150515883481,\n",
       " 0.695047175614041,\n",
       " 0.382202121221773,\n",
       " -2.00373462453755,\n",
       " 0.30120187818858,\n",
       " -0.81766084417826,\n",
       " -1.19843375478667,\n",
       " 1.14801144278375,\n",
       " -1.34875177416652,\n",
       " -0.763315239935053,\n",
       " -0.167093798857664,\n",
       " -1.47847546258359,\n",
       " -1.73191860151754,\n",
       " -1.06612104084362,\n",
       " 0.0947402695193354,\n",
       " -0.971258111375682,\n",
       " -1.53257009181108,\n",
       " 0.500709442737836,\n",
       " -0.00996362436460503,\n",
       " -0.0850246435223168,\n",
       " 0.306800483744294,\n",
       " -0.809006505715899,\n",
       " 0.180721392604983,\n",
       " -0.664063576980838,\n",
       " -0.397358539254111,\n",
       " 0.257520026203694,\n",
       " 0.758394347826551,\n",
       " 0.640772533337974,\n",
       " -1.10647583398445,\n",
       " 1.28191560319977,\n",
       " -0.397358539254111,\n",
       " -0.756331953206634,\n",
       " 1.40949953018436,\n",
       " -2.56332895987681,\n",
       " 0.914548771130317,\n",
       " 0.408712982547887,\n",
       " 1.24475737737332,\n",
       " 0.32931896752932,\n",
       " 0.140542876799583,\n",
       " 0.253071201445601,\n",
       " 1.12500429027107,\n",
       " -0.396751011752799,\n",
       " 1.03362830429051,\n",
       " -1.26799312743916,\n",
       " -0.229408504480094,\n",
       " -0.363506516973987,\n",
       " -0.688183878486488,\n",
       " -0.894459477776971,\n",
       " -0.447316813514687,\n",
       " 1.37707956533788,\n",
       " 0.841963787058399,\n",
       " -2.09806992039415,\n",
       " 0.253457304110579,\n",
       " 1.10212913917881,\n",
       " -0.756331953206634,\n",
       " 1.14801144278375,\n",
       " -0.797510820994831,\n",
       " -1.10647583398445,\n",
       " 1.40949953018436,\n",
       " 1.0701905522326,\n",
       " -0.229408504480094,\n",
       " 1.01138250984028,\n",
       " 0.103922759006272,\n",
       " -0.510937573326197,\n",
       " -0.674549859665813,\n",
       " -0.0620659972073883,\n",
       " 1.0701905522326,\n",
       " -0.442071604220517,\n",
       " -0.402137448640123,\n",
       " 0.295919343003049,\n",
       " 1.14801144278375,\n",
       " 0.841963787058399,\n",
       " -1.19746581154428,\n",
       " 0.607304031883433,\n",
       " 0.92062304968959,\n",
       " -1.14685515734813,\n",
       " -1.2408362182553,\n",
       " -1.62054791291846,\n",
       " -0.683895173702397,\n",
       " 0.909631680102414,\n",
       " 0.291981646721172,\n",
       " -1.70434875861064,\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt = '../data/MasterArbeit/data/data_scores'\n",
    "data_tgt = []\n",
    "with open(tgt) as fi:\n",
    "    for line in fi:\n",
    "        data_tgt.append(float(line.strip()))\n",
    "data_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.17366603836231"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(data_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = torch.rand(5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.5373  0.1000  0.3239  0.2236\n",
       " 0.6642  0.8575  0.1118  0.1466\n",
       " 0.0265  0.9292  0.8547  0.5076\n",
       " 0.6759  0.0811  0.2124  0.2080\n",
       " 0.6331  0.7333  0.4775  0.8177\n",
       "[torch.FloatTensor of size 5x4]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a1 = a[:,:2]\n",
    "a2 = a[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.5373  0.1000\n",
       " 0.6642  0.8575\n",
       " 0.0265  0.9292\n",
       " 0.6759  0.0811\n",
       " 0.6331  0.7333\n",
       "[torch.FloatTensor of size 5x2]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.3239  0.2236\n",
       " 0.1118  0.1466\n",
       " 0.8547  0.5076\n",
       " 0.2124  0.2080\n",
       " 0.4775  0.8177\n",
       "[torch.FloatTensor of size 5x2]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py27",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
