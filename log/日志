1. 前面获取隐藏层的最后的输出的时候，并没有考虑到目标句子长度的问题。而直接取最后一项，也即是padding的输出。这里把他改了回来
2. 出现corr为nan的想象，其原因是同一个Batch内的各个句子对应输出的score的值相同，从而导致variant为0，最后求得corr为nan。出现同一Batch内的值相同的原因可能是每个神经元的输入太多，导致输出全都逼近与1。这个已经设定为issue了。
3. 数据的分数是z score，这将导致这个分数会依赖于数据的mean和variance。也就是说不通的数据集，分数可能会差别很大。这将十分不利于扩张
4. fmin跑完了一次，结果是：{'opt': 0, 'linear_act_func_out': 0, 'linear_dim3': 3, 'linear_act_func': 1, 'linear_dim2': 1, 'bn_momentum': 0.14846664666248366, 'li_batch_size': 2, 'drop_out_rate': 0.3643314564947353, 'li_lr': 0.01592636698766986}。现在让它再跑一次，看一下结果会是怎么样。
忘记把出现nan的情况给log出来了，回头应该补上。
5. 把分数给规范化了。
6. 给一些文档添加了说明文件，方便以后归总。
7. 增加一个双线模型，目的是减少参数的数量。
8. 发现以前的训练集中预处理之前是进行过乱序的，而我一直使用的是乱序前的分数，所以结果有点感人。现在使用回了对应的分数，感觉结果有改进，用新的模型的话corr可以达到0.7左右。0.7的那个最后直接到500到1，输出没有激活函数。但问题是，还是不能确定现在用的数据，是否就一定是正确的？？是否有必要重新跑一次，整理数据？？
9. 把新的模型，添加到fmin里面。居然会有重名异常。这两个重名的家伙应该不可能同时出现才对啊，这样都不行吗。还是乖乖的改正吧。
未 10. 给新的模型增加一点参数，然后一次性让它去跑个够。
11. 把自认为正确的分数数据进行规范化，并把规范化后的数据加入到fmin中的选择项中。
12. 试着跑了一下，用新的数据的时候，经常会出现corr为0的情况，究竟是为了什么呢？？？
13. 添加了两个模型，其基本思想是相同的，即：输出的向量中并非每个维度都对评分有利，因此，我们尝试建立一个mask，通过这个mask来屏蔽掉这个向量的部分信息。两个模型的主要差别在于，用于建立这个mask的信息原的不同。第一个模型仅使用ref信息，而第二个模型同时使用了ref和sys的信息。
14. 对现行模型做了一些更改：去掉了dropout，并在每个activation function之前加入了bn操作。但是这个更改并不测地，去掉操作知识简单的加了个注释好。所以有时间还是应该彻底改一下的。
15. 增加一个mlp模型，仅适用dropout，而不使用bn。这样做的初衷是在不减低效果的情况下，尽可能的减少参数的数量，毕竟用来训练的数据并不多。
16. 在修改原来的mlp模型的时候，产生了几个疑问，还没有验证。所以有时间的时候就去验证一下吧。另外，更改后的代码还没有跑过，可能会出现一些错误也说不定哦。还有就是还没有把maskmodel给加入到实验中。
17. 测试了几个新的模型，都能跑，另外把masked的多维结构去掉之后，效果反而更好了。
18. Masked2还没清理干净
18.5 下面是一些个实验，实验的基本对比项是参数是：'batch_size': 100, 'dim2': 100, 'dim3': 10, 'lr': 0.01592636698766986, 'act_func': 'LeakyReLU', 'act_func_out': None, 'model': './model/LinearModel', 'type': 'linear', 'momentum': 0.19338528925355508, 'drop_out_rate': 0.5683040090088415。没有使用dropout，第一层之前没有加bn，输入数据没有规范化。
19. 实验：尝试一下在Basic Linear模型里面加个dropout，就加在最后一层，结果显示：相同参数的情况下，拟合的速度没有加之前的快，最终精度略低于之前的版本，估计是之前的有过拟合的现象。毕竟数据重复使用了。结论是，为防止过拟合，可以选择使用
20. 实验：尝试在第一层的输入之前加入bn，结果显示：收敛的熟读类似，但是过程比较稳定，最终结果比加入之前，略微好一点点。结论是应该使用。
21. 在data_util中增加规范化数据的选项。
22. 实验：尝试使用z_score对数据集进行规范化，然后进行训练, 结果显示没有出现太大的区别，是因为都使用了bn的缘故吗？ 结论是再尝试一下其他网络
23. 实验：尝试使用minmax对数据集进行规范化，然后进行训练，结果区别不大，感觉有一点点提升。结论是再尝试一下其他网络，但是相对于在第一层前加bn，感觉还是这个比较好，毕竟可以省了很多参数，跑起来也快了很多。
24. 实验：去掉basicmodel中的线性转化的bias，结果没看出明显变化，但是速度是边快了。结论是可以使用。
25. 综上，使用minmax对数据进行规范化，第一层前不加bn，线性转化的bias都去掉。对basicLinear模型进行调整。
（未）26. 在用hyperopt跑一下basicLinear模型，希望能够得到更好的结果。
27. 把optim和loss添加到fmin的选择集上
28. 调整学习率取值范围
29. 从新整理了一下maskedmodel
30. 离得近是两个方向的，corre是一个方向的，虽然有帮助但确实不一样，先看一下loss是怎么变化的吧。
31. 居然返现训练方法写得有点问题，每回合多取了其次数据，所以该了一下。但是其实区别并不大
32. 突然想看一下，如果把tgt数值扩大会怎么样。果然没啥影响。
重要想法 33. 突然想到，我最终的目的并不是做一个自动化的标尺，而是想要使用这个网络来优化原来的mt系统，所以感觉执着于使用人工Reference数据，并没有多大的意义，反而使用普通的BLUE就可以了，关键的优势是在于网络不是吗？？？应该想的是如何使用这个网络来优化MT系统。
34. 下一步先看一下其他paper中的实验方法
想法 35. 因为encoder decoder结构不是一个坑一个字的吗，所以说最后一句 与其说是整个句子的几个结合， 还不如说是最后一个单词的一个表达。虽然说它包括了其他层的所有信息。但是也夹杂了其他的一些信息不是吗？？比如前面单词的Attention信息啊之类的，所以只拿最后一个单词进行推算真的好吗？？
想法 36. 根据GAN的想法，那么我真的需要有一个具体的分数吗，我应该设计的不应该就是一个判别器，在输入原文和译文的情况下，可以分辨出这个译文值真的译文还是机器的译文就好了吗？？？但是为了设计根号的译文，通过尝试是否能够还原分数的这个方法，估计也是可行的。毕竟不同的网络的差别是很大的啊。但是一个问题是，如果不训练生成器那么这个神经网络翻译系统还有意义吗？？？
35. 做了一个demo文件，准备用这个进行报告
想法36. 只使用最后一个hidden value的结果有点不尽人意，所以尝试使用decoder的所有的hidden value
37. 修改pipeline_hidden.py。增加_get_full_hidden内部方法和get_hidden_full方法，来获得整个句子的hidden value， 因为每个batch的句子长度不同，所以扩展到固定长度。
38. 修改get_hidden.py。增加一个argument，询问是否获取所有的hidden value。
39. 运行get_hidden.py，参数为prepronce的时候，出现了错误，因为数据太大了，内存不足。这估计会是一个大问题。
40. 看了下util中的data方法，还想并不用改的样子。但还是测试一下吧
41. 准备编写用于full hidden value 的新的model。但是存在一个问题是就和句子的长度不一一样，这里hidden value的长度也是不一的。作为参考，这里回去看一下论文，Attention is all you need.
42. 加一个插曲，放到服务器上的程序，在跑到Batch1007的时候，就被kill了，原因未知。估计还是太大了的原因，所以还是先对 原始文件进行划分吧。
43. 把原数据分成了十份，然后再扔到服务器上跑
