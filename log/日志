1. 前面获取隐藏层的最后的输出的时候，并没有考虑到目标句子长度的问题。而直接取最后一项，也即是padding的输出。这里把他改了回来
2. 出现corr为nan的想象，其原因是同一个Batch内的各个句子对应输出的score的值相同，从而导致variant为0，最后求得corr为nan。出现同一Batch内的值相同的原因可能是每个神经元的输入太多，导致输出全都逼近与1。这个已经设定为issue了。
3. 数据的分数是z score，这将导致这个分数会依赖于数据的mean和variance。也就是说不通的数据集，分数可能会差别很大。这将十分不利于扩张
4. fmin跑完了一次，结果是：{'opt': 0, 'linear_act_func_out': 0, 'linear_dim3': 3, 'linear_act_func': 1, 'linear_dim2': 1, 'bn_momentum': 0.14846664666248366, 'li_batch_size': 2, 'drop_out_rate': 0.3643314564947353, 'li_lr': 0.01592636698766986}。现在让它再跑一次，看一下结果会是怎么样。
忘记把出现nan的情况给log出来了，回头应该补上。
5. 把分数给规范化了。
6. 给一些文档添加了说明文件，方便以后归总。
7. 增加一个双线模型，目的是减少参数的数量。