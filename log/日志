1. 前面获取隐藏层的最后的输出的时候，并没有考虑到目标句子长度的问题。而直接取最后一项，也即是padding的输出。这里把他改了回来
2. 出现corr为nan的想象，其原因是同一个Batch内的各个句子对应输出的score的值相同，从而导致variant为0，最后求得corr为nan。出现同一Batch内的值相同的原因可能是每个神经元的输入太多，导致输出全都逼近与1。这个已经设定为issue了。
3. 数据的分数是z score，这将导致这个分数会依赖于数据的mean和variance。也就是说不通的数据集，分数可能会差别很大。这将十分不利于扩张
4. fmin跑完了一次，结果是：{'opt': 0, 'linear_act_func_out': 0, 'linear_dim3': 3, 'linear_act_func': 1, 'linear_dim2': 1, 'bn_momentum': 0.14846664666248366, 'li_batch_size': 2, 'drop_out_rate': 0.3643314564947353, 'li_lr': 0.01592636698766986}。现在让它再跑一次，看一下结果会是怎么样。
忘记把出现nan的情况给log出来了，回头应该补上。
5. 把分数给规范化了。
6. 给一些文档添加了说明文件，方便以后归总。
7. 增加一个双线模型，目的是减少参数的数量。
8. 发现以前的训练集中预处理之前是进行过乱序的，而我一直使用的是乱序前的分数，所以结果有点感人。现在使用回了对应的分数，感觉结果有改进，用新的模型的话corr可以达到0.7左右。0.7的那个最后直接到500到1，输出没有激活函数。但问题是，还是不能确定现在用的数据，是否就一定是正确的？？是否有必要重新跑一次，整理数据？？
9. 把新的模型，添加到fmin里面。居然会有重名异常。这两个重名的家伙应该不可能同时出现才对啊，这样都不行吗。还是乖乖的改正吧。
未 10. 给新的模型增加一点参数，然后一次性让它去跑个够。
11. 把自认为正确的分数数据进行规范化，并把规范化后的数据加入到fmin中的选择项中。
12. 试着跑了一下，用新的数据的时候，经常会出现corr为0的情况，究竟是为了什么呢？？？
13. 添加了两个模型，其基本思想是相同的，即：输出的向量中并非每个维度都对评分有利，因此，我们尝试建立一个mask，通过这个mask来屏蔽掉这个向量的部分信息。两个模型的主要差别在于，用于建立这个mask的信息原的不同。第一个模型仅使用ref信息，而第二个模型同时使用了ref和sys的信息。
14. 对现行模型做了一些更改：去掉了dropout，并在每个activation function之前加入了bn操作。但是这个更改并不测地，去掉操作知识简单的加了个注释好。所以有时间还是应该彻底改一下的。
