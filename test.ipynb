{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_sys = file(\"./data/hidden_sys\")\n",
    "data_sys = np.load(file_sys)\n",
    "data_sys.shape\n",
    "file_sys.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_ref = open(\"./data/hidden_ref\")\n",
    "data_ref = np.load(file_ref)\n",
    "data_ref.shape\n",
    "file_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_scores = []\n",
    "with open(\"./data/data_scores\") as fi:\n",
    "    for line in fi:\n",
    "        data_scores.append(float(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.9131\n",
       " 0.1423\n",
       " 0.1597\n",
       "   ⋮   \n",
       " 1.0628\n",
       " 1.1250\n",
       " 0.8761\n",
       "[torch.FloatTensor of size 9392]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.1317e-01  1.9135e-01  4.8339e-02  ...   3.3562e-01  2.1015e-01 -3.0384e-01\n",
       " 6.9478e-01  6.4986e-01 -2.1220e-01  ...  -3.8425e-01 -6.4973e-01 -2.3927e-01\n",
       " 2.5970e-01  5.3346e-01  8.0853e-02  ...  -4.2903e-01 -3.2311e-01 -8.9193e-02\n",
       "                ...                   ⋱                   ...                \n",
       " 6.6741e-01  6.7923e-01  1.4909e-01  ...  -2.2978e-01 -3.1571e-01  1.3677e-01\n",
       " 2.5324e-02  1.3155e-01 -6.5003e-03  ...   4.0089e-01 -2.2887e-01 -3.4650e-01\n",
       " 4.1332e-01  5.0622e-01 -4.5596e-01  ...  -5.0268e-01 -3.7340e-01 -2.6541e-01\n",
       "[torch.FloatTensor of size 9392x1000]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(data_scores)\n",
    "b = torch.from_numpy(data_ref)\n",
    "c = torch.from_numpy(data_sys)\n",
    "d = torch.cat((c,b), 1)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(3248)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = range(len(data_scores))\n",
    "random.shuffle(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb = zip(d, a, tmp)\n",
    "comb = sorted(comb, key = lambda x: x[-1])\n",
    "d, a, tmp = zip(*comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.9131\n",
       " 0.1423\n",
       " 0.1597\n",
       "   ⋮   \n",
       " 1.0628\n",
       " 1.1250\n",
       " 0.8761\n",
       "[torch.FloatTensor of size 9392]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 3.1889e-01  6.3258e-01  1.1316e-01  ...  -4.0196e-01 -4.5356e-01 -4.0905e-01\n",
       " 4.2669e-01  5.7952e-01 -1.5267e-01  ...  -7.3717e-01 -5.4875e-01 -4.3146e-01\n",
       " 2.3961e-01  4.4815e-01 -3.0775e-01  ...  -7.1228e-01 -6.1418e-01 -2.2865e-01\n",
       "                ...                   ⋱                   ...                \n",
       " 3.0726e-01  4.2501e-01 -6.7688e-02  ...  -3.7334e-01 -6.1822e-01 -2.2931e-01\n",
       " 4.6479e-01  4.5037e-01  4.2272e-02  ...  -5.3935e-01 -3.9767e-01 -6.4714e-02\n",
       " 4.3281e-01  4.3685e-01 -4.6474e-02  ...  -6.4254e-01 -2.9456e-01 -4.9992e-01\n",
       "[torch.FloatTensor of size 9392x1000]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = d[0].view(1, -1)\n",
    "for i in range(1, len(d)):\n",
    "    tmp = torch.cat((tmp, d[i].view(1, -1)), 0)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 3.1889e-01  6.3258e-01  1.1316e-01  ...  -4.0196e-01 -4.5356e-01 -4.0905e-01\n",
       " 4.2669e-01  5.7952e-01 -1.5267e-01  ...  -7.3717e-01 -5.4875e-01 -4.3146e-01\n",
       " 2.3961e-01  4.4815e-01 -3.0775e-01  ...  -7.1228e-01 -6.1418e-01 -2.2865e-01\n",
       "                ...                   ⋱                   ...                \n",
       " 3.0726e-01  4.2501e-01 -6.7688e-02  ...  -3.7334e-01 -6.1822e-01 -2.2931e-01\n",
       " 4.6479e-01  4.5037e-01  4.2272e-02  ...  -5.3935e-01 -3.9767e-01 -6.4714e-02\n",
       " 4.3281e-01  4.3685e-01 -4.6474e-02  ...  -6.4254e-01 -2.9456e-01 -4.9992e-01\n",
       "[torch.FloatTensor of size 9392x1000]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'view'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-0706f0478fb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'view'"
     ]
    }
   ],
   "source": [
    "tmp = d[0][0].view(1, -1)\n",
    "for i in range(1, len(d)):\n",
    "    tmp = torch.cat((tmp, d[i][0].view(1, -1)), 0)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 8.8883e-23  1.4013e-45  7.8276e-23\n",
       "[torch.FloatTensor of size 1x3]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0][0].view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.Tensor(20, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = a[0:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.6434e-43  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.5593e-43  0.0000e+00  1.2916e+26 -1.2851e+17\n",
       " 6.2487e-29  1.4013e-45  8.8666e-23  1.4013e-45\n",
       "-3.1784e+15  1.4013e-45  0.0000e+00  1.4013e-45\n",
       "[torch.FloatTensor of size 10x4]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = a[10:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "-2.5641e+04  4.5863e-41  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "-2.5641e+04  4.5863e-41 -2.5641e+04  4.5863e-41\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.4472e-43  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00 -1.0898e+17  4.7161e-01\n",
       " 4.8357e-29  1.4013e-45  4.2008e-19  1.4013e-45\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "[torch.FloatTensor of size 10x4]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.6434e-43  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.5593e-43  0.0000e+00  1.2916e+26 -1.2851e+17\n",
       " 6.2487e-29  1.4013e-45  8.8666e-23  1.4013e-45\n",
       "-3.1784e+15  1.4013e-45  0.0000e+00  1.4013e-45\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "-2.5641e+04  4.5863e-41  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "-2.5641e+04  4.5863e-41 -2.5641e+04  4.5863e-41\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.4472e-43  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00 -1.0898e+17  4.7161e-01\n",
       " 4.8357e-29  1.4013e-45  4.2008e-19  1.4013e-45\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "[torch.FloatTensor of size 20x4]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 9\n",
    "b = 2\n",
    "c = round(a/b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = torch.Tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    a.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = torch.cat(a, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt = Params.Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pas = {'tgt': '../data/MasterArbeit/data/data_scores', 'src_sys': '../data/MasterArbeit/data/sys_hidden', 'src_ref': '../data/MasterArbeit/data/ref_hidden', 'batch_size': 100, 'dim2': 100, 'dim3': 10, 'lr': 0.01592636698766986, 'act_func': 'LeakyReLU', 'act_func_out': 'Tanh', 'model': './model/LinearModel', 'type': 'linear', 'momentum': 0.7919209839255212, 'drop_out_rate': 0.44618529671927565}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pas1 = {'dim2': 10, 'act_func_out': None, 'tgt': '../data/MasterArbeit/data/normalized_data_scores', 'src_sys': '../data/MasterArbeit/data/sys_hidden', 'src_ref': '../data/MasterArbeit/data/ref_hidden', 'batch_size': 100, 'lr': 0.01592636698766986, 'act_func': 'Tanh', 'model': 'BiLinear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt.set_params(pas1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt.act_func_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('act_func_out', None)\n",
      "('tgt', '../data/MasterArbeit/data/normalized_data_scores')\n",
      "('src_sys', '../data/MasterArbeit/data/sys_hidden')\n",
      "('src_ref', '../data/MasterArbeit/data/ref_hidden')\n",
      "('eps', 1e-08)\n",
      "('batch_size', 100)\n",
      "('dim2', 10)\n",
      "('dim3', None)\n",
      "('lr', 0.01592636698766986)\n",
      "('act_func', 'Tanh')\n",
      "('model', 'BiLinear')\n",
      "('weight_decay', 0)\n",
      "('drop_out_rate', 0.5)\n",
      "('momentum', 0.1)\n",
      "('out', './test_data/pred')\n",
      "BiLinear (\n",
      "  (li_sys): Linear (500 -> 500)\n",
      "  (li_ref): Linear (500 -> 500)\n",
      "  (act_func): Tanh ()\n",
      "  (fc): Linear (500 -> 10)\n",
      "  (drop_out): Dropout (p = 0.5)\n",
      "  (li_out): Linear (10 -> 1)\n",
      ")\n",
      "number of batch is 93\n",
      "evaluate 0\n",
      "the correlation coeffizient is : -0.118962\n",
      "evaluate 1\n",
      "the correlation coeffizient is : 0.039419\n",
      "evaluate 2\n",
      "the correlation coeffizient is : -0.005627\n",
      "evaluate 3\n",
      "the correlation coeffizient is : -0.177405\n",
      "evaluate 4\n",
      "the correlation coeffizient is : 0.078632\n",
      "evaluate 5\n",
      "the correlation coeffizient is : 0.121071\n",
      "evaluate 6\n",
      "the correlation coeffizient is : 0.020969\n",
      "evaluate 7\n",
      "the correlation coeffizient is : -0.021523\n",
      "evaluate 8\n",
      "the correlation coeffizient is : -0.184819\n",
      "evaluate 9\n",
      "the correlation coeffizient is : 0.051806\n",
      "evaluate 10\n",
      "the correlation coeffizient is : -0.265162\n",
      "evaluate 11\n",
      "the correlation coeffizient is : 0.146985\n",
      "evaluate 12\n",
      "the correlation coeffizient is : 0.165615\n",
      "evaluate 13\n",
      "the correlation coeffizient is : -0.029785\n",
      "evaluate 14\n",
      "the correlation coeffizient is : 0.030954\n",
      "evaluate 15\n",
      "the correlation coeffizient is : 0.052804\n",
      "evaluate 16\n",
      "the correlation coeffizient is : -0.014726\n",
      "evaluate 17\n",
      "the correlation coeffizient is : -0.141558\n",
      "evaluate 18\n",
      "the correlation coeffizient is : -0.005418\n",
      "evaluate 19\n",
      "the correlation coeffizient is : -0.016257\n",
      "evaluate 20\n",
      "the correlation coeffizient is : -0.011503\n",
      "evaluate 21\n",
      "the correlation coeffizient is : -0.070717\n",
      "evaluate 22\n",
      "the correlation coeffizient is : 0.055506\n",
      "evaluate 23\n",
      "the correlation coeffizient is : 0.263900\n",
      "evaluate 24\n",
      "the correlation coeffizient is : 0.100512\n",
      "evaluate 25\n",
      "the correlation coeffizient is : -0.063206\n",
      "evaluate 26\n",
      "the correlation coeffizient is : 0.127077\n",
      "evaluate 27\n",
      "the correlation coeffizient is : 0.050764\n",
      "evaluate 28\n",
      "the correlation coeffizient is : 0.087640\n",
      "evaluate 29\n",
      "the correlation coeffizient is : 0.003144\n",
      "evaluate 30\n",
      "the correlation coeffizient is : 0.110489\n",
      "evaluate 31\n",
      "the correlation coeffizient is : 0.176018\n",
      "evaluate 32\n",
      "the correlation coeffizient is : 0.292362\n",
      "evaluate 33\n",
      "the correlation coeffizient is : 0.112537\n",
      "evaluate 34\n",
      "the correlation coeffizient is : 0.199739\n",
      "evaluate 35\n",
      "the correlation coeffizient is : -0.035841\n",
      "evaluate 36\n",
      "the correlation coeffizient is : 0.248932\n",
      "evaluate 37\n",
      "the correlation coeffizient is : 0.310670\n",
      "evaluate 38\n",
      "the correlation coeffizient is : 0.041322\n",
      "evaluate 39\n",
      "the correlation coeffizient is : 0.203700\n",
      "evaluate 40\n",
      "the correlation coeffizient is : 0.304051\n",
      "evaluate 41\n",
      "the correlation coeffizient is : 0.336998\n",
      "evaluate 42\n",
      "the correlation coeffizient is : 0.357634\n",
      "evaluate 43\n",
      "the correlation coeffizient is : 0.098368\n",
      "evaluate 44\n",
      "the correlation coeffizient is : 0.254849\n",
      "evaluate 45\n",
      "the correlation coeffizient is : 0.212841\n",
      "evaluate 46\n",
      "the correlation coeffizient is : 0.119956\n",
      "evaluate 47\n",
      "the correlation coeffizient is : 0.317373\n",
      "evaluate 48\n",
      "the correlation coeffizient is : 0.305730\n",
      "evaluate 49\n",
      "the correlation coeffizient is : 0.350761\n",
      "evaluate 50\n",
      "the correlation coeffizient is : 0.385962\n",
      "evaluate 51\n",
      "the correlation coeffizient is : 0.258300\n",
      "evaluate 52\n",
      "the correlation coeffizient is : 0.363377\n",
      "evaluate 53\n",
      "the correlation coeffizient is : 0.184721\n",
      "evaluate 54\n",
      "the correlation coeffizient is : 0.288506\n",
      "evaluate 55\n",
      "the correlation coeffizient is : 0.291631\n",
      "evaluate 56\n",
      "the correlation coeffizient is : 0.221415\n",
      "evaluate 57\n",
      "the correlation coeffizient is : 0.330938\n",
      "evaluate 58\n",
      "the correlation coeffizient is : 0.398581\n",
      "evaluate 59\n",
      "the correlation coeffizient is : 0.383980\n",
      "evaluate 60\n",
      "the correlation coeffizient is : 0.445879\n",
      "evaluate 61\n",
      "the correlation coeffizient is : 0.400230\n",
      "evaluate 62\n",
      "the correlation coeffizient is : 0.349511\n",
      "evaluate 63\n",
      "the correlation coeffizient is : 0.257039\n",
      "evaluate 64\n",
      "the correlation coeffizient is : 0.386108\n",
      "evaluate 65\n",
      "the correlation coeffizient is : 0.418733\n",
      "evaluate 66\n",
      "the correlation coeffizient is : 0.186599\n",
      "evaluate 67\n",
      "the correlation coeffizient is : 0.326129\n",
      "evaluate 68\n",
      "the correlation coeffizient is : 0.203920\n",
      "evaluate 69\n",
      "the correlation coeffizient is : 0.332753\n",
      "evaluate 70\n",
      "the correlation coeffizient is : 0.326869\n",
      "evaluate 71\n",
      "the correlation coeffizient is : 0.317719\n",
      "evaluate 72\n",
      "the correlation coeffizient is : 0.227482\n",
      "evaluate 73\n",
      "the correlation coeffizient is : 0.214403\n",
      "evaluate 74\n",
      "the correlation coeffizient is : 0.286185\n",
      "evaluate 75\n",
      "the correlation coeffizient is : 0.350602\n",
      "evaluate 76\n",
      "the correlation coeffizient is : 0.251805\n",
      "evaluate 77\n",
      "the correlation coeffizient is : 0.333893\n",
      "evaluate 78\n",
      "the correlation coeffizient is : 0.294768\n",
      "evaluate 79\n",
      "the correlation coeffizient is : 0.412849\n",
      "evaluate 80\n",
      "the correlation coeffizient is : 0.289245\n",
      "evaluate 81\n",
      "the correlation coeffizient is : 0.131196\n",
      "evaluate 82\n",
      "the correlation coeffizient is : 0.434431\n",
      "evaluate 83\n",
      "the correlation coeffizient is : 0.267329\n",
      "evaluate 84\n",
      "the correlation coeffizient is : 0.358599\n",
      "evaluate 85\n",
      "the correlation coeffizient is : 0.236770\n",
      "evaluate 86\n",
      "the correlation coeffizient is : 0.336538\n",
      "evaluate 87\n",
      "the correlation coeffizient is : 0.338312\n",
      "evaluate 88\n",
      "the correlation coeffizient is : 0.475782\n",
      "evaluate 89\n",
      "the correlation coeffizient is : 0.363292\n",
      "evaluate 90\n",
      "the correlation coeffizient is : 0.280226\n",
      "evaluate 91\n",
      "the correlation coeffizient is : 0.275595\n",
      "evaluate 92\n",
      "the correlation coeffizient is : 0.302567\n",
      "evaluate 93\n",
      "the correlation coeffizient is : 0.279545\n",
      "evaluate 94\n",
      "the correlation coeffizient is : 0.410166\n",
      "evaluate 95\n",
      "the correlation coeffizient is : 0.310046\n",
      "evaluate 96\n",
      "the correlation coeffizient is : 0.373336\n",
      "evaluate 97\n",
      "the correlation coeffizient is : 0.440248\n",
      "evaluate 98\n",
      "the correlation coeffizient is : 0.294453\n",
      "evaluate 99\n",
      "the correlation coeffizient is : 0.276742\n",
      "evaluate 100\n",
      "the correlation coeffizient is : 0.379893\n",
      "evaluate 101\n",
      "the correlation coeffizient is : 0.320025\n",
      "evaluate 102\n",
      "the correlation coeffizient is : 0.364793\n",
      "evaluate 103\n",
      "the correlation coeffizient is : 0.369618\n",
      "evaluate 104\n",
      "the correlation coeffizient is : 0.237871\n",
      "evaluate 105\n",
      "the correlation coeffizient is : 0.328274\n",
      "evaluate 106\n",
      "the correlation coeffizient is : 0.280454\n",
      "evaluate 107\n",
      "the correlation coeffizient is : 0.432620\n",
      "evaluate 108\n",
      "the correlation coeffizient is : 0.355394\n",
      "evaluate 109\n",
      "the correlation coeffizient is : 0.487828\n",
      "evaluate 110\n",
      "the correlation coeffizient is : 0.200177\n",
      "evaluate 111\n",
      "the correlation coeffizient is : 0.331856\n",
      "evaluate 112\n",
      "the correlation coeffizient is : 0.480076\n",
      "evaluate 113\n",
      "the correlation coeffizient is : 0.330519\n",
      "evaluate 114\n",
      "the correlation coeffizient is : 0.466356\n",
      "evaluate 115\n",
      "the correlation coeffizient is : 0.343283\n",
      "evaluate 116\n",
      "the correlation coeffizient is : 0.427642\n",
      "evaluate 117\n",
      "the correlation coeffizient is : 0.385466\n",
      "evaluate 118\n",
      "the correlation coeffizient is : 0.459699\n",
      "evaluate 119\n",
      "the correlation coeffizient is : 0.446549\n",
      "evaluate 120\n",
      "the correlation coeffizient is : 0.398209\n",
      "evaluate 121\n",
      "the correlation coeffizient is : 0.467646\n",
      "evaluate 122\n",
      "the correlation coeffizient is : 0.440789\n",
      "evaluate 123\n",
      "the correlation coeffizient is : 0.385714\n",
      "evaluate 124\n",
      "the correlation coeffizient is : 0.327736\n",
      "evaluate 125\n",
      "the correlation coeffizient is : 0.421204\n",
      "evaluate 126\n",
      "the correlation coeffizient is : 0.274791\n",
      "evaluate 127\n",
      "the correlation coeffizient is : 0.450714\n",
      "evaluate 128\n",
      "the correlation coeffizient is : 0.368771\n",
      "evaluate 129\n",
      "the correlation coeffizient is : 0.419198\n",
      "evaluate 130\n",
      "the correlation coeffizient is : 0.328756\n",
      "evaluate 131\n",
      "the correlation coeffizient is : 0.443318\n",
      "evaluate 132\n",
      "the correlation coeffizient is : 0.294908\n",
      "evaluate 133\n",
      "the correlation coeffizient is : 0.256146\n",
      "evaluate 134\n",
      "the correlation coeffizient is : 0.312967\n",
      "evaluate 135\n",
      "the correlation coeffizient is : 0.445597\n",
      "evaluate 136\n",
      "the correlation coeffizient is : 0.511149\n",
      "evaluate 137\n",
      "the correlation coeffizient is : 0.479650\n",
      "evaluate 138\n",
      "the correlation coeffizient is : 0.286794\n",
      "evaluate 139\n",
      "the correlation coeffizient is : 0.429611\n",
      "evaluate 140\n",
      "the correlation coeffizient is : 0.341441\n",
      "evaluate 141\n",
      "the correlation coeffizient is : 0.412071\n",
      "evaluate 142\n",
      "the correlation coeffizient is : 0.313343\n",
      "evaluate 143\n",
      "the correlation coeffizient is : 0.565875\n",
      "evaluate 144\n",
      "the correlation coeffizient is : 0.587294\n",
      "evaluate 145\n",
      "the correlation coeffizient is : 0.472894\n",
      "evaluate 146\n",
      "the correlation coeffizient is : 0.234710\n",
      "evaluate 147\n",
      "the correlation coeffizient is : 0.549842\n",
      "evaluate 148\n",
      "the correlation coeffizient is : 0.398741\n",
      "evaluate 149\n",
      "the correlation coeffizient is : 0.430770\n",
      "evaluate 150\n",
      "the correlation coeffizient is : 0.508473\n",
      "evaluate 151\n",
      "the correlation coeffizient is : 0.550211\n",
      "evaluate 152\n",
      "the correlation coeffizient is : 0.495572\n",
      "evaluate 153\n",
      "the correlation coeffizient is : 0.470275\n",
      "evaluate 154\n",
      "the correlation coeffizient is : 0.236037\n",
      "evaluate 155\n",
      "the correlation coeffizient is : 0.526193\n",
      "evaluate 156\n",
      "the correlation coeffizient is : 0.460700\n",
      "evaluate 157\n",
      "the correlation coeffizient is : 0.414161\n",
      "evaluate 158\n",
      "the correlation coeffizient is : 0.510349\n",
      "evaluate 159\n",
      "the correlation coeffizient is : 0.430690\n",
      "evaluate 160\n",
      "the correlation coeffizient is : 0.483783\n",
      "evaluate 161\n",
      "the correlation coeffizient is : 0.378915\n",
      "evaluate 162\n",
      "the correlation coeffizient is : 0.529119\n",
      "evaluate 163\n",
      "the correlation coeffizient is : 0.475403\n",
      "evaluate 164\n",
      "the correlation coeffizient is : 0.460331\n",
      "evaluate 165\n",
      "the correlation coeffizient is : 0.342281\n",
      "evaluate 166\n",
      "the correlation coeffizient is : 0.390112\n",
      "evaluate 167\n",
      "the correlation coeffizient is : 0.388908\n",
      "evaluate 168\n",
      "the correlation coeffizient is : 0.518949\n",
      "evaluate 169\n",
      "the correlation coeffizient is : 0.623372\n",
      "evaluate 170\n",
      "the correlation coeffizient is : 0.534492\n",
      "evaluate 171\n",
      "the correlation coeffizient is : 0.534040\n",
      "evaluate 172\n",
      "the correlation coeffizient is : 0.428808\n",
      "evaluate 173\n",
      "the correlation coeffizient is : 0.562078\n",
      "evaluate 174\n",
      "the correlation coeffizient is : 0.428787\n",
      "evaluate 175\n",
      "the correlation coeffizient is : 0.402466\n",
      "evaluate 176\n",
      "the correlation coeffizient is : 0.576697\n",
      "evaluate 177\n",
      "the correlation coeffizient is : 0.477479\n",
      "evaluate 178\n",
      "the correlation coeffizient is : 0.398822\n",
      "evaluate 179\n",
      "the correlation coeffizient is : 0.570348\n",
      "evaluate 180\n",
      "the correlation coeffizient is : 0.483041\n",
      "evaluate 181\n",
      "the correlation coeffizient is : 0.606467\n",
      "evaluate 182\n",
      "the correlation coeffizient is : 0.433863\n",
      "evaluate 183\n",
      "the correlation coeffizient is : 0.531507\n",
      "evaluate 184\n",
      "the correlation coeffizient is : 0.538701\n",
      "evaluate 185\n",
      "the correlation coeffizient is : 0.561773\n",
      "evaluate 186\n",
      "the correlation coeffizient is : 0.483877\n",
      "evaluate 187\n",
      "the correlation coeffizient is : 0.430780\n",
      "evaluate 188\n",
      "the correlation coeffizient is : 0.468853\n",
      "evaluate 189\n",
      "the correlation coeffizient is : 0.540329\n",
      "evaluate 190\n",
      "the correlation coeffizient is : 0.438639\n",
      "evaluate 191\n",
      "the correlation coeffizient is : 0.429757\n",
      "evaluate 192\n",
      "the correlation coeffizient is : 0.390554\n",
      "evaluate 193\n",
      "the correlation coeffizient is : 0.431032\n",
      "evaluate 194\n",
      "the correlation coeffizient is : 0.561607\n",
      "evaluate 195\n",
      "the correlation coeffizient is : 0.522524\n",
      "evaluate 196\n",
      "the correlation coeffizient is : 0.533484\n",
      "evaluate 197\n",
      "the correlation coeffizient is : 0.377238\n",
      "evaluate 198\n",
      "the correlation coeffizient is : 0.523958\n",
      "evaluate 199\n",
      "the correlation coeffizient is : 0.476064\n",
      "evaluate 200\n",
      "the correlation coeffizient is : 0.505271\n",
      "evaluate 201\n",
      "the correlation coeffizient is : 0.490872\n",
      "evaluate 202\n",
      "the correlation coeffizient is : 0.581088\n",
      "evaluate 203\n",
      "the correlation coeffizient is : 0.383949\n",
      "evaluate 204\n",
      "the correlation coeffizient is : 0.552368\n",
      "evaluate 205\n",
      "the correlation coeffizient is : 0.410217\n",
      "evaluate 206\n",
      "the correlation coeffizient is : 0.554304\n",
      "evaluate 207\n",
      "the correlation coeffizient is : 0.309749\n",
      "evaluate 208\n",
      "the correlation coeffizient is : 0.580844\n",
      "evaluate 209\n",
      "the correlation coeffizient is : 0.564153\n",
      "evaluate 210\n",
      "the correlation coeffizient is : 0.521440\n",
      "evaluate 211\n",
      "the correlation coeffizient is : 0.511330\n",
      "evaluate 212\n",
      "the correlation coeffizient is : 0.540143\n",
      "evaluate 213\n",
      "the correlation coeffizient is : 0.482182\n",
      "evaluate 214\n",
      "the correlation coeffizient is : 0.425598\n",
      "evaluate 215\n",
      "the correlation coeffizient is : 0.507267\n",
      "evaluate 216\n",
      "the correlation coeffizient is : 0.551591\n",
      "evaluate 217\n",
      "the correlation coeffizient is : 0.490197\n",
      "evaluate 218\n",
      "the correlation coeffizient is : 0.568721\n",
      "evaluate 219\n",
      "the correlation coeffizient is : 0.521858\n",
      "evaluate 220\n",
      "the correlation coeffizient is : 0.436941\n",
      "evaluate 221\n",
      "the correlation coeffizient is : 0.547583\n",
      "evaluate 222\n",
      "the correlation coeffizient is : 0.583339\n",
      "evaluate 223\n",
      "the correlation coeffizient is : 0.444535\n",
      "evaluate 224\n",
      "the correlation coeffizient is : 0.468117\n",
      "evaluate 225\n",
      "the correlation coeffizient is : 0.485132\n",
      "evaluate 226\n",
      "the correlation coeffizient is : 0.570137\n",
      "evaluate 227\n",
      "the correlation coeffizient is : 0.629813\n",
      "evaluate 228\n",
      "the correlation coeffizient is : 0.546728\n",
      "evaluate 229\n",
      "the correlation coeffizient is : 0.460164\n",
      "evaluate 230\n",
      "the correlation coeffizient is : 0.516084\n",
      "evaluate 231\n",
      "the correlation coeffizient is : 0.453814\n",
      "evaluate 232\n",
      "the correlation coeffizient is : 0.540346\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d27b52266a64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfmin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpas1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ihuangyiran/Documents/Workplace_Python/MasterArbeit/fmin.pyc\u001b[0m in \u001b[0;36mo_func\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnu_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_repeatly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"evaluate %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ihuangyiran/Documents/Workplace_Python/MasterArbeit/fmin.pyc\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(model, loss_fn, optimizer, src, tgt)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ihuangyiran/anaconda2/envs/py27/lib/python2.7/site-packages/torch/optim/adam.pyc\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fmin.o_func(pas1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = getattr(torch.nn, 'ReLU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = torch.nn.ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.activation.ReLU"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "DuplicateLabel",
     "evalue": "linear_act_func",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDuplicateLabel\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f0aeffc33b9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfmin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ihuangyiran/Documents/Workplace_Python/MasterArbeit/fmin.pyc\u001b[0m in \u001b[0;36mget_best\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mli_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim_algo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             max_evals = 500)\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ihuangyiran/anaconda2/envs/py27/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     domain = base.Domain(fn, space,\n\u001b[0;32m--> 314\u001b[0;31m                          pass_expr_memo_ctrl=pass_expr_memo_ctrl)\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     rval = FMinIter(algo, domain, trials, max_evals=max_evals,\n",
      "\u001b[0;32m/Users/ihuangyiran/anaconda2/envs/py27/lib/python2.7/site-packages/hyperopt/base.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fn, expr, workdir, pass_expr_memo_ctrl, name, loss_target)\u001b[0m\n\u001b[1;32m    774\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mDuplicateLabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'obj'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDuplicateLabel\u001b[0m: linear_act_func"
     ]
    }
   ],
   "source": [
    "fmin.get_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32/10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "x = float('nan')\n",
    "math.isnan(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## normalize scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.70434875861064,\n",
       " 1.12727142153235,\n",
       " -0.872401325076093,\n",
       " -0.520636691467046,\n",
       " 0.0293189192586597,\n",
       " -1.67083618888355,\n",
       " -1.54107458193584,\n",
       " -1.26716970413938,\n",
       " 1.14801144278375,\n",
       " -0.126473141789861,\n",
       " 1.08998382718802,\n",
       " -1.45083864991872,\n",
       " -1.30334660957726,\n",
       " 0.909684951356344,\n",
       " -0.865310032116374,\n",
       " -1.04805674497439,\n",
       " 1.03362830429051,\n",
       " -1.30334660957726,\n",
       " 0.473968273650239,\n",
       " 0.0655234422069162,\n",
       " -2.31501818674212,\n",
       " -1.30040055102541,\n",
       " -1.26443616430169,\n",
       " 1.24609931070437,\n",
       " 0.0048710057016938,\n",
       " 0.339556020247105,\n",
       " -0.553215740838215,\n",
       " -0.284941429727458,\n",
       " -0.740862210579549,\n",
       " -1.44105725859061,\n",
       " -0.264247987380428,\n",
       " 0.0386786043300455,\n",
       " 0.71831182779596,\n",
       " -1.26443616430169,\n",
       " 1.10910099750817,\n",
       " 0.0686014628819244,\n",
       " 1.11418127557441,\n",
       " 0.253071201445601,\n",
       " 0.419182111938213,\n",
       " -1.80918239815969,\n",
       " -0.229408504480094,\n",
       " -0.123356240182688,\n",
       " -0.0496745081911503,\n",
       " 1.22217430718766,\n",
       " -1.1248553785731,\n",
       " -0.985337863893415,\n",
       " -1.15989655423098,\n",
       " -0.0139082445291922,\n",
       " -1.54107458193584,\n",
       " -0.434365786127364,\n",
       " 0.564354763650173,\n",
       " -0.625664260181483,\n",
       " 0.00479229747097395,\n",
       " -1.00060178914239,\n",
       " -0.541165306892952,\n",
       " 1.37707956533788,\n",
       " 1.19092537160453,\n",
       " 1.12500429027107,\n",
       " -0.0269699547415003,\n",
       " 0.439961524610728,\n",
       " 1.16851268433334,\n",
       " 1.15399058740957,\n",
       " 0.0196085297921715,\n",
       " -2.00803966495828,\n",
       " -0.779261527378905,\n",
       " -1.80242807284352,\n",
       " -0.637772075862252,\n",
       " 1.24475737737332,\n",
       " -1.34225705485283,\n",
       " 0.37271797660176,\n",
       " 0.330892091996744,\n",
       " 0.955074894851372,\n",
       " 1.13791095964253,\n",
       " -2.09778641339656,\n",
       " -0.823820570438701,\n",
       " 1.16851268433334,\n",
       " -0.500696803050913,\n",
       " 0.384805693494673,\n",
       " -0.932247035025456,\n",
       " 1.24475737737332,\n",
       " -1.26868535215846,\n",
       " 0.0788671043790961,\n",
       " -0.27777460080266,\n",
       " -0.397358539254111,\n",
       " -0.602958594616973,\n",
       " 1.12727142153235,\n",
       " -2.03295160375887,\n",
       " 0.347025990290812,\n",
       " -1.57571972650626,\n",
       " -1.30219792188555,\n",
       " 0.993248980926827,\n",
       " -1.90283357720715,\n",
       " 1.21000101759139,\n",
       " -0.379648013438239,\n",
       " -0.992027214946222,\n",
       " -1.02774905479782,\n",
       " -0.486227258790259,\n",
       " 0.719043156989968,\n",
       " -1.80918239815969,\n",
       " -2.00373462453755,\n",
       " -0.0582123607589716,\n",
       " 0.972182822522608,\n",
       " 0.382861811868042,\n",
       " 1.16851268433334,\n",
       " -0.447165611587295,\n",
       " 0.674241034792515,\n",
       " -0.866534515433376,\n",
       " -0.0287202722561164,\n",
       " -1.27105218589777,\n",
       " -0.123356240182688,\n",
       " -0.856060160977616,\n",
       " -0.430871108981201,\n",
       " 0.443748066717318,\n",
       " 0.23927090856685,\n",
       " 0.778513503941099,\n",
       " 1.31592111393706,\n",
       " -0.75860037571926,\n",
       " -2.06453839447977,\n",
       " 1.33820803399917,\n",
       " -0.482802158719479,\n",
       " 0.20779127437812,\n",
       " -0.173912076323135,\n",
       " 0.343579268244777,\n",
       " 0.994257260766243,\n",
       " 0.00479229747097395,\n",
       " -0.444034451401381,\n",
       " -0.548865626582772,\n",
       " -1.00060178914239,\n",
       " 0.0271241254075607,\n",
       " -0.281845171077426,\n",
       " -0.695735501030716,\n",
       " 0.690942402274422,\n",
       " -0.252764587136829,\n",
       " -1.80918239815969,\n",
       " 0.751045204576369,\n",
       " -0.63848432233684,\n",
       " 0.262822929695734,\n",
       " -1.20165401217182,\n",
       " -1.08645606177375,\n",
       " -0.291675032412401,\n",
       " -1.94336634123875,\n",
       " 1.10910099750817,\n",
       " 0.943144249829505,\n",
       " -1.70434875861064,\n",
       " -1.67083618888355,\n",
       " 0.756711144595315,\n",
       " -0.847686178890694,\n",
       " -0.0590320517207384,\n",
       " 1.06188186411476,\n",
       " 0.449516610200471,\n",
       " -2.08483829855699,\n",
       " 0.461460279450232,\n",
       " -0.537212341742857,\n",
       " 0.607304031883433,\n",
       " 0.0112417995560491,\n",
       " -2.56555146682984,\n",
       " 0.439961524610728,\n",
       " -0.260215120221697,\n",
       " 0.23915411187824,\n",
       " 0.0585189750677431,\n",
       " 0.994279345865177,\n",
       " -0.00359956318197308,\n",
       " -1.33519147480243,\n",
       " -0.397358539254111,\n",
       " 0.439961524610728,\n",
       " -0.429989807649004,\n",
       " 1.24320555951971,\n",
       " -0.496517149884582,\n",
       " -0.599201778713575,\n",
       " 0.26029264897955,\n",
       " 0.989797466710602,\n",
       " 0.50373844696225,\n",
       " -1.73786132833773,\n",
       " 0.597195595525027,\n",
       " -1.92591373398641,\n",
       " 1.10910099750817,\n",
       " 1.13808643198301,\n",
       " -2.08155551508869,\n",
       " -0.75860037571926,\n",
       " -1.05899799038095,\n",
       " 0.339556020247105,\n",
       " 0.439961524610728,\n",
       " 0.334625776914176,\n",
       " 0.953459216405889,\n",
       " -0.0448634541906483,\n",
       " -0.535467414373893,\n",
       " 1.10933155370155,\n",
       " -0.52513770406583,\n",
       " 1.11438695101786,\n",
       " 0.842606540648234,\n",
       " -1.26868535215846,\n",
       " -1.28276570388248,\n",
       " -1.80327153195803,\n",
       " 0.876119110375324,\n",
       " 0.422144355491307,\n",
       " -0.746508634549636,\n",
       " -1.75756247178124,\n",
       " 0.473968273650239,\n",
       " 1.10933155370155,\n",
       " -0.510937573326197,\n",
       " 1.27826994710041,\n",
       " 0.185662513653259,\n",
       " -0.0582123607589716,\n",
       " -0.486227258790259,\n",
       " -1.75756247178124,\n",
       " 1.27667406097425,\n",
       " -1.59466782113548,\n",
       " 0.262822929695734,\n",
       " -1.70434875861064,\n",
       " 0.989797466710602,\n",
       " -0.295087858940278,\n",
       " 1.0701905522326,\n",
       " 0.719996544752459,\n",
       " -1.77027195288412,\n",
       " -0.781053698110154,\n",
       " 0.598727039920146,\n",
       " 1.27405959353085,\n",
       " -0.564093519025504,\n",
       " 0.642175654201316,\n",
       " -0.564048149341402,\n",
       " 1.0701905522326,\n",
       " -0.341824903278122,\n",
       " -1.96482417926198,\n",
       " 1.28467217835392,\n",
       " 0.706598918332718,\n",
       " 0.579274529984365,\n",
       " -0.102207934526366,\n",
       " 0.900709118925694,\n",
       " -0.376135420884919,\n",
       " 1.40949953018436,\n",
       " 0.926520122082437,\n",
       " -0.379685237733824,\n",
       " 0.634684332724337,\n",
       " 0.497609811563913,\n",
       " 0.0383048671980643,\n",
       " 0.829239603209405,\n",
       " 0.564354763650173,\n",
       " 0.48653387309903,\n",
       " -0.971258111375682,\n",
       " 0.23927090856685,\n",
       " 0.253071201445601,\n",
       " -0.581544630256631,\n",
       " -0.535129524307294,\n",
       " -1.4027362817954,\n",
       " -0.164872458589217,\n",
       " -0.953152602097117,\n",
       " 0.408712982547887,\n",
       " -0.213854141861258,\n",
       " -0.733801051217404,\n",
       " -1.48333542610263,\n",
       " -0.783441247075023,\n",
       " 0.641513194197249,\n",
       " 0.972099966217012,\n",
       " -1.46774305829811,\n",
       " 0.175250310894458,\n",
       " -1.22552571902612,\n",
       " -1.4027362817954,\n",
       " 0.419182111938213,\n",
       " -1.23285982636747,\n",
       " 0.265014180998248,\n",
       " 1.07403731052786,\n",
       " -0.460406660165596,\n",
       " -1.17071299050689,\n",
       " 0.755948714560977,\n",
       " -0.992063047372689,\n",
       " 1.0701905522326,\n",
       " 0.313082023708868,\n",
       " 1.03362830429051,\n",
       " -1.09024692596408,\n",
       " -1.99067343624685,\n",
       " 1.28191560319977,\n",
       " 0.968798289594455,\n",
       " -1.80918239815969,\n",
       " 0.855357038545309,\n",
       " -1.4328260350607,\n",
       " -0.596075155191685,\n",
       " 1.13808643198301,\n",
       " 0.814969791723953,\n",
       " -1.14770482847498,\n",
       " -0.246525665219529,\n",
       " 0.369802537272315,\n",
       " 0.0585189750677431,\n",
       " -1.12623472156049,\n",
       " -0.00996362436460503,\n",
       " 1.40949953018436,\n",
       " -0.779261527378905,\n",
       " 0.296070948612527,\n",
       " -0.216896895197801,\n",
       " 1.06281053932284,\n",
       " 0.28470623969371,\n",
       " -0.932858794576327,\n",
       " 0.978296273700086,\n",
       " 1.31592111393706,\n",
       " -2.12268477597773,\n",
       " -1.19999504666178,\n",
       " 1.10212913917881,\n",
       " -1.62317166694938,\n",
       " -0.717049409583369,\n",
       " 1.10230499578951,\n",
       " 0.0300867972781843,\n",
       " -0.0193019154834,\n",
       " -1.14685515734813,\n",
       " -2.19614552194098,\n",
       " -1.02571718725709,\n",
       " 0.978296273700086,\n",
       " -2.08155551508869,\n",
       " -0.430871108981201,\n",
       " -0.0150395288217961,\n",
       " 1.06077538369876,\n",
       " -1.30219792188555,\n",
       " 0.528581349166527,\n",
       " -0.992027214946222,\n",
       " -2.36691624176049,\n",
       " -1.14770482847498,\n",
       " 1.14801144278375,\n",
       " 0.876119110375324,\n",
       " -1.1087943831994,\n",
       " 1.27826994710041,\n",
       " 0.304296724621513,\n",
       " -1.55189857268501,\n",
       " 0.179978776659988,\n",
       " 0.440455703923149,\n",
       " 0.175250310894458,\n",
       " -0.621512892217109,\n",
       " 0.540367028974351,\n",
       " -1.26868535215846,\n",
       " -0.329814008843717,\n",
       " 0.0468204923308349,\n",
       " -1.30516983311103,\n",
       " -0.0696572594721942,\n",
       " -2.31501818674212,\n",
       " 0.0718174369251547,\n",
       " 0.875638325854746,\n",
       " -0.63848432233684,\n",
       " 0.0718174369251547,\n",
       " 1.31592111393706,\n",
       " 0.11459886653771,\n",
       " -0.900350648128308,\n",
       " 0.979734698812601,\n",
       " -0.0112751913917948,\n",
       " 0.0300867972781843,\n",
       " -0.379685237733824,\n",
       " 0.791352364108435,\n",
       " 0.657839617230895,\n",
       " 0.408712982547887,\n",
       " 0.495559062113284,\n",
       " 0.00479229747097395,\n",
       " 0.907023179435717,\n",
       " -1.46700226365005,\n",
       " 0.875638325854746,\n",
       " 1.05066505346354,\n",
       " -1.05899799038095,\n",
       " -1.20774914964979,\n",
       " 0.48653387309903,\n",
       " 0.603265208925745,\n",
       " 0.291981646721172,\n",
       " 0.758394347826551,\n",
       " 1.12727142153235,\n",
       " -1.43204991296795,\n",
       " 0.607304031883433,\n",
       " 0.544922191177836,\n",
       " -0.09699274989249,\n",
       " 1.13929835840446,\n",
       " -0.48427166364237,\n",
       " -0.172712233230048,\n",
       " 0.163078872945356,\n",
       " 1.16851268433334,\n",
       " 0.755948714560977,\n",
       " -0.637772075862252,\n",
       " 0.180721392604983,\n",
       " 1.12084246222882,\n",
       " 1.27590424447258,\n",
       " 0.14098017266066,\n",
       " -0.581544630256631,\n",
       " 0.534697724358764,\n",
       " 0.926520122082437,\n",
       " -1.35650092356657,\n",
       " -1.18502879913206,\n",
       " -2.12046596036426,\n",
       " -0.797510820994831,\n",
       " 0.376903944426195,\n",
       " -1.10987484581602,\n",
       " 0.253071201445601,\n",
       " 0.0718174369251547,\n",
       " -1.26868535215846,\n",
       " -1.23346354811633,\n",
       " -0.402789060597252,\n",
       " -0.218130719983525,\n",
       " 0.334625776914176,\n",
       " 1.14801144278375,\n",
       " 1.04302389002484,\n",
       " -1.33386905247995,\n",
       " -1.16325469537246,\n",
       " -1.30334660957726,\n",
       " -0.344545128191809,\n",
       " 0.23927090856685,\n",
       " -1.42413519480213,\n",
       " 1.0701905522326,\n",
       " -1.07059230219275,\n",
       " -1.4704492297673,\n",
       " 1.04468167218798,\n",
       " -1.34074852588581,\n",
       " 0.607304031883433,\n",
       " 0.872111010835791,\n",
       " 0.800113538039163,\n",
       " -0.190769976503235,\n",
       " -1.4324833364275,\n",
       " 0.451707688042341,\n",
       " -1.30700947870196,\n",
       " 0.914548771130317,\n",
       " -0.481354147843781,\n",
       " -1.73786132833773,\n",
       " -0.121529922887002,\n",
       " 0.468317777199008,\n",
       " 1.4059348392863,\n",
       " 0.0585189750677431,\n",
       " 1.05066505346354,\n",
       " -0.291675032412401,\n",
       " 0.540367028974351,\n",
       " -1.15989655423098,\n",
       " 0.136339865618886,\n",
       " -0.652761827800241,\n",
       " 1.12727142153235,\n",
       " 1.03128010695703,\n",
       " -1.1087943831994,\n",
       " -0.559919235090311,\n",
       " 0.406493023156187,\n",
       " -2.24434244131896,\n",
       " 0.875638325854746,\n",
       " 1.31592111393706,\n",
       " -0.0112751913917948,\n",
       " -0.866534515433376,\n",
       " -0.833021945706286,\n",
       " -1.09958954229816,\n",
       " -1.18723448071181,\n",
       " -0.430871108981201,\n",
       " -1.3763272186606,\n",
       " 1.40949953018436,\n",
       " 1.16851268433334,\n",
       " -1.26799312743916,\n",
       " -0.953152602097117,\n",
       " -0.246525665219529,\n",
       " 0.829759829702995,\n",
       " 1.01138250984028,\n",
       " 0.603113877397893,\n",
       " -1.86383893371079,\n",
       " -1.62317166694938,\n",
       " 0.180721392604983,\n",
       " 0.884241954570418,\n",
       " 0.719996544752459,\n",
       " 1.02921009516021,\n",
       " -0.0908001402654495,\n",
       " -2.19828685091541,\n",
       " -1.73786132833773,\n",
       " -1.23695139427351,\n",
       " 0.367028727303907,\n",
       " -0.296345507389176,\n",
       " 0.926520122082437,\n",
       " -0.304619423058557,\n",
       " 0.961031326948384,\n",
       " -0.397358539254111,\n",
       " 0.495914170923356,\n",
       " 0.41403413162775,\n",
       " -1.99583308993905,\n",
       " 0.922342675157862,\n",
       " 1.09563279213051,\n",
       " -0.63398929618739,\n",
       " 1.15937063285942,\n",
       " 1.38478199035282,\n",
       " -1.02571718725709,\n",
       " 0.914548771130317,\n",
       " -0.833021945706286,\n",
       " -0.904579217166058,\n",
       " 0.690942402274422,\n",
       " -0.631030521934587,\n",
       " 0.681086099476888,\n",
       " -0.0850246435223168,\n",
       " 0.291981646721172,\n",
       " 0.525444318374602,\n",
       " 0.418940575899193,\n",
       " 0.756711144595315,\n",
       " 0.876119110375324,\n",
       " -1.30334660957726,\n",
       " -1.09958954229816,\n",
       " 0.670641625528527,\n",
       " 0.700639537036547,\n",
       " -0.865310032116374,\n",
       " 1.01290466180783,\n",
       " 1.06281053932284,\n",
       " -2.45573327887905,\n",
       " 0.577192147961468,\n",
       " -1.40935238415628,\n",
       " 0.989797466710602,\n",
       " -1.08862345996662,\n",
       " -0.88169378228938,\n",
       " 0.681086099476888,\n",
       " -0.631030521934587,\n",
       " -1.38485265117887,\n",
       " 1.47720793355067,\n",
       " -2.15959033354874,\n",
       " -1.59466782113548,\n",
       " 1.0701905522326,\n",
       " -1.59022989529419,\n",
       " -1.62054791291846,\n",
       " 0.0783099145510313,\n",
       " 0.37271797660176,\n",
       " 0.608326484276941,\n",
       " 0.586294255246056,\n",
       " 0.741178037701597,\n",
       " -1.7020225684799,\n",
       " 0.515021160981687,\n",
       " -1.21524266829661,\n",
       " -1.18738825351849,\n",
       " -0.356869042585994,\n",
       " -1.26700502030908,\n",
       " 0.910308411792737,\n",
       " 0.71831182779596,\n",
       " -0.677766865960105,\n",
       " -1.22966642103051,\n",
       " -0.746331126250924,\n",
       " -0.252764587136829,\n",
       " -1.68921921850741,\n",
       " 0.977384239780983,\n",
       " 1.37707956533788,\n",
       " -1.67083618888355,\n",
       " 0.86318702926281,\n",
       " 0.585925829502245,\n",
       " 0.291981646721172,\n",
       " 0.165513106866101,\n",
       " 0.272619017338022,\n",
       " -1.54724786336601,\n",
       " -0.340255970190741,\n",
       " -0.971258111375682,\n",
       " -1.18723448071181,\n",
       " -1.1330580437527,\n",
       " 0.525444318374602,\n",
       " 0.920352322992141,\n",
       " -0.434019278718319,\n",
       " 0.0870105983706088,\n",
       " 0.219120709404338,\n",
       " -0.246525665219529,\n",
       " 0.875638325854746,\n",
       " 1.1740437247872,\n",
       " 0.586294255246056,\n",
       " 0.483313793502665,\n",
       " 0.0885164203515176,\n",
       " 0.500709442737836,\n",
       " -0.241671092187928,\n",
       " -0.548865626582772,\n",
       " 0.107884006505189,\n",
       " -1.80897244437611,\n",
       " -0.0885287116111344,\n",
       " 0.291981646721172,\n",
       " 0.961031326948384,\n",
       " -0.195940003025553,\n",
       " -0.823820570438701,\n",
       " 1.72007680147304,\n",
       " -1.26700502030908,\n",
       " 1.15937063285942,\n",
       " 0.214160756170029,\n",
       " 0.603265208925745,\n",
       " 1.22246729466657,\n",
       " -1.23116964849535,\n",
       " -1.36733755393449,\n",
       " 0.229574910778941,\n",
       " 0.334318659802405,\n",
       " -0.779261527378905,\n",
       " 1.3101425624288,\n",
       " 0.99236966168146,\n",
       " -0.284648153582344,\n",
       " -0.0492461679878697,\n",
       " -0.136033251310115,\n",
       " -1.63732361915646,\n",
       " -0.75860037571926,\n",
       " 0.972182822522608,\n",
       " -1.66855406702536,\n",
       " -0.0458777306939917,\n",
       " -1.30628756393234,\n",
       " -1.65218305936452,\n",
       " 0.987107045391448,\n",
       " -1.03384980805919,\n",
       " -0.63848432233684,\n",
       " -1.65983045654172,\n",
       " -0.790341698554976,\n",
       " 0.382983283095002,\n",
       " 1.0255063621908,\n",
       " 0.92999271151655,\n",
       " 0.292347609402157,\n",
       " -1.87440001422189,\n",
       " 0.23927090856685,\n",
       " -1.77027195288412,\n",
       " -1.43398521737853,\n",
       " 1.12923014071007,\n",
       " -0.397358539254111,\n",
       " 1.02752736478197,\n",
       " 0.00479229747097395,\n",
       " 1.06617184637462,\n",
       " -1.42007794540398,\n",
       " 1.16851268433334,\n",
       " 0.876119110375324,\n",
       " 1.40949953018436,\n",
       " -1.70434875861064,\n",
       " 0.291981646721172,\n",
       " 0.330892091996744,\n",
       " 1.09563279213051,\n",
       " -1.05899799038095,\n",
       " 0.419182111938213,\n",
       " 0.382861811868042,\n",
       " 0.473430026065269,\n",
       " -1.00965742817504,\n",
       " -0.52513770406583,\n",
       " 0.564354763650173,\n",
       " 0.214160756170029,\n",
       " 0.23915411187824,\n",
       " -1.52561359361464,\n",
       " -1.14770482847498,\n",
       " -0.258510043347204,\n",
       " 1.18692188805932,\n",
       " -0.0599155859935225,\n",
       " 0.225900885807531,\n",
       " 0.473968273650239,\n",
       " 0.257520026203694,\n",
       " -1.65272776646046,\n",
       " 1.40949953018436,\n",
       " 0.439592583267062,\n",
       " -1.77767808741152,\n",
       " 0.701947740974723,\n",
       " 0.932817422593748,\n",
       " 0.763375274232797,\n",
       " 0.330892091996744,\n",
       " -0.0285974957528473,\n",
       " 0.30120187818858,\n",
       " -0.559919235090311,\n",
       " -0.257268568254085,\n",
       " -1.34225705485283,\n",
       " -0.856060160977616,\n",
       " -0.992063047372689,\n",
       " -1.03097349264826,\n",
       " -0.402789060597252,\n",
       " -0.564048149341402,\n",
       " -1.14770482847498,\n",
       " 0.411117293401116,\n",
       " 0.272619017338022,\n",
       " -1.2355846352725,\n",
       " 0.0783099145510313,\n",
       " 0.331646285081327,\n",
       " 0.373024521701646,\n",
       " -2.27610774146655,\n",
       " -1.70434875861064,\n",
       " 1.16851268433334,\n",
       " 0.525444318374602,\n",
       " 1.16256503549545,\n",
       " -0.779261527378905,\n",
       " 1.0255063621908,\n",
       " -0.304619423058557,\n",
       " -0.174943696585686,\n",
       " -0.932247035025456,\n",
       " -0.0885287116111344,\n",
       " 0.222208368527447,\n",
       " 1.34930179720262,\n",
       " -0.932858794576327,\n",
       " -1.09773497636255,\n",
       " -0.430871108981201,\n",
       " -0.81766084417826,\n",
       " 1.08994759708681,\n",
       " -1.70434875861064,\n",
       " 0.621594397640184,\n",
       " -0.262877005934635,\n",
       " 0.913092906777817,\n",
       " -0.992063047372689,\n",
       " 0.813281151747804,\n",
       " 0.909684951356344,\n",
       " 0.0196085297921715,\n",
       " -1.77767808741152,\n",
       " -1.98116499583196,\n",
       " 1.12923014071007,\n",
       " 1.28467217835392,\n",
       " -0.299546735766103,\n",
       " 0.147166550128454,\n",
       " 0.707709536247056,\n",
       " -0.00996362436460503,\n",
       " 0.972182822522608,\n",
       " 0.719996544752459,\n",
       " 0.221082543490581,\n",
       " 0.573835530428892,\n",
       " 0.349987581279877,\n",
       " 1.12727142153235,\n",
       " 0.071808008610776,\n",
       " -1.56814856266174,\n",
       " -1.65354061705741,\n",
       " 1.16851268433334,\n",
       " -0.999184037934538,\n",
       " -0.130434065718029,\n",
       " 0.876119110375324,\n",
       " 0.292347609402157,\n",
       " 1.23783376309809,\n",
       " 0.429063024279698,\n",
       " 0.105276510065317,\n",
       " 1.33466174502193,\n",
       " -1.06988393792383,\n",
       " -0.702462893780194,\n",
       " 0.304296724621513,\n",
       " 1.0701905522326,\n",
       " -1.77767808741152,\n",
       " 1.40949953018436,\n",
       " -1.06612104084362,\n",
       " 0.861287270198005,\n",
       " 0.473968273650239,\n",
       " -0.719689930443688,\n",
       " -1.99019804198158,\n",
       " -1.14511008600648,\n",
       " -0.274241375533518,\n",
       " -0.910440724305693,\n",
       " 1.51818018465465,\n",
       " -1.49932207289429,\n",
       " -0.548865626582772,\n",
       " -0.894459477776971,\n",
       " -0.481354147843781,\n",
       " -0.341824903278122,\n",
       " -0.568377543224087,\n",
       " -1.40473269744839,\n",
       " -0.43021951320734,\n",
       " -1.35525127936924,\n",
       " -0.689242921649265,\n",
       " -0.308296499795993,\n",
       " -0.0162341031651332,\n",
       " 0.842606540648234,\n",
       " 1.16851268433334,\n",
       " 0.607304031883433,\n",
       " -1.97409080552784,\n",
       " -0.43021951320734,\n",
       " -0.206376342480928,\n",
       " -2.66712411643915,\n",
       " -0.430871108981201,\n",
       " 0.257520026203694,\n",
       " 1.05335462461849,\n",
       " -0.515949037009763,\n",
       " -0.218130719983525,\n",
       " -1.26799312743916,\n",
       " -1.22076013144799,\n",
       " 1.67969747810936,\n",
       " 1.07403731052786,\n",
       " 0.418940575899193,\n",
       " 0.09658283511177,\n",
       " -0.268982875926372,\n",
       " -1.70084513056344,\n",
       " 1.06281053932284,\n",
       " -0.834897040453163,\n",
       " -0.0620659972073883,\n",
       " 1.37707956533788,\n",
       " 1.09402340261556,\n",
       " -1.26680619562754,\n",
       " -1.46774305829811,\n",
       " -1.30040055102541,\n",
       " 0.884241954570418,\n",
       " 1.24475737737332,\n",
       " 0.993248980926827,\n",
       " -1.30219792188555,\n",
       " -1.67083618888355,\n",
       " -0.39526835938535,\n",
       " 0.681086099476888,\n",
       " 1.10910099750817,\n",
       " 1.24475737737332,\n",
       " 0.962998784292824,\n",
       " -0.719689930443688,\n",
       " 0.0655234422069162,\n",
       " -0.833021945706286,\n",
       " -1.27194458854253,\n",
       " 0.841583542065221,\n",
       " -0.482802158719479,\n",
       " -1.80897244437611,\n",
       " -0.0492461679878697,\n",
       " 0.914548771130317,\n",
       " 0.962998784292824,\n",
       " 0.0655234422069162,\n",
       " -0.641869039892545,\n",
       " 0.395815005362906,\n",
       " 0.993248980926827,\n",
       " -0.697967524843669,\n",
       " -0.09699274989249,\n",
       " -1.51626202555283,\n",
       " -0.369495922963544,\n",
       " -2.58256778141511,\n",
       " -1.66855406702536,\n",
       " 0.565946659941896,\n",
       " -0.831137946148934,\n",
       " 1.0701905522326,\n",
       " 0.447623427823459,\n",
       " -1.23346354811633,\n",
       " -0.284941429727458,\n",
       " -1.22966642103051,\n",
       " -0.184027794053265,\n",
       " 0.814969791723953,\n",
       " 0.884241954570418,\n",
       " -1.66855406702536,\n",
       " -2.17050352364416,\n",
       " -0.460406660165596,\n",
       " 0.291981646721172,\n",
       " 1.08994759708681,\n",
       " 0.758906990028031,\n",
       " 0.00479229747097395,\n",
       " -0.225492548362466,\n",
       " 0.564714560598538,\n",
       " -1.26868535215846,\n",
       " 0.595303118863663,\n",
       " 0.642175654201316,\n",
       " -0.856060160977616,\n",
       " 0.657567349510425,\n",
       " -1.1087943831994,\n",
       " 0.809093970921143,\n",
       " -1.61016992863868,\n",
       " -0.126473141789861,\n",
       " -0.695735501030716,\n",
       " 0.330892091996744,\n",
       " -1.30219792188555,\n",
       " -0.559919235090311,\n",
       " -0.971258111375682,\n",
       " 1.1497599683492,\n",
       " 0.408111519585134,\n",
       " -0.162471501571012,\n",
       " 0.32931896752932,\n",
       " -1.65354061705741,\n",
       " 1.40949953018436,\n",
       " -2.62630174894669,\n",
       " -1.10987484581602,\n",
       " -0.564048149341402,\n",
       " 1.63931815474568,\n",
       " -0.548865626582772,\n",
       " 1.27367351292414,\n",
       " -0.274241375533518,\n",
       " -1.63231414856146,\n",
       " -0.559919235090311,\n",
       " 0.640772533337974,\n",
       " 0.968798289594455,\n",
       " -0.430871108981201,\n",
       " -1.4704492297673,\n",
       " 0.440455703923149,\n",
       " -2.66712411643915,\n",
       " 0.0686014628819244,\n",
       " -1.1248553785731,\n",
       " 0.628444531108159,\n",
       " -0.992063047372689,\n",
       " -0.965715536479997,\n",
       " 1.31592111393706,\n",
       " 0.835750085171348,\n",
       " -1.0110088439584,\n",
       " -0.397358539254111,\n",
       " -0.965715536479997,\n",
       " 1.17626855661063,\n",
       " -2.1175079387829,\n",
       " 0.0686014628819244,\n",
       " -0.430871108981201,\n",
       " -1.70434875861064,\n",
       " 0.993248980926827,\n",
       " -0.520636691467046,\n",
       " 0.14528319028958,\n",
       " -1.3455701075556,\n",
       " -0.363506516973987,\n",
       " -1.44748460421017,\n",
       " 0.989797466710602,\n",
       " 1.40949953018436,\n",
       " 0.841963787058399,\n",
       " -1.08314219382245,\n",
       " 0.473968273650239,\n",
       " 0.865130426150909,\n",
       " 1.26338865075756,\n",
       " -1.14770482847498,\n",
       " -0.363282510298258,\n",
       " 0.640772533337974,\n",
       " 0.70061479017368,\n",
       " 0.706598918332718,\n",
       " -1.51864198975974,\n",
       " 1.47780086129097,\n",
       " 0.707709536247056,\n",
       " -1.28276570388248,\n",
       " -1.10987484581602,\n",
       " -1.20165401217182,\n",
       " -1.06609651062077,\n",
       " -1.57571972650626,\n",
       " 0.69320389664261,\n",
       " 0.977384239780983,\n",
       " 1.37707956533788,\n",
       " 1.06281053932284,\n",
       " 0.837204646485788,\n",
       " -1.38485265117887,\n",
       " 0.500709442737836,\n",
       " 0.103922759006272,\n",
       " -1.24649160387974,\n",
       " 1.33466174502193,\n",
       " 0.99236966168146,\n",
       " -2.66712411643915,\n",
       " 1.01107645710647,\n",
       " 0.607304031883433,\n",
       " 0.48653387309903,\n",
       " 0.876119110375324,\n",
       " -1.62054791291846,\n",
       " 0.138745011519858,\n",
       " -2.04264506981312,\n",
       " -0.169401316222573,\n",
       " -2.08125974412258,\n",
       " 1.12923014071007,\n",
       " -0.0582123607589716,\n",
       " -1.06612104084362,\n",
       " 1.25649604667355,\n",
       " -0.468659405814178,\n",
       " 0.00479229747097395,\n",
       " 0.291981646721172,\n",
       " 0.642175654201316,\n",
       " 0.129422940519542,\n",
       " 1.31592111393706,\n",
       " 0.257520026203694,\n",
       " 1.03362830429051,\n",
       " -0.356869042585994,\n",
       " 0.384805693494673,\n",
       " -0.00359956318197308,\n",
       " 1.19514559774522,\n",
       " -1.69881018639504,\n",
       " 1.27826994710041,\n",
       " 0.239150515883481,\n",
       " 0.695047175614041,\n",
       " 0.382202121221773,\n",
       " -2.00373462453755,\n",
       " 0.30120187818858,\n",
       " -0.81766084417826,\n",
       " -1.19843375478667,\n",
       " 1.14801144278375,\n",
       " -1.34875177416652,\n",
       " -0.763315239935053,\n",
       " -0.167093798857664,\n",
       " -1.47847546258359,\n",
       " -1.73191860151754,\n",
       " -1.06612104084362,\n",
       " 0.0947402695193354,\n",
       " -0.971258111375682,\n",
       " -1.53257009181108,\n",
       " 0.500709442737836,\n",
       " -0.00996362436460503,\n",
       " -0.0850246435223168,\n",
       " 0.306800483744294,\n",
       " -0.809006505715899,\n",
       " 0.180721392604983,\n",
       " -0.664063576980838,\n",
       " -0.397358539254111,\n",
       " 0.257520026203694,\n",
       " 0.758394347826551,\n",
       " 0.640772533337974,\n",
       " -1.10647583398445,\n",
       " 1.28191560319977,\n",
       " -0.397358539254111,\n",
       " -0.756331953206634,\n",
       " 1.40949953018436,\n",
       " -2.56332895987681,\n",
       " 0.914548771130317,\n",
       " 0.408712982547887,\n",
       " 1.24475737737332,\n",
       " 0.32931896752932,\n",
       " 0.140542876799583,\n",
       " 0.253071201445601,\n",
       " 1.12500429027107,\n",
       " -0.396751011752799,\n",
       " 1.03362830429051,\n",
       " -1.26799312743916,\n",
       " -0.229408504480094,\n",
       " -0.363506516973987,\n",
       " -0.688183878486488,\n",
       " -0.894459477776971,\n",
       " -0.447316813514687,\n",
       " 1.37707956533788,\n",
       " 0.841963787058399,\n",
       " -2.09806992039415,\n",
       " 0.253457304110579,\n",
       " 1.10212913917881,\n",
       " -0.756331953206634,\n",
       " 1.14801144278375,\n",
       " -0.797510820994831,\n",
       " -1.10647583398445,\n",
       " 1.40949953018436,\n",
       " 1.0701905522326,\n",
       " -0.229408504480094,\n",
       " 1.01138250984028,\n",
       " 0.103922759006272,\n",
       " -0.510937573326197,\n",
       " -0.674549859665813,\n",
       " -0.0620659972073883,\n",
       " 1.0701905522326,\n",
       " -0.442071604220517,\n",
       " -0.402137448640123,\n",
       " 0.295919343003049,\n",
       " 1.14801144278375,\n",
       " 0.841963787058399,\n",
       " -1.19746581154428,\n",
       " 0.607304031883433,\n",
       " 0.92062304968959,\n",
       " -1.14685515734813,\n",
       " -1.2408362182553,\n",
       " -1.62054791291846,\n",
       " -0.683895173702397,\n",
       " 0.909631680102414,\n",
       " 0.291981646721172,\n",
       " -1.70434875861064,\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt = '../data/MasterArbeit/data/data_scores'\n",
    "data_tgt = []\n",
    "with open(tgt) as fi:\n",
    "    for line in fi:\n",
    "        data_tgt.append(float(line.strip()))\n",
    "data_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.17366603836231"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(data_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = torch.rand(5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.5373  0.1000  0.3239  0.2236\n",
       " 0.6642  0.8575  0.1118  0.1466\n",
       " 0.0265  0.9292  0.8547  0.5076\n",
       " 0.6759  0.0811  0.2124  0.2080\n",
       " 0.6331  0.7333  0.4775  0.8177\n",
       "[torch.FloatTensor of size 5x4]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a1 = a[:,:2]\n",
    "a2 = a[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.5373  0.1000\n",
       " 0.6642  0.8575\n",
       " 0.0265  0.9292\n",
       " 0.6759  0.0811\n",
       " 0.6331  0.7333\n",
       "[torch.FloatTensor of size 5x2]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.3239  0.2236\n",
       " 0.1118  0.1466\n",
       " 0.8547  0.5076\n",
       " 0.2124  0.2080\n",
       " 0.4775  0.8177\n",
       "[torch.FloatTensor of size 5x2]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py27",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
