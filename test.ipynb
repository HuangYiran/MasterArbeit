{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_sys = file(\"./data/hidden_sys\")\n",
    "data_sys = np.load(file_sys)\n",
    "data_sys.shape\n",
    "file_sys.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_ref = open(\"./data/hidden_ref\")\n",
    "data_ref = np.load(file_ref)\n",
    "data_ref.shape\n",
    "file_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_scores = []\n",
    "with open(\"./data/data_scores\") as fi:\n",
    "    for line in fi:\n",
    "        data_scores.append(float(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.9131\n",
       " 0.1423\n",
       " 0.1597\n",
       "   ⋮   \n",
       " 1.0628\n",
       " 1.1250\n",
       " 0.8761\n",
       "[torch.FloatTensor of size 9392]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.1317e-01  1.9135e-01  4.8339e-02  ...   3.3562e-01  2.1015e-01 -3.0384e-01\n",
       " 6.9478e-01  6.4986e-01 -2.1220e-01  ...  -3.8425e-01 -6.4973e-01 -2.3927e-01\n",
       " 2.5970e-01  5.3346e-01  8.0853e-02  ...  -4.2903e-01 -3.2311e-01 -8.9193e-02\n",
       "                ...                   ⋱                   ...                \n",
       " 6.6741e-01  6.7923e-01  1.4909e-01  ...  -2.2978e-01 -3.1571e-01  1.3677e-01\n",
       " 2.5324e-02  1.3155e-01 -6.5003e-03  ...   4.0089e-01 -2.2887e-01 -3.4650e-01\n",
       " 4.1332e-01  5.0622e-01 -4.5596e-01  ...  -5.0268e-01 -3.7340e-01 -2.6541e-01\n",
       "[torch.FloatTensor of size 9392x1000]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(data_scores)\n",
    "b = torch.from_numpy(data_ref)\n",
    "c = torch.from_numpy(data_sys)\n",
    "d = torch.cat((c,b), 1)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(3248)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = range(len(data_scores))\n",
    "random.shuffle(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb = zip(d, a, tmp)\n",
    "comb = sorted(comb, key = lambda x: x[-1])\n",
    "d, a, tmp = zip(*comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.9131\n",
       " 0.1423\n",
       " 0.1597\n",
       "   ⋮   \n",
       " 1.0628\n",
       " 1.1250\n",
       " 0.8761\n",
       "[torch.FloatTensor of size 9392]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 3.1889e-01  6.3258e-01  1.1316e-01  ...  -4.0196e-01 -4.5356e-01 -4.0905e-01\n",
       " 4.2669e-01  5.7952e-01 -1.5267e-01  ...  -7.3717e-01 -5.4875e-01 -4.3146e-01\n",
       " 2.3961e-01  4.4815e-01 -3.0775e-01  ...  -7.1228e-01 -6.1418e-01 -2.2865e-01\n",
       "                ...                   ⋱                   ...                \n",
       " 3.0726e-01  4.2501e-01 -6.7688e-02  ...  -3.7334e-01 -6.1822e-01 -2.2931e-01\n",
       " 4.6479e-01  4.5037e-01  4.2272e-02  ...  -5.3935e-01 -3.9767e-01 -6.4714e-02\n",
       " 4.3281e-01  4.3685e-01 -4.6474e-02  ...  -6.4254e-01 -2.9456e-01 -4.9992e-01\n",
       "[torch.FloatTensor of size 9392x1000]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = d[0].view(1, -1)\n",
    "for i in range(1, len(d)):\n",
    "    tmp = torch.cat((tmp, d[i].view(1, -1)), 0)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 3.1889e-01  6.3258e-01  1.1316e-01  ...  -4.0196e-01 -4.5356e-01 -4.0905e-01\n",
       " 4.2669e-01  5.7952e-01 -1.5267e-01  ...  -7.3717e-01 -5.4875e-01 -4.3146e-01\n",
       " 2.3961e-01  4.4815e-01 -3.0775e-01  ...  -7.1228e-01 -6.1418e-01 -2.2865e-01\n",
       "                ...                   ⋱                   ...                \n",
       " 3.0726e-01  4.2501e-01 -6.7688e-02  ...  -3.7334e-01 -6.1822e-01 -2.2931e-01\n",
       " 4.6479e-01  4.5037e-01  4.2272e-02  ...  -5.3935e-01 -3.9767e-01 -6.4714e-02\n",
       " 4.3281e-01  4.3685e-01 -4.6474e-02  ...  -6.4254e-01 -2.9456e-01 -4.9992e-01\n",
       "[torch.FloatTensor of size 9392x1000]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'view'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-0706f0478fb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'view'"
     ]
    }
   ],
   "source": [
    "tmp = d[0][0].view(1, -1)\n",
    "for i in range(1, len(d)):\n",
    "    tmp = torch.cat((tmp, d[i][0].view(1, -1)), 0)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 8.8883e-23  1.4013e-45  7.8276e-23\n",
       "[torch.FloatTensor of size 1x3]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0][0].view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.Tensor(20, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = a[0:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.6434e-43  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.5593e-43  0.0000e+00  1.2916e+26 -1.2851e+17\n",
       " 6.2487e-29  1.4013e-45  8.8666e-23  1.4013e-45\n",
       "-3.1784e+15  1.4013e-45  0.0000e+00  1.4013e-45\n",
       "[torch.FloatTensor of size 10x4]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = a[10:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "-2.5641e+04  4.5863e-41  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "-2.5641e+04  4.5863e-41 -2.5641e+04  4.5863e-41\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.4472e-43  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00 -1.0898e+17  4.7161e-01\n",
       " 4.8357e-29  1.4013e-45  4.2008e-19  1.4013e-45\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "[torch.FloatTensor of size 10x4]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.6434e-43  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.5593e-43  0.0000e+00  1.2916e+26 -1.2851e+17\n",
       " 6.2487e-29  1.4013e-45  8.8666e-23  1.4013e-45\n",
       "-3.1784e+15  1.4013e-45  0.0000e+00  1.4013e-45\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "-2.5641e+04  4.5863e-41  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "-2.5641e+04  4.5863e-41 -2.5641e+04  4.5863e-41\n",
       " 0.0000e+00 -3.6893e+19 -7.8149e-22  2.0005e+00\n",
       " 3.4472e-43  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00 -1.0898e+17  4.7161e-01\n",
       " 4.8357e-29  1.4013e-45  4.2008e-19  1.4013e-45\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "[torch.FloatTensor of size 20x4]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 9\n",
    "b = 2\n",
    "c = round(a/b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = torch.Tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    a.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = torch.cat(a, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fmin\n",
    "import Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Params.Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'opt': 0, 'basic_drop_out_rate': 0.5683040090088415, 'basic_dim3': 3, 'basic_dim2': 1, 'basic_act_func': 2, 'basic_tgt': 0, 'basic_bn_momentum': 0.19338528925355508, 'basic_act_func_out': 2, 'basic_batch_size': 2, 'basic_lr': 0.011904082335539058"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic Linear\n",
    "pas = {'tgt': '../data/MasterArbeit/data/record_prepronce_cleaned', 'src_sys': '../data/MasterArbeit/data/hidden_value_pred', 'src_ref': '../data/MasterArbeit/data/hidden_value_ref', 'optim': 'Adam','loss_fn': 'MSELoss', 'batch_size': 100, 'dim2': 100, 'dim3': 10, 'lr': 0.00592636698766986, 'act_func': 'LeakyReLU', 'act_func_out': None, 'model': './model/LinearModel', 'type': 'linear', 'momentum': 0.19338528925355508, 'drop_out_rate': 0.5683040090088415}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bi Linear\n",
    "pas1 = {'dim2': 10, 'act_func_out': None, 'tgt': '../data/MasterArbeit/data/data_scores', 'src_sys': '../data/MasterArbeit/data/sys_hidden', 'src_ref': '../data/MasterArbeit/data/ref_hidden', 'batch_size': 100, 'lr': 0.01592636698766986, 'act_func': 'LeakyReLU', 'act_func_out': None , 'model': 'BiLinear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Masked\n",
    "pas2 = {'dim2': 10, 'tgt': '../data/MasterArbeit/data/data_scores', 'src_sys': '../data/MasterArbeit/data/sys_hidden', 'src_ref': '../data/MasterArbeit/data/ref_hidden', 'batch_size': 100, 'lr': 0.005592636698766986, 'act_func': 'Tanh', 'model': 'MaskedModel1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BasicLinear_dropout\n",
    "pas3 = {'tgt': '../data/MasterArbeit/data/data_scores', 'src_sys': '../data/MasterArbeit/data/sys_hidden', 'src_ref': '../data/MasterArbeit/data/ref_hidden', 'batch_size': 100, 'dim2': 100, 'dim3': 10, 'lr': 0.01592636698766986, 'act_func': 'LeakyReLU', 'act_func_out': None, 'model': 'BasicLinearDropout', 'type': 'linear', 'momentum': 0.19338528925355508, 'drop_out_rate': 0.5683040090088415}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MultiHeadLSTMModel\n",
    "pas = {'model': 'MultiHeadAttnLSTMModel',\n",
    "       'tgt': '../data/MasterArbeit/data2/record_NIST_dev2015_clean', \n",
    "       'src_sys': '../data/MasterArbeit/data2/hidden_pred_preprodev2015',\n",
    "       'src_ref': '../data/MasterArbeit/data2/hidden_ref_preprodev2015',\n",
    "       'val_tgt': '../data/MasterArbeit/data2/record_NIST_tst2016_clean',\n",
    "       'src_val_sys': '../data/MasterArbeit/data2/hidden_pred_preprotst2016',\n",
    "       'src_val_ref': '../data/MasterArbeit/data2/hidden_ref_preprotst2016',\n",
    "       'test_tgt': '../data/MasterArbeit/data2/record_NIST_tst2016_clean',\n",
    "       'src_test_sys': '../data/MasterArbeit/data2/hidden_pred_preprotst2016',\n",
    "       'src_test_ref': '../data/MasterArbeit/data2/hidden_ref_preprotst2016',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Test\n",
    "pas = {\n",
    "      'tgt': '../data/MasterArbeit/test/train_scores',\n",
    "      'src_sys': '../data/MasterArbeit/test/train_sys_hidden',\n",
    "      'src_ref': '../data/MasterArbeit/test/train_ref_hidden',\n",
    "      'tgt_val': '../data/MasterArbeit/test/val_scores',\n",
    "      'src_val_sys': '../data/MasterArbeit/test/val_sys_hidden',\n",
    "      'src_val_ref': '../data/MasterArbeit/test/val_ref_hidden',\n",
    "      'tgt_test': '../data/MasterArbeit/test/test_scores',\n",
    "      'src_test_sys': '../data/MasterArbeit/test/test_sys_hidden',\n",
    "      'src_test_ref': '../data/MasterArbeit/test/test_ref_hidden',\n",
    "      'optim': 'Adam',\n",
    "      'loss_fn': 'MSELoss', \n",
    "      'batch_size': 100, \n",
    "      'dim2': 100, \n",
    "      'dim3': 10, \n",
    "      'lr': 0.00592636698766986, \n",
    "      'act_func': 'LeakyReLU', \n",
    "      'act_func_out': None, \n",
    "      'model': 'BasicLinear',\n",
    "      'type': 'linear', \n",
    "      'momentum': 0.19338528925355508, \n",
    "      'drop_out_rate': 0.5683040090088415,\n",
    "      'loss_fn': 'MSECorrLoss'\n",
    "     # 'isRandom': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# R\n",
    "pas = {\n",
    "      'tgt': '../data/MasterArbeit/test2/train_scores',\n",
    "      'src_sys': '../data/MasterArbeit/test2/train_sys_hidden',\n",
    "      'src_ref': '../data/MasterArbeit/test2/train_ref_hidden',\n",
    "      'tgt_val': '../data/MasterArbeit/test2/val_scores',\n",
    "      'src_val_sys': '../data/MasterArbeit/test2/val_sys_hidden',\n",
    "      'src_val_ref': '../data/MasterArbeit/test2/val_ref_hidden',\n",
    "      'tgt_test': '../data/MasterArbeit/test2/test_scores',\n",
    "      'src_test_sys': '../data/MasterArbeit/test2/test_sys_hidden',\n",
    "      'src_test_ref': '../data/MasterArbeit/test2/test_ref_hidden',\n",
    "      'model': 'MultiHeadAttnConvModel',\n",
    "     # 'isRandom': True\n",
    "      'num_dim_k': 16,\n",
    "      'num_dim_v': 16,\n",
    "      'num_head': 4,\n",
    "      'kernel_size1': 2,\n",
    "      'stride1': 1,\n",
    "      'kernel_size2': 3,\n",
    "      'stride2': 1,\n",
    "      'batch_size': 50,\n",
    "      'debug': True,\n",
    "      'loss_fn': 'MSECorrLoss'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_head = opt.num_head, num_dim_k = opt.num_dim_k, num_dim_v = opt.num_dim_v, d_rate_attn = opt.d_rate_attn, act_func1 = opt.act_func1, dim2 = opt.dim2, act_func2 = opt.act_func2)<br>\n",
    "pas1 = {'dim2': 10, 'act_func_out': None, 'tgt': '../data/MasterArbeit/data/normalized_data_scores', 'src_sys': '../data/MasterArbeit/data/sys_hidden', 'src_ref': '../data/MasterArbeit/data/ref_hidden', 'batch_size': 100, 'lr': 0.01592636698766986, 'act_func': 'Tanh', 'model': 'BasicLinearDropout'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt.set_params(pas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MultiHeadAttnConvModel'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('act_func1', 'LeakyReLU')\n",
      "('act_func_out', None)\n",
      "('tgt', '../data/MasterArbeit/test2/train_scores')\n",
      "('loss_fn', 'MSECorrLoss')\n",
      "('isRandom', False)\n",
      "('src_test_sys', '../data/MasterArbeit/test2/test_sys_hidden')\n",
      "('dim2', 500)\n",
      "('dim3', None)\n",
      "('dim1', 20)\n",
      "('weight_decay', 0)\n",
      "('out', './pred')\n",
      "('kernel_size2', 3)\n",
      "('kernel_size1', 2)\n",
      "('src_test_ref', '../data/MasterArbeit/test2/test_ref_hidden')\n",
      "('tgt_test', '../data/MasterArbeit/test2/test_scores')\n",
      "('checkpoint', './checkpoints/cp1')\n",
      "('num_dim_k', 16)\n",
      "('tgt_val', '../data/MasterArbeit/test2/val_scores')\n",
      "('lr', 0.02)\n",
      "('act_func', 'ReLU')\n",
      "('drop_out_rate', 0.5)\n",
      "('momentum', 0.1)\n",
      "('src_val_ref', '../data/MasterArbeit/test2/val_ref_hidden')\n",
      "('resume', False)\n",
      "('optim', 'Adam')\n",
      "('batch_size', 50)\n",
      "('src_val_sys', '../data/MasterArbeit/test2/val_sys_hidden')\n",
      "('num_head', 4)\n",
      "('num_dim_v', 16)\n",
      "('stride2', 1)\n",
      "('src_sys', '../data/MasterArbeit/test2/train_sys_hidden')\n",
      "('act_func2', 'LeakyReLU')\n",
      "('src_ref', '../data/MasterArbeit/test2/train_ref_hidden')\n",
      "('eps', 1e-08)\n",
      "('d_rate_attn', 0.1)\n",
      "('stride1', 1)\n",
      "('cuda', False)\n",
      "('debug', True)\n",
      "('model', 'MultiHeadAttnConvModel')\n",
      "MultiHeadAttnConvModel (\n",
      "  (attn): MultiHeadAttention (\n",
      "    (attention): ScaledDotProductAttention (\n",
      "      (dropout): Dropout (p = 0.1)\n",
      "      (softmax): Softmax ()\n",
      "    )\n",
      "    (project): Linear (\n",
      "      (li): Linear (64 -> 500)\n",
      "    )\n",
      "    (dropout): Dropout (p = 0.1)\n",
      "  )\n",
      "  (layers): Sequential (\n",
      "    (conv1): Conv1d(100, 20, kernel_size=(2,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (act_fun1): LeakyReLU (0.01)\n",
      "    (conv2): Conv1d(20, 1, kernel_size=(3,), stride=(1,))\n",
      "  )\n",
      "  (li): Linear (497 -> 1)\n",
      ")\n",
      "initializing the model...\n",
      "=> spring the self defined model and the model that doesn't need the initialization\n",
      "Dropout (p = 0.1)\n",
      "=> spring the self defined model and the model that doesn't need the initialization\n",
      "Softmax ()\n",
      "=> spring the self defined model and the model that doesn't need the initialization\n",
      "ScaledDotProductAttention (\n",
      "  (dropout): Dropout (p = 0.1)\n",
      "  (softmax): Softmax ()\n",
      ")\n",
      "=> initializing Linear model\n",
      "Linear (64 -> 500)\n",
      "=> spring the self defined model and the model that doesn't need the initialization\n",
      "Linear (\n",
      "  (li): Linear (64 -> 500)\n",
      ")\n",
      "=> spring the self defined model and the model that doesn't need the initialization\n",
      "Dropout (p = 0.1)\n",
      "=> spring the self defined model and the model that doesn't need the initialization\n",
      "MultiHeadAttention (\n",
      "  (attention): ScaledDotProductAttention (\n",
      "    (dropout): Dropout (p = 0.1)\n",
      "    (softmax): Softmax ()\n",
      "  )\n",
      "  (project): Linear (\n",
      "    (li): Linear (64 -> 500)\n",
      "  )\n",
      "  (dropout): Dropout (p = 0.1)\n",
      ")\n",
      "=> initiliazing conv1d\n",
      "Conv1d(100, 20, kernel_size=(2,), stride=(1,))\n",
      "=> initializing BatchNorm1d\n",
      "BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True)\n",
      "=> spring the self defined model and the model that doesn't need the initialization\n",
      "LeakyReLU (0.01)\n",
      "=> initiliazing conv1d\n",
      "Conv1d(20, 1, kernel_size=(3,), stride=(1,))\n",
      "=> spring the self defined model and the model that doesn't need the initialization\n",
      "Sequential (\n",
      "  (conv1): Conv1d(100, 20, kernel_size=(2,), stride=(1,))\n",
      "  (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (act_fun1): LeakyReLU (0.01)\n",
      "  (conv2): Conv1d(20, 1, kernel_size=(3,), stride=(1,))\n",
      ")\n",
      "=> initializing Linear model\n",
      "Linear (497 -> 1)\n",
      "=> spring the self defined model and the model that doesn't need the initialization\n",
      "MultiHeadAttnConvModel (\n",
      "  (attn): MultiHeadAttention (\n",
      "    (attention): ScaledDotProductAttention (\n",
      "      (dropout): Dropout (p = 0.1)\n",
      "      (softmax): Softmax ()\n",
      "    )\n",
      "    (project): Linear (\n",
      "      (li): Linear (64 -> 500)\n",
      "    )\n",
      "    (dropout): Dropout (p = 0.1)\n",
      "  )\n",
      "  (layers): Sequential (\n",
      "    (conv1): Conv1d(100, 20, kernel_size=(2,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (act_fun1): LeakyReLU (0.01)\n",
      "    (conv2): Conv1d(20, 1, kernel_size=(3,), stride=(1,))\n",
      "  )\n",
      "  (li): Linear (497 -> 1)\n",
      ")\n",
      "number of batch is 150 \n",
      "number of val batch 18 \n",
      "number of test batch 18\n",
      "evaluate 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ihuangyiran/anaconda2/envs/py27/lib/python2.7/site-packages/numpy/lib/function_base.py:3167: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/ihuangyiran/anaconda2/envs/py27/lib/python2.7/site-packages/numpy/lib/function_base.py:3168: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the corr is nan, which means the variance of the scores is 0\n",
      "the correlation coeffizient is : 0.000000\n",
      "the mean loss is 3.887150\n",
      "save checkpoint 0\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 1\n",
      "the correlation coeffizient is : 0.007486\n",
      "the mean loss is 150.159775\n",
      "save checkpoint 1\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 2\n",
      "the correlation coeffizient is : 0.179423\n",
      "the mean loss is 5.462531\n",
      "save checkpoint 2\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 3\n",
      "the correlation coeffizient is : -0.107991\n",
      "the mean loss is 4.232353\n",
      "save checkpoint 3\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 4\n",
      "the correlation coeffizient is : 0.066340\n",
      "the mean loss is 1.575798\n",
      "save checkpoint 4\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 5\n",
      "the correlation coeffizient is : 0.128327\n",
      "the mean loss is 0.911417\n",
      "save checkpoint 5\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 6\n",
      "the correlation coeffizient is : -0.028175\n",
      "the mean loss is 1.043194\n",
      "save checkpoint 6\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 7\n",
      "the correlation coeffizient is : 0.082215\n",
      "the mean loss is 0.666265\n",
      "save checkpoint 7\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 8\n",
      "the correlation coeffizient is : 0.089162\n",
      "the mean loss is 0.937125\n",
      "save checkpoint 8\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 9\n",
      "the correlation coeffizient is : -0.014247\n",
      "the mean loss is 1.198690\n",
      "save checkpoint 9\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 10\n",
      "the correlation coeffizient is : 0.013565\n",
      "the mean loss is 1.006626\n",
      "save checkpoint 10\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 11\n",
      "the correlation coeffizient is : -0.024299\n",
      "the mean loss is 0.878051\n",
      "save checkpoint 11\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 12\n",
      "the correlation coeffizient is : 0.055050\n",
      "the mean loss is 0.975122\n",
      "save checkpoint 12\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 13\n",
      "the correlation coeffizient is : -0.313280\n",
      "the mean loss is 1.084527\n",
      "save checkpoint 13\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 14\n",
      "the correlation coeffizient is : 0.359747\n",
      "the mean loss is 1.125883\n",
      "save checkpoint 14\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 15\n",
      "the correlation coeffizient is : -0.022532\n",
      "the mean loss is 1.099144\n",
      "save checkpoint 15\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 16\n",
      "the correlation coeffizient is : 0.125207\n",
      "the mean loss is 1.073832\n",
      "save checkpoint 16\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 17\n",
      "the correlation coeffizient is : 0.101342\n",
      "the mean loss is 1.015074\n",
      "save checkpoint 17\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 18\n",
      "the correlation coeffizient is : 0.241578\n",
      "the mean loss is 0.946695\n",
      "save checkpoint 18\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 19\n",
      "the correlation coeffizient is : -0.049759\n",
      "the mean loss is 1.084920\n",
      "save checkpoint 19\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 20\n",
      "the correlation coeffizient is : 0.200957\n",
      "the mean loss is 1.074218\n",
      "save checkpoint 20\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 21\n",
      "the correlation coeffizient is : 0.138291\n",
      "the mean loss is 0.935785\n",
      "save checkpoint 21\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 22\n",
      "the correlation coeffizient is : 0.126661\n",
      "the mean loss is 1.152703\n",
      "save checkpoint 22\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 23\n",
      "the correlation coeffizient is : 0.175811\n",
      "the mean loss is 0.805975\n",
      "save checkpoint 23\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 24\n",
      "the correlation coeffizient is : 0.274744\n",
      "the mean loss is 1.039406\n",
      "save checkpoint 24\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 25\n",
      "the correlation coeffizient is : 0.059417\n",
      "the mean loss is 1.109940\n",
      "save checkpoint 25\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 26\n",
      "the correlation coeffizient is : 0.134405\n",
      "the mean loss is 0.938850\n",
      "save checkpoint 26\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 27\n",
      "the correlation coeffizient is : 0.089504\n",
      "the mean loss is 1.178290\n",
      "save checkpoint 27\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 28\n",
      "the correlation coeffizient is : 0.272058\n",
      "the mean loss is 0.940012\n",
      "save checkpoint 28\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 29\n",
      "the correlation coeffizient is : 0.107593\n",
      "the mean loss is 0.889487\n",
      "save checkpoint 29\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 30\n",
      "the correlation coeffizient is : 0.082974\n",
      "the mean loss is 0.939409\n",
      "save checkpoint 30\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 31\n",
      "the correlation coeffizient is : 0.137521\n",
      "the mean loss is 0.936584\n",
      "save checkpoint 31\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 32\n",
      "the correlation coeffizient is : 0.020463\n",
      "the mean loss is 1.204952\n",
      "save checkpoint 32\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 33\n",
      "the correlation coeffizient is : 0.180280\n",
      "the mean loss is 1.031946\n",
      "save checkpoint 33\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 34\n",
      "the correlation coeffizient is : 0.412491\n",
      "the mean loss is 0.936956\n",
      "save checkpoint 34\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 35\n",
      "the correlation coeffizient is : 0.246792\n",
      "the mean loss is 1.064006\n",
      "save checkpoint 35\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 36\n",
      "the correlation coeffizient is : 0.360240\n",
      "the mean loss is 0.922498\n",
      "save checkpoint 36\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 37\n",
      "the correlation coeffizient is : 0.087290\n",
      "the mean loss is 1.086685\n",
      "save checkpoint 37\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 38\n",
      "the correlation coeffizient is : 0.321210\n",
      "the mean loss is 0.978672\n",
      "save checkpoint 38\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 39\n",
      "the correlation coeffizient is : 0.196770\n",
      "the mean loss is 0.907011\n",
      "save checkpoint 39\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 40\n",
      "the correlation coeffizient is : 0.428150\n",
      "the mean loss is 0.956462\n",
      "save checkpoint 40\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 41\n",
      "the correlation coeffizient is : 0.353328\n",
      "the mean loss is 0.713906\n",
      "save checkpoint 41\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 42\n",
      "the correlation coeffizient is : 0.198144\n",
      "the mean loss is 1.054335\n",
      "save checkpoint 42\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 43\n",
      "the correlation coeffizient is : 0.354203\n",
      "the mean loss is 0.590221\n",
      "save checkpoint 43\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 44\n",
      "the correlation coeffizient is : 0.324512\n",
      "the mean loss is 0.842841\n",
      "save checkpoint 44\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 45\n",
      "the correlation coeffizient is : 0.310288\n",
      "the mean loss is 1.062283\n",
      "save checkpoint 45\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 46\n",
      "the correlation coeffizient is : 0.413224\n",
      "the mean loss is 0.813131\n",
      "save checkpoint 46\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 47\n",
      "the correlation coeffizient is : 0.287154\n",
      "the mean loss is 0.788372\n",
      "save checkpoint 47\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 48\n",
      "the correlation coeffizient is : 0.303605\n",
      "the mean loss is 0.847596\n",
      "save checkpoint 48\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 49\n",
      "the correlation coeffizient is : 0.170745\n",
      "the mean loss is 0.937246\n",
      "save checkpoint 49\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 50\n",
      "the correlation coeffizient is : 0.066586\n",
      "the mean loss is 1.201165\n",
      "save checkpoint 50\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 51\n",
      "the correlation coeffizient is : 0.531100\n",
      "the mean loss is 0.807645\n",
      "save checkpoint 51\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 52\n",
      "the correlation coeffizient is : 0.450415\n",
      "the mean loss is 0.872486\n",
      "save checkpoint 52\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 53\n",
      "the correlation coeffizient is : 0.330279\n",
      "the mean loss is 0.992050\n",
      "save checkpoint 53\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 54\n",
      "the correlation coeffizient is : 0.233386\n",
      "the mean loss is 0.961796\n",
      "save checkpoint 54\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 55\n",
      "the correlation coeffizient is : 0.323188\n",
      "the mean loss is 0.990601\n",
      "save checkpoint 55\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 56\n",
      "the correlation coeffizient is : 0.466698\n",
      "the mean loss is 0.851385\n",
      "save checkpoint 56\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 57\n",
      "the correlation coeffizient is : 0.284676\n",
      "the mean loss is 0.866114\n",
      "save checkpoint 57\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 58\n",
      "the correlation coeffizient is : 0.500307\n",
      "the mean loss is 0.853149\n",
      "save checkpoint 58\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 59\n",
      "the correlation coeffizient is : 0.477396\n",
      "the mean loss is 0.627021\n",
      "save checkpoint 59\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 60\n",
      "the correlation coeffizient is : 0.404793\n",
      "the mean loss is 0.881925\n",
      "save checkpoint 60\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 61\n",
      "the correlation coeffizient is : 0.450830\n",
      "the mean loss is 0.529480\n",
      "save checkpoint 61\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 62\n",
      "the correlation coeffizient is : 0.473050\n",
      "the mean loss is 0.795650\n",
      "save checkpoint 62\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 63\n",
      "the correlation coeffizient is : 0.433993\n",
      "the mean loss is 1.014724\n",
      "save checkpoint 63\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 64\n",
      "the correlation coeffizient is : 0.313333\n",
      "the mean loss is 0.833106\n",
      "save checkpoint 64\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 65\n",
      "the correlation coeffizient is : 0.328607\n",
      "the mean loss is 0.773788\n",
      "save checkpoint 65\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 66\n",
      "the correlation coeffizient is : 0.447445\n",
      "the mean loss is 0.746587\n",
      "save checkpoint 66\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 67\n",
      "the correlation coeffizient is : -0.026913\n",
      "the mean loss is 1.149748\n",
      "save checkpoint 67\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 68\n",
      "the correlation coeffizient is : 0.232984\n",
      "the mean loss is 1.163085\n",
      "save checkpoint 68\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 69\n",
      "the correlation coeffizient is : 0.553664\n",
      "the mean loss is 0.743147\n",
      "save checkpoint 69\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 70\n",
      "the correlation coeffizient is : 0.402936\n",
      "the mean loss is 0.892601\n",
      "save checkpoint 70\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 71\n",
      "the correlation coeffizient is : 0.424687\n",
      "the mean loss is 0.858185\n",
      "save checkpoint 71\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 72\n",
      "the correlation coeffizient is : 0.214946\n",
      "the mean loss is 1.139964\n",
      "save checkpoint 72\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 73\n",
      "the correlation coeffizient is : 0.412722\n",
      "the mean loss is 0.955758\n",
      "save checkpoint 73\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 74\n",
      "the correlation coeffizient is : 0.487724\n",
      "the mean loss is 0.829126\n",
      "save checkpoint 74\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 75\n",
      "the correlation coeffizient is : 0.532563\n",
      "the mean loss is 0.792076\n",
      "save checkpoint 75\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 76\n",
      "the correlation coeffizient is : 0.459785\n",
      "the mean loss is 0.868383\n",
      "save checkpoint 76\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 77\n",
      "the correlation coeffizient is : 0.480620\n",
      "the mean loss is 0.623277\n",
      "save checkpoint 77\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 78\n",
      "the correlation coeffizient is : 0.538370\n",
      "the mean loss is 0.760862\n",
      "save checkpoint 78\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 79\n",
      "the correlation coeffizient is : 0.452218\n",
      "the mean loss is 0.533116\n",
      "save checkpoint 79\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 80\n",
      "the correlation coeffizient is : 0.383431\n",
      "the mean loss is 0.808800\n",
      "save checkpoint 80\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 81\n",
      "the correlation coeffizient is : 0.470334\n",
      "the mean loss is 0.913422\n",
      "save checkpoint 81\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 82\n",
      "the correlation coeffizient is : 0.422684\n",
      "the mean loss is 0.786595\n",
      "save checkpoint 82\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 83\n",
      "the correlation coeffizient is : 0.409305\n",
      "the mean loss is 0.753411\n",
      "save checkpoint 83\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 84\n",
      "the correlation coeffizient is : 0.337215\n",
      "the mean loss is 0.890090\n",
      "save checkpoint 84\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 85\n",
      "the correlation coeffizient is : 0.388388\n",
      "the mean loss is 0.781120\n",
      "save checkpoint 85\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 86\n",
      "the correlation coeffizient is : 0.177723\n",
      "the mean loss is 1.269649\n",
      "save checkpoint 86\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 87\n",
      "the correlation coeffizient is : 0.590294\n",
      "the mean loss is 0.687303\n",
      "save checkpoint 87\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 88\n",
      "the correlation coeffizient is : 0.454624\n",
      "the mean loss is 0.860532\n",
      "save checkpoint 88\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 89\n",
      "the correlation coeffizient is : 0.446874\n",
      "the mean loss is 0.828759\n",
      "save checkpoint 89\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 90\n",
      "the correlation coeffizient is : 0.182585\n",
      "the mean loss is 1.083115\n",
      "save checkpoint 90\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 91\n",
      "the correlation coeffizient is : 0.434319\n",
      "the mean loss is 0.939914\n",
      "save checkpoint 91\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 92\n",
      "the correlation coeffizient is : 0.493083\n",
      "the mean loss is 0.996263\n",
      "save checkpoint 92\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 93\n",
      "the correlation coeffizient is : 0.466333\n",
      "the mean loss is 0.830450\n",
      "save checkpoint 93\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 94\n",
      "the correlation coeffizient is : 0.446766\n",
      "the mean loss is 0.900567\n",
      "save checkpoint 94\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 95\n",
      "the correlation coeffizient is : 0.417093\n",
      "the mean loss is 0.673826\n",
      "save checkpoint 95\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 96\n",
      "the correlation coeffizient is : 0.570713\n",
      "the mean loss is 0.751893\n",
      "save checkpoint 96\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 97\n",
      "the correlation coeffizient is : 0.505224\n",
      "the mean loss is 0.500843\n",
      "save checkpoint 97\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 98\n",
      "the correlation coeffizient is : 0.446947\n",
      "the mean loss is 0.754295\n",
      "save checkpoint 98\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 99\n",
      "the correlation coeffizient is : 0.403388\n",
      "the mean loss is 1.005767\n",
      "save checkpoint 99\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 100\n",
      "the correlation coeffizient is : 0.415446\n",
      "the mean loss is 0.845792\n",
      "save checkpoint 100\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 101\n",
      "the correlation coeffizient is : 0.495808\n",
      "the mean loss is 0.698649\n",
      "save checkpoint 101\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 102\n",
      "the correlation coeffizient is : 0.470086\n",
      "the mean loss is 0.734243\n",
      "save checkpoint 102\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 103\n",
      "the correlation coeffizient is : 0.328192\n",
      "the mean loss is 0.853291\n",
      "save checkpoint 103\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 104\n",
      "the correlation coeffizient is : 0.221787\n",
      "the mean loss is 1.344517\n",
      "save checkpoint 104\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 105\n",
      "the correlation coeffizient is : 0.619890\n",
      "the mean loss is 0.651299\n",
      "save checkpoint 105\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 106\n",
      "the correlation coeffizient is : 0.587023\n",
      "the mean loss is 0.715876\n",
      "save checkpoint 106\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 107\n",
      "the correlation coeffizient is : 0.384791\n",
      "the mean loss is 0.939494\n",
      "save checkpoint 107\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 108\n",
      "the correlation coeffizient is : 0.232129\n",
      "the mean loss is 1.026262\n",
      "save checkpoint 108\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 109\n",
      "the correlation coeffizient is : 0.520728\n",
      "the mean loss is 0.889037\n",
      "save checkpoint 109\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 110\n",
      "the correlation coeffizient is : 0.514279\n",
      "the mean loss is 0.895992\n",
      "save checkpoint 110\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 111\n",
      "the correlation coeffizient is : 0.433457\n",
      "the mean loss is 0.802766\n",
      "save checkpoint 111\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 112\n",
      "the correlation coeffizient is : 0.485722\n",
      "the mean loss is 0.890570\n",
      "save checkpoint 112\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 113\n",
      "the correlation coeffizient is : 0.369329\n",
      "the mean loss is 0.787917\n",
      "save checkpoint 113\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 114\n",
      "the correlation coeffizient is : 0.525916\n",
      "the mean loss is 0.745640\n",
      "save checkpoint 114\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 115\n",
      "the correlation coeffizient is : 0.497258\n",
      "the mean loss is 0.528463\n",
      "save checkpoint 115\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 116\n",
      "the correlation coeffizient is : 0.458703\n",
      "the mean loss is 0.760554\n",
      "save checkpoint 116\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 117\n",
      "the correlation coeffizient is : 0.372881\n",
      "the mean loss is 1.094223\n",
      "save checkpoint 117\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 118\n",
      "the correlation coeffizient is : 0.427828\n",
      "the mean loss is 0.831269\n",
      "save checkpoint 118\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 119\n",
      "the correlation coeffizient is : 0.485628\n",
      "the mean loss is 0.690442\n",
      "save checkpoint 119\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 120\n",
      "the correlation coeffizient is : 0.345298\n",
      "the mean loss is 0.896003\n",
      "save checkpoint 120\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 121\n",
      "the correlation coeffizient is : 0.378807\n",
      "the mean loss is 0.909869\n",
      "save checkpoint 121\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 122\n",
      "the correlation coeffizient is : 0.186335\n",
      "the mean loss is 1.384767\n",
      "save checkpoint 122\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 123\n",
      "the correlation coeffizient is : 0.512426\n",
      "the mean loss is 0.802946\n",
      "save checkpoint 123\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 124\n",
      "the correlation coeffizient is : 0.615745\n",
      "the mean loss is 0.687084\n",
      "save checkpoint 124\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 125\n",
      "the correlation coeffizient is : 0.470003\n",
      "the mean loss is 0.845564\n",
      "save checkpoint 125\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 126\n",
      "the correlation coeffizient is : 0.194414\n",
      "the mean loss is 1.073150\n",
      "save checkpoint 126\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 127\n",
      "the correlation coeffizient is : 0.486358\n",
      "the mean loss is 0.906880\n",
      "save checkpoint 127\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 128\n",
      "the correlation coeffizient is : 0.528702\n",
      "the mean loss is 0.864976\n",
      "save checkpoint 128\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 129\n",
      "the correlation coeffizient is : 0.501623\n",
      "the mean loss is 0.720622\n",
      "save checkpoint 129\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 130\n",
      "the correlation coeffizient is : 0.475235\n",
      "the mean loss is 0.869327\n",
      "save checkpoint 130\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 131\n",
      "the correlation coeffizient is : 0.372125\n",
      "the mean loss is 0.748205\n",
      "save checkpoint 131\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 132\n",
      "the correlation coeffizient is : 0.569372\n",
      "the mean loss is 0.704828\n",
      "save checkpoint 132\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 133\n",
      "the correlation coeffizient is : 0.552593\n",
      "the mean loss is 0.494900\n",
      "save checkpoint 133\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 134\n",
      "the correlation coeffizient is : 0.254101\n",
      "the mean loss is 1.038291\n",
      "save checkpoint 134\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 135\n",
      "the correlation coeffizient is : 0.340731\n",
      "the mean loss is 1.146606\n",
      "save checkpoint 135\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 136\n",
      "the correlation coeffizient is : 0.438592\n",
      "the mean loss is 0.802905\n",
      "save checkpoint 136\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 137\n",
      "the correlation coeffizient is : 0.469803\n",
      "the mean loss is 0.687167\n",
      "save checkpoint 137\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 138\n",
      "the correlation coeffizient is : 0.394749\n",
      "the mean loss is 0.832708\n",
      "save checkpoint 138\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 139\n",
      "the correlation coeffizient is : 0.260992\n",
      "the mean loss is 0.947310\n",
      "save checkpoint 139\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 140\n",
      "the correlation coeffizient is : 0.352075\n",
      "the mean loss is 1.195816\n",
      "save checkpoint 140\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 141\n",
      "the correlation coeffizient is : 0.520034\n",
      "the mean loss is 0.806698\n",
      "save checkpoint 141\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 142\n",
      "the correlation coeffizient is : 0.544609\n",
      "the mean loss is 0.755033\n",
      "save checkpoint 142\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 143\n",
      "the correlation coeffizient is : 0.528237\n",
      "the mean loss is 0.751918\n",
      "save checkpoint 143\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 144\n",
      "the correlation coeffizient is : 0.079090\n",
      "the mean loss is 1.118701\n",
      "save checkpoint 144\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 145\n",
      "the correlation coeffizient is : 0.514003\n",
      "the mean loss is 0.853264\n",
      "save checkpoint 145\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 146\n",
      "the correlation coeffizient is : 0.551301\n",
      "the mean loss is 1.033510\n",
      "save checkpoint 146\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 147\n",
      "the correlation coeffizient is : 0.398730\n",
      "the mean loss is 0.872141\n",
      "save checkpoint 147\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 148\n",
      "the correlation coeffizient is : 0.468881\n",
      "the mean loss is 0.867385\n",
      "save checkpoint 148\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 149\n",
      "the correlation coeffizient is : 0.414921\n",
      "the mean loss is 0.751268\n",
      "save checkpoint 149\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 150\n",
      "the correlation coeffizient is : 0.603640\n",
      "the mean loss is 0.658800\n",
      "save checkpoint 150\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 151\n",
      "the correlation coeffizient is : 0.450928\n",
      "the mean loss is 0.701571\n",
      "save checkpoint 151\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 152\n",
      "the correlation coeffizient is : 0.511654\n",
      "the mean loss is 0.769125\n",
      "save checkpoint 152\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 153\n",
      "the correlation coeffizient is : 0.357525\n",
      "the mean loss is 1.118598\n",
      "save checkpoint 153\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 154\n",
      "the correlation coeffizient is : 0.412443\n",
      "the mean loss is 0.932038\n",
      "save checkpoint 154\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 155\n",
      "the correlation coeffizient is : 0.444752\n",
      "the mean loss is 0.789452\n",
      "save checkpoint 155\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 156\n",
      "the correlation coeffizient is : 0.402660\n",
      "the mean loss is 0.831358\n",
      "save checkpoint 156\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 157\n",
      "the correlation coeffizient is : 0.304624\n",
      "the mean loss is 0.871448\n",
      "save checkpoint 157\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 158\n",
      "the correlation coeffizient is : 0.290515\n",
      "the mean loss is 1.287066\n",
      "save checkpoint 158\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 159\n",
      "the correlation coeffizient is : 0.535836\n",
      "the mean loss is 0.790520\n",
      "save checkpoint 159\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 160\n",
      "the correlation coeffizient is : 0.609108\n",
      "the mean loss is 0.669986\n",
      "save checkpoint 160\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 161\n",
      "the correlation coeffizient is : 0.575670\n",
      "the mean loss is 0.700406\n",
      "save checkpoint 161\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 162\n",
      "the correlation coeffizient is : 0.000992\n",
      "the mean loss is 1.170527\n",
      "save checkpoint 162\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 163\n",
      "the correlation coeffizient is : 0.465054\n",
      "the mean loss is 0.898804\n",
      "save checkpoint 163\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 164\n",
      "the correlation coeffizient is : 0.518272\n",
      "the mean loss is 0.840045\n",
      "save checkpoint 164\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 165\n",
      "the correlation coeffizient is : 0.464561\n",
      "the mean loss is 0.762982\n",
      "save checkpoint 165\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 166\n",
      "the correlation coeffizient is : 0.461547\n",
      "the mean loss is 0.940594\n",
      "save checkpoint 166\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 167\n",
      "the correlation coeffizient is : 0.337218\n",
      "the mean loss is 0.816315\n",
      "save checkpoint 167\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 168\n",
      "the correlation coeffizient is : 0.487258\n",
      "the mean loss is 0.818890\n",
      "save checkpoint 168\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 169\n",
      "the correlation coeffizient is : 0.422879\n",
      "the mean loss is 0.745195\n",
      "save checkpoint 169\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 170\n",
      "the correlation coeffizient is : 0.494434\n",
      "the mean loss is 0.804643\n",
      "save checkpoint 170\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 171\n",
      "the correlation coeffizient is : 0.294747\n",
      "the mean loss is 1.191090\n",
      "save checkpoint 171\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 172\n",
      "the correlation coeffizient is : 0.492341\n",
      "the mean loss is 0.816952\n",
      "save checkpoint 172\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 173\n",
      "the correlation coeffizient is : 0.408836\n",
      "the mean loss is 0.862982\n",
      "save checkpoint 173\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 174\n",
      "the correlation coeffizient is : 0.427228\n",
      "the mean loss is 0.817127\n",
      "save checkpoint 174\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 175\n",
      "the correlation coeffizient is : 0.340852\n",
      "the mean loss is 1.051826\n",
      "save checkpoint 175\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 176\n",
      "the correlation coeffizient is : 0.219761\n",
      "the mean loss is 1.400566\n",
      "save checkpoint 176\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 177\n",
      "the correlation coeffizient is : 0.531447\n",
      "the mean loss is 0.807318\n",
      "save checkpoint 177\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 178\n",
      "the correlation coeffizient is : 0.504859\n",
      "the mean loss is 0.863083\n",
      "save checkpoint 178\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 179\n",
      "the correlation coeffizient is : 0.587027\n",
      "the mean loss is 0.781153\n",
      "save checkpoint 179\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 180\n",
      "the correlation coeffizient is : 0.022581\n",
      "the mean loss is 1.245662\n",
      "save checkpoint 180\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 181\n",
      "the correlation coeffizient is : 0.481846\n",
      "the mean loss is 0.862977\n",
      "save checkpoint 181\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 182\n",
      "the correlation coeffizient is : 0.536064\n",
      "the mean loss is 0.814269\n",
      "save checkpoint 182\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 183\n",
      "the correlation coeffizient is : 0.459083\n",
      "the mean loss is 0.799430\n",
      "save checkpoint 183\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 184\n",
      "the correlation coeffizient is : 0.438116\n",
      "the mean loss is 0.926601\n",
      "save checkpoint 184\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 185\n",
      "the correlation coeffizient is : 0.366537\n",
      "the mean loss is 0.762650\n",
      "save checkpoint 185\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 186\n",
      "the correlation coeffizient is : 0.525608\n",
      "the mean loss is 0.820682\n",
      "save checkpoint 186\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 187\n",
      "the correlation coeffizient is : 0.558465\n",
      "the mean loss is 0.598642\n",
      "save checkpoint 187\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 188\n",
      "the correlation coeffizient is : 0.484826\n",
      "the mean loss is 0.821769\n",
      "save checkpoint 188\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 189\n",
      "the correlation coeffizient is : 0.307657\n",
      "the mean loss is 1.250858\n",
      "save checkpoint 189\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 190\n",
      "the correlation coeffizient is : 0.495143\n",
      "the mean loss is 0.783792\n",
      "save checkpoint 190\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 191\n",
      "the correlation coeffizient is : 0.379872\n",
      "the mean loss is 0.873524\n",
      "save checkpoint 191\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 192\n",
      "the correlation coeffizient is : 0.439113\n",
      "the mean loss is 0.843815\n",
      "save checkpoint 192\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 193\n",
      "the correlation coeffizient is : 0.346892\n",
      "the mean loss is 1.096948\n",
      "save checkpoint 193\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 194\n",
      "the correlation coeffizient is : 0.287575\n",
      "the mean loss is 1.318661\n",
      "save checkpoint 194\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 195\n",
      "the correlation coeffizient is : 0.492460\n",
      "the mean loss is 0.826155\n",
      "save checkpoint 195\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 196\n",
      "the correlation coeffizient is : 0.515973\n",
      "the mean loss is 0.838633\n",
      "save checkpoint 196\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 197\n",
      "the correlation coeffizient is : 0.563382\n",
      "the mean loss is 0.792111\n",
      "save checkpoint 197\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 198\n",
      "the correlation coeffizient is : 0.149071\n",
      "the mean loss is 1.231415\n",
      "save checkpoint 198\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 199\n",
      "the correlation coeffizient is : 0.497448\n",
      "the mean loss is 0.860497\n",
      "save checkpoint 199\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 200\n",
      "the correlation coeffizient is : 0.483389\n",
      "the mean loss is 0.969800\n",
      "save checkpoint 200\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 201\n",
      "the correlation coeffizient is : 0.409392\n",
      "the mean loss is 0.862558\n",
      "save checkpoint 201\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 202\n",
      "the correlation coeffizient is : 0.590295\n",
      "the mean loss is 0.741760\n",
      "save checkpoint 202\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 203\n",
      "the correlation coeffizient is : 0.463340\n",
      "the mean loss is 0.683462\n",
      "save checkpoint 203\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 204\n",
      "the correlation coeffizient is : 0.472118\n",
      "the mean loss is 0.837451\n",
      "save checkpoint 204\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 205\n",
      "the correlation coeffizient is : 0.545071\n",
      "the mean loss is 0.557692\n",
      "save checkpoint 205\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 206\n",
      "the correlation coeffizient is : 0.412637\n",
      "the mean loss is 0.909736\n",
      "save checkpoint 206\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 207\n",
      "the correlation coeffizient is : 0.316349\n",
      "the mean loss is 1.240222\n",
      "save checkpoint 207\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 208\n",
      "the correlation coeffizient is : 0.498117\n",
      "the mean loss is 0.796249\n",
      "save checkpoint 208\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 209\n",
      "the correlation coeffizient is : 0.363211\n",
      "the mean loss is 0.943916\n",
      "save checkpoint 209\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 210\n",
      "the correlation coeffizient is : 0.441677\n",
      "the mean loss is 0.884588\n",
      "save checkpoint 210\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 211\n",
      "the correlation coeffizient is : 0.453209\n",
      "the mean loss is 0.825183\n",
      "save checkpoint 211\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 212\n",
      "the correlation coeffizient is : 0.213737\n",
      "the mean loss is 1.484546\n",
      "save checkpoint 212\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 213\n",
      "the correlation coeffizient is : 0.492278\n",
      "the mean loss is 1.009867\n",
      "save checkpoint 213\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 214\n",
      "the correlation coeffizient is : 0.493520\n",
      "the mean loss is 0.854181\n",
      "save checkpoint 214\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 215\n",
      "the correlation coeffizient is : 0.544428\n",
      "the mean loss is 0.757749\n",
      "save checkpoint 215\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 216\n",
      "the correlation coeffizient is : 0.192239\n",
      "the mean loss is 1.125990\n",
      "save checkpoint 216\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 217\n",
      "the correlation coeffizient is : 0.537961\n",
      "the mean loss is 0.835552\n",
      "save checkpoint 217\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 218\n",
      "the correlation coeffizient is : 0.496021\n",
      "the mean loss is 0.928901\n",
      "save checkpoint 218\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 219\n",
      "the correlation coeffizient is : 0.537954\n",
      "the mean loss is 0.735310\n",
      "save checkpoint 219\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 220\n",
      "the correlation coeffizient is : 0.613541\n",
      "the mean loss is 0.705218\n",
      "save checkpoint 220\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 221\n",
      "the correlation coeffizient is : 0.325758\n",
      "the mean loss is 0.812053\n",
      "save checkpoint 221\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 222\n",
      "the correlation coeffizient is : 0.545385\n",
      "the mean loss is 0.811410\n",
      "save checkpoint 222\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 223\n",
      "the correlation coeffizient is : 0.443743\n",
      "the mean loss is 0.679349\n",
      "save checkpoint 223\n",
      "please remove the comment sign before saving a checkpoint\n",
      "evaluate 224\n",
      "the correlation coeffizient is : 0.415133\n",
      "the mean loss is 0.947266\n",
      "save checkpoint 224\n",
      "please remove the comment sign before saving a checkpoint\n",
      "the correlation coeffizient is : 0.334294\n",
      "the correlation coeffizient is : 0.494097\n",
      "the correlation coeffizient is : 0.481949\n",
      "the correlation coeffizient is : 0.360121\n",
      "the correlation coeffizient is : 0.621869\n",
      "the correlation coeffizient is : 0.570260\n",
      "the correlation coeffizient is : 0.393822\n",
      "the correlation coeffizient is : 0.606098\n",
      "the correlation coeffizient is : 0.644297\n",
      "the correlation coeffizient is : 0.528398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49647938856763096"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmin.o_func(pas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('act_func1', 'LeakyReLU')\n",
      "('act_func_out', None)\n",
      "('tgt', '../data/MasterArbeit/data2/record_NIST_dev2015_clean')\n",
      "('loss_fn', 'MSELoss')\n",
      "('isRandom', False)\n",
      "('src_test_sys', '../data/MasterArbeit/data2/hidden_pred_preprotst2016')\n",
      "('dim2', 500)\n",
      "('dim3', None)\n",
      "('val_tgt', '../data/MasterArbeit/data2/record_NIST_tst2016_clean')\n",
      "('dim1', 20)\n",
      "('test_tgt', '../data/MasterArbeit/data2/record_NIST_tst2016_clean')\n",
      "('weight_decay', 0)\n",
      "('out', './pred')\n",
      "('kernel_size2', 3)\n",
      "('kernel_size1', 0)\n",
      "('src_test_ref', '../data/MasterArbeit/data2/hidden_ref_preprotst2016')\n",
      "('tgt_test', '../data/MasterArbeit/data/record_newstest2015_cleaned')\n",
      "('checkpoint', './checkpoints/cp0')\n",
      "('num_dim_k', 0)\n",
      "('tgt_val', '../data/MasterArbeit/data/record_newstest2016_cleaned')\n",
      "('lr', 0.02)\n",
      "('act_func', 'ReLU')\n",
      "('drop_out_rate', 0.5)\n",
      "('momentum', 0.1)\n",
      "('src_val_ref', '../data/MasterArbeit/data2/hidden_ref_preprotst2016')\n",
      "('resume', False)\n",
      "('optim', 'Adam')\n",
      "('batch_size', 50)\n",
      "('src_val_sys', '../data/MasterArbeit/data2/hidden_pred_preprotst2016')\n",
      "('num_head', 1)\n",
      "('num_dim_v', 3)\n",
      "('stride2', 1)\n",
      "('src_sys', '../data/MasterArbeit/data2/hidden_pred_preprodev2015')\n",
      "('act_func2', 'LeakyReLU')\n",
      "('src_ref', '../data/MasterArbeit/data2/hidden_ref_preprodev2015')\n",
      "('eps', 1e-08)\n",
      "('d_rate_attn', 0.1)\n",
      "('stride1', 1)\n",
      "('cuda', False)\n",
      "('debug', False)\n",
      "('model', 'MultiHeadAttnConvModel')\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '../data/MasterArbeit/data/record_newstest2016_cleaned'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8837d8b2e1c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     }\n\u001b[1;32m     25\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mfmin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ihuangyiran/Documents/Workplace_Python/MasterArbeit/fmin.pyc\u001b[0m in \u001b[0;36mo_func\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# read data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataUtil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;31m#data.normalize_minmax()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ihuangyiran/Documents/Workplace_Python/MasterArbeit/utils/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnu_val_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_val_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_val_tgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_val_tgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '../data/MasterArbeit/data/record_newstest2016_cleaned'"
     ]
    }
   ],
   "source": [
    "import fmin\n",
    "import Params\n",
    "opt = Params.Params()\n",
    "# MultiHeadLSTMModel\n",
    "pas = {'model': 'MultiHeadAttnConvModel',\n",
    "       'tgt': '../data/MasterArbeit/data2/record_NIST_dev2015_clean', \n",
    "       'src_sys': '../data/MasterArbeit/data2/hidden_pred_preprodev2015',\n",
    "       'src_ref': '../data/MasterArbeit/data2/hidden_ref_preprodev2015',\n",
    "       'val_tgt': '../data/MasterArbeit/data2/record_NIST_tst2016_clean',\n",
    "       'src_val_sys': '../data/MasterArbeit/data2/hidden_pred_preprotst2016',\n",
    "       'src_val_ref': '../data/MasterArbeit/data2/hidden_ref_preprotst2016',\n",
    "       'test_tgt': '../data/MasterArbeit/data2/record_NIST_tst2016_clean',\n",
    "       'src_test_sys': '../data/MasterArbeit/data2/hidden_pred_preprotst2016',\n",
    "       'src_test_ref': '../data/MasterArbeit/data2/hidden_ref_preprotst2016',\n",
    "       'resume': False,\n",
    "       'checkpoint': './checkpoints/cp0',\n",
    "       'num_dim_k': 0,\n",
    "       'num_dim_v': 3,\n",
    "       'num_head': 1,\n",
    "       'kernel_size1': 0,\n",
    "       'stride1': 1,\n",
    "       'kernel_size2': 3,\n",
    "       'stride2': 1\n",
    "    }\n",
    "opt.set_params(pas)\n",
    "fmin.o_func(pas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fmin\n",
    "import Params\n",
    "\n",
    "fmin.get_best()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fmin\n",
    "import Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Params.Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pas = {'tgt': '../data/MasterArbeit/data/data_scores', 'src_sys': '../data/MasterArbeit/data/sys_hidden', 'src_ref': '../data/MasterArbeit/data/ref_hidden', 'batch_size': 100, 'dim2': 100, 'dim3': 10, 'lr': 0.01592636698766986, 'act_func': 'LeakyReLU', 'act_func_out': None, 'model': './model/LinearModel', 'type': 'linear', 'momentum': 0.19338528925355508, 'drop_out_rate': 0.5683040090088415}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt.set_params(pas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./utils/\")\n",
    "from data import DataUtil\n",
    "data = DataUtil(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.1317e-01  1.9135e-01  4.8339e-02  ...   3.3562e-01  2.1015e-01 -3.0384e-01\n",
       "-7.8419e-02 -6.2597e-02 -3.2062e-01  ...  -2.0042e-01 -4.3326e-02 -1.9184e-01\n",
       "-1.4486e-01 -3.4520e-01 -2.9599e-01  ...  -5.4923e-01 -2.9880e-01 -9.2808e-02\n",
       "                ...                   ⋱                   ...                \n",
       " 5.6298e-02  6.2424e-02  1.5753e-01  ...   2.7108e-01  5.2202e-02  4.0222e-01\n",
       " 2.5324e-02  1.3155e-01 -6.5003e-03  ...   4.0089e-01 -2.2887e-01 -3.4650e-01\n",
       " 9.4739e-02 -3.0009e-01 -3.0777e-01  ...   2.3748e-02  3.1988e-02 -8.6498e-02\n",
       "[torch.FloatTensor of size 9392x1000]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.normalize_minmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.0263e-01  1.8456e-01  3.4689e-02  ...   3.3574e-01  2.0426e-01 -3.3436e-01\n",
       "-9.8142e-02 -8.1562e-02 -3.5195e-01  ...  -2.2599e-01 -6.1368e-02 -2.1700e-01\n",
       "-1.6777e-01 -3.7771e-01 -3.2614e-01  ...  -5.9152e-01 -3.2909e-01 -1.1322e-01\n",
       "                ...                   ⋱                   ...                \n",
       " 4.3030e-02  4.9449e-02  1.4911e-01  ...   2.6810e-01  3.8737e-02  4.0552e-01\n",
       " 1.0572e-02  1.2189e-01 -2.2778e-02  ...   4.0414e-01 -2.5581e-01 -3.7906e-01\n",
       " 8.3313e-02 -3.3044e-01 -3.3848e-01  ...   8.9200e-03  1.7555e-02 -1.0661e-01\n",
       "[torch.FloatTensor of size 9392x1000]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = getattr(torch.nn, 'ReLU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.nn.ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.activation.ReLU"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "DuplicateLabel",
     "evalue": "linear_act_func",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDuplicateLabel\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f0aeffc33b9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfmin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ihuangyiran/Documents/Workplace_Python/MasterArbeit/fmin.pyc\u001b[0m in \u001b[0;36mget_best\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mli_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim_algo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             max_evals = 500)\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ihuangyiran/anaconda2/envs/py27/lib/python2.7/site-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     domain = base.Domain(fn, space,\n\u001b[0;32m--> 314\u001b[0;31m                          pass_expr_memo_ctrl=pass_expr_memo_ctrl)\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     rval = FMinIter(algo, domain, trials, max_evals=max_evals,\n",
      "\u001b[0;32m/Users/ihuangyiran/anaconda2/envs/py27/lib/python2.7/site-packages/hyperopt/base.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fn, expr, workdir, pass_expr_memo_ctrl, name, loss_target)\u001b[0m\n\u001b[1;32m    774\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mDuplicateLabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'obj'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDuplicateLabel\u001b[0m: linear_act_func"
     ]
    }
   ],
   "source": [
    "fmin.get_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32/10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "x = float('nan')\n",
    "math.isnan(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## normalize scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.70434875861064,\n",
       " 1.12727142153235,\n",
       " -0.872401325076093,\n",
       " -0.520636691467046,\n",
       " 0.0293189192586597,\n",
       " -1.67083618888355,\n",
       " -1.54107458193584,\n",
       " -1.26716970413938,\n",
       " 1.14801144278375,\n",
       " -0.126473141789861,\n",
       " 1.08998382718802,\n",
       " -1.45083864991872,\n",
       " -1.30334660957726,\n",
       " 0.909684951356344,\n",
       " -0.865310032116374,\n",
       " -1.04805674497439,\n",
       " 1.03362830429051,\n",
       " -1.30334660957726,\n",
       " 0.473968273650239,\n",
       " 0.0655234422069162,\n",
       " -2.31501818674212,\n",
       " -1.30040055102541,\n",
       " -1.26443616430169,\n",
       " 1.24609931070437,\n",
       " 0.0048710057016938,\n",
       " 0.339556020247105,\n",
       " -0.553215740838215,\n",
       " -0.284941429727458,\n",
       " -0.740862210579549,\n",
       " -1.44105725859061,\n",
       " -0.264247987380428,\n",
       " 0.0386786043300455,\n",
       " 0.71831182779596,\n",
       " -1.26443616430169,\n",
       " 1.10910099750817,\n",
       " 0.0686014628819244,\n",
       " 1.11418127557441,\n",
       " 0.253071201445601,\n",
       " 0.419182111938213,\n",
       " -1.80918239815969,\n",
       " -0.229408504480094,\n",
       " -0.123356240182688,\n",
       " -0.0496745081911503,\n",
       " 1.22217430718766,\n",
       " -1.1248553785731,\n",
       " -0.985337863893415,\n",
       " -1.15989655423098,\n",
       " -0.0139082445291922,\n",
       " -1.54107458193584,\n",
       " -0.434365786127364,\n",
       " 0.564354763650173,\n",
       " -0.625664260181483,\n",
       " 0.00479229747097395,\n",
       " -1.00060178914239,\n",
       " -0.541165306892952,\n",
       " 1.37707956533788,\n",
       " 1.19092537160453,\n",
       " 1.12500429027107,\n",
       " -0.0269699547415003,\n",
       " 0.439961524610728,\n",
       " 1.16851268433334,\n",
       " 1.15399058740957,\n",
       " 0.0196085297921715,\n",
       " -2.00803966495828,\n",
       " -0.779261527378905,\n",
       " -1.80242807284352,\n",
       " -0.637772075862252,\n",
       " 1.24475737737332,\n",
       " -1.34225705485283,\n",
       " 0.37271797660176,\n",
       " 0.330892091996744,\n",
       " 0.955074894851372,\n",
       " 1.13791095964253,\n",
       " -2.09778641339656,\n",
       " -0.823820570438701,\n",
       " 1.16851268433334,\n",
       " -0.500696803050913,\n",
       " 0.384805693494673,\n",
       " -0.932247035025456,\n",
       " 1.24475737737332,\n",
       " -1.26868535215846,\n",
       " 0.0788671043790961,\n",
       " -0.27777460080266,\n",
       " -0.397358539254111,\n",
       " -0.602958594616973,\n",
       " 1.12727142153235,\n",
       " -2.03295160375887,\n",
       " 0.347025990290812,\n",
       " -1.57571972650626,\n",
       " -1.30219792188555,\n",
       " 0.993248980926827,\n",
       " -1.90283357720715,\n",
       " 1.21000101759139,\n",
       " -0.379648013438239,\n",
       " -0.992027214946222,\n",
       " -1.02774905479782,\n",
       " -0.486227258790259,\n",
       " 0.719043156989968,\n",
       " -1.80918239815969,\n",
       " -2.00373462453755,\n",
       " -0.0582123607589716,\n",
       " 0.972182822522608,\n",
       " 0.382861811868042,\n",
       " 1.16851268433334,\n",
       " -0.447165611587295,\n",
       " 0.674241034792515,\n",
       " -0.866534515433376,\n",
       " -0.0287202722561164,\n",
       " -1.27105218589777,\n",
       " -0.123356240182688,\n",
       " -0.856060160977616,\n",
       " -0.430871108981201,\n",
       " 0.443748066717318,\n",
       " 0.23927090856685,\n",
       " 0.778513503941099,\n",
       " 1.31592111393706,\n",
       " -0.75860037571926,\n",
       " -2.06453839447977,\n",
       " 1.33820803399917,\n",
       " -0.482802158719479,\n",
       " 0.20779127437812,\n",
       " -0.173912076323135,\n",
       " 0.343579268244777,\n",
       " 0.994257260766243,\n",
       " 0.00479229747097395,\n",
       " -0.444034451401381,\n",
       " -0.548865626582772,\n",
       " -1.00060178914239,\n",
       " 0.0271241254075607,\n",
       " -0.281845171077426,\n",
       " -0.695735501030716,\n",
       " 0.690942402274422,\n",
       " -0.252764587136829,\n",
       " -1.80918239815969,\n",
       " 0.751045204576369,\n",
       " -0.63848432233684,\n",
       " 0.262822929695734,\n",
       " -1.20165401217182,\n",
       " -1.08645606177375,\n",
       " -0.291675032412401,\n",
       " -1.94336634123875,\n",
       " 1.10910099750817,\n",
       " 0.943144249829505,\n",
       " -1.70434875861064,\n",
       " -1.67083618888355,\n",
       " 0.756711144595315,\n",
       " -0.847686178890694,\n",
       " -0.0590320517207384,\n",
       " 1.06188186411476,\n",
       " 0.449516610200471,\n",
       " -2.08483829855699,\n",
       " 0.461460279450232,\n",
       " -0.537212341742857,\n",
       " 0.607304031883433,\n",
       " 0.0112417995560491,\n",
       " -2.56555146682984,\n",
       " 0.439961524610728,\n",
       " -0.260215120221697,\n",
       " 0.23915411187824,\n",
       " 0.0585189750677431,\n",
       " 0.994279345865177,\n",
       " -0.00359956318197308,\n",
       " -1.33519147480243,\n",
       " -0.397358539254111,\n",
       " 0.439961524610728,\n",
       " -0.429989807649004,\n",
       " 1.24320555951971,\n",
       " -0.496517149884582,\n",
       " -0.599201778713575,\n",
       " 0.26029264897955,\n",
       " 0.989797466710602,\n",
       " 0.50373844696225,\n",
       " -1.73786132833773,\n",
       " 0.597195595525027,\n",
       " -1.92591373398641,\n",
       " 1.10910099750817,\n",
       " 1.13808643198301,\n",
       " -2.08155551508869,\n",
       " -0.75860037571926,\n",
       " -1.05899799038095,\n",
       " 0.339556020247105,\n",
       " 0.439961524610728,\n",
       " 0.334625776914176,\n",
       " 0.953459216405889,\n",
       " -0.0448634541906483,\n",
       " -0.535467414373893,\n",
       " 1.10933155370155,\n",
       " -0.52513770406583,\n",
       " 1.11438695101786,\n",
       " 0.842606540648234,\n",
       " -1.26868535215846,\n",
       " -1.28276570388248,\n",
       " -1.80327153195803,\n",
       " 0.876119110375324,\n",
       " 0.422144355491307,\n",
       " -0.746508634549636,\n",
       " -1.75756247178124,\n",
       " 0.473968273650239,\n",
       " 1.10933155370155,\n",
       " -0.510937573326197,\n",
       " 1.27826994710041,\n",
       " 0.185662513653259,\n",
       " -0.0582123607589716,\n",
       " -0.486227258790259,\n",
       " -1.75756247178124,\n",
       " 1.27667406097425,\n",
       " -1.59466782113548,\n",
       " 0.262822929695734,\n",
       " -1.70434875861064,\n",
       " 0.989797466710602,\n",
       " -0.295087858940278,\n",
       " 1.0701905522326,\n",
       " 0.719996544752459,\n",
       " -1.77027195288412,\n",
       " -0.781053698110154,\n",
       " 0.598727039920146,\n",
       " 1.27405959353085,\n",
       " -0.564093519025504,\n",
       " 0.642175654201316,\n",
       " -0.564048149341402,\n",
       " 1.0701905522326,\n",
       " -0.341824903278122,\n",
       " -1.96482417926198,\n",
       " 1.28467217835392,\n",
       " 0.706598918332718,\n",
       " 0.579274529984365,\n",
       " -0.102207934526366,\n",
       " 0.900709118925694,\n",
       " -0.376135420884919,\n",
       " 1.40949953018436,\n",
       " 0.926520122082437,\n",
       " -0.379685237733824,\n",
       " 0.634684332724337,\n",
       " 0.497609811563913,\n",
       " 0.0383048671980643,\n",
       " 0.829239603209405,\n",
       " 0.564354763650173,\n",
       " 0.48653387309903,\n",
       " -0.971258111375682,\n",
       " 0.23927090856685,\n",
       " 0.253071201445601,\n",
       " -0.581544630256631,\n",
       " -0.535129524307294,\n",
       " -1.4027362817954,\n",
       " -0.164872458589217,\n",
       " -0.953152602097117,\n",
       " 0.408712982547887,\n",
       " -0.213854141861258,\n",
       " -0.733801051217404,\n",
       " -1.48333542610263,\n",
       " -0.783441247075023,\n",
       " 0.641513194197249,\n",
       " 0.972099966217012,\n",
       " -1.46774305829811,\n",
       " 0.175250310894458,\n",
       " -1.22552571902612,\n",
       " -1.4027362817954,\n",
       " 0.419182111938213,\n",
       " -1.23285982636747,\n",
       " 0.265014180998248,\n",
       " 1.07403731052786,\n",
       " -0.460406660165596,\n",
       " -1.17071299050689,\n",
       " 0.755948714560977,\n",
       " -0.992063047372689,\n",
       " 1.0701905522326,\n",
       " 0.313082023708868,\n",
       " 1.03362830429051,\n",
       " -1.09024692596408,\n",
       " -1.99067343624685,\n",
       " 1.28191560319977,\n",
       " 0.968798289594455,\n",
       " -1.80918239815969,\n",
       " 0.855357038545309,\n",
       " -1.4328260350607,\n",
       " -0.596075155191685,\n",
       " 1.13808643198301,\n",
       " 0.814969791723953,\n",
       " -1.14770482847498,\n",
       " -0.246525665219529,\n",
       " 0.369802537272315,\n",
       " 0.0585189750677431,\n",
       " -1.12623472156049,\n",
       " -0.00996362436460503,\n",
       " 1.40949953018436,\n",
       " -0.779261527378905,\n",
       " 0.296070948612527,\n",
       " -0.216896895197801,\n",
       " 1.06281053932284,\n",
       " 0.28470623969371,\n",
       " -0.932858794576327,\n",
       " 0.978296273700086,\n",
       " 1.31592111393706,\n",
       " -2.12268477597773,\n",
       " -1.19999504666178,\n",
       " 1.10212913917881,\n",
       " -1.62317166694938,\n",
       " -0.717049409583369,\n",
       " 1.10230499578951,\n",
       " 0.0300867972781843,\n",
       " -0.0193019154834,\n",
       " -1.14685515734813,\n",
       " -2.19614552194098,\n",
       " -1.02571718725709,\n",
       " 0.978296273700086,\n",
       " -2.08155551508869,\n",
       " -0.430871108981201,\n",
       " -0.0150395288217961,\n",
       " 1.06077538369876,\n",
       " -1.30219792188555,\n",
       " 0.528581349166527,\n",
       " -0.992027214946222,\n",
       " -2.36691624176049,\n",
       " -1.14770482847498,\n",
       " 1.14801144278375,\n",
       " 0.876119110375324,\n",
       " -1.1087943831994,\n",
       " 1.27826994710041,\n",
       " 0.304296724621513,\n",
       " -1.55189857268501,\n",
       " 0.179978776659988,\n",
       " 0.440455703923149,\n",
       " 0.175250310894458,\n",
       " -0.621512892217109,\n",
       " 0.540367028974351,\n",
       " -1.26868535215846,\n",
       " -0.329814008843717,\n",
       " 0.0468204923308349,\n",
       " -1.30516983311103,\n",
       " -0.0696572594721942,\n",
       " -2.31501818674212,\n",
       " 0.0718174369251547,\n",
       " 0.875638325854746,\n",
       " -0.63848432233684,\n",
       " 0.0718174369251547,\n",
       " 1.31592111393706,\n",
       " 0.11459886653771,\n",
       " -0.900350648128308,\n",
       " 0.979734698812601,\n",
       " -0.0112751913917948,\n",
       " 0.0300867972781843,\n",
       " -0.379685237733824,\n",
       " 0.791352364108435,\n",
       " 0.657839617230895,\n",
       " 0.408712982547887,\n",
       " 0.495559062113284,\n",
       " 0.00479229747097395,\n",
       " 0.907023179435717,\n",
       " -1.46700226365005,\n",
       " 0.875638325854746,\n",
       " 1.05066505346354,\n",
       " -1.05899799038095,\n",
       " -1.20774914964979,\n",
       " 0.48653387309903,\n",
       " 0.603265208925745,\n",
       " 0.291981646721172,\n",
       " 0.758394347826551,\n",
       " 1.12727142153235,\n",
       " -1.43204991296795,\n",
       " 0.607304031883433,\n",
       " 0.544922191177836,\n",
       " -0.09699274989249,\n",
       " 1.13929835840446,\n",
       " -0.48427166364237,\n",
       " -0.172712233230048,\n",
       " 0.163078872945356,\n",
       " 1.16851268433334,\n",
       " 0.755948714560977,\n",
       " -0.637772075862252,\n",
       " 0.180721392604983,\n",
       " 1.12084246222882,\n",
       " 1.27590424447258,\n",
       " 0.14098017266066,\n",
       " -0.581544630256631,\n",
       " 0.534697724358764,\n",
       " 0.926520122082437,\n",
       " -1.35650092356657,\n",
       " -1.18502879913206,\n",
       " -2.12046596036426,\n",
       " -0.797510820994831,\n",
       " 0.376903944426195,\n",
       " -1.10987484581602,\n",
       " 0.253071201445601,\n",
       " 0.0718174369251547,\n",
       " -1.26868535215846,\n",
       " -1.23346354811633,\n",
       " -0.402789060597252,\n",
       " -0.218130719983525,\n",
       " 0.334625776914176,\n",
       " 1.14801144278375,\n",
       " 1.04302389002484,\n",
       " -1.33386905247995,\n",
       " -1.16325469537246,\n",
       " -1.30334660957726,\n",
       " -0.344545128191809,\n",
       " 0.23927090856685,\n",
       " -1.42413519480213,\n",
       " 1.0701905522326,\n",
       " -1.07059230219275,\n",
       " -1.4704492297673,\n",
       " 1.04468167218798,\n",
       " -1.34074852588581,\n",
       " 0.607304031883433,\n",
       " 0.872111010835791,\n",
       " 0.800113538039163,\n",
       " -0.190769976503235,\n",
       " -1.4324833364275,\n",
       " 0.451707688042341,\n",
       " -1.30700947870196,\n",
       " 0.914548771130317,\n",
       " -0.481354147843781,\n",
       " -1.73786132833773,\n",
       " -0.121529922887002,\n",
       " 0.468317777199008,\n",
       " 1.4059348392863,\n",
       " 0.0585189750677431,\n",
       " 1.05066505346354,\n",
       " -0.291675032412401,\n",
       " 0.540367028974351,\n",
       " -1.15989655423098,\n",
       " 0.136339865618886,\n",
       " -0.652761827800241,\n",
       " 1.12727142153235,\n",
       " 1.03128010695703,\n",
       " -1.1087943831994,\n",
       " -0.559919235090311,\n",
       " 0.406493023156187,\n",
       " -2.24434244131896,\n",
       " 0.875638325854746,\n",
       " 1.31592111393706,\n",
       " -0.0112751913917948,\n",
       " -0.866534515433376,\n",
       " -0.833021945706286,\n",
       " -1.09958954229816,\n",
       " -1.18723448071181,\n",
       " -0.430871108981201,\n",
       " -1.3763272186606,\n",
       " 1.40949953018436,\n",
       " 1.16851268433334,\n",
       " -1.26799312743916,\n",
       " -0.953152602097117,\n",
       " -0.246525665219529,\n",
       " 0.829759829702995,\n",
       " 1.01138250984028,\n",
       " 0.603113877397893,\n",
       " -1.86383893371079,\n",
       " -1.62317166694938,\n",
       " 0.180721392604983,\n",
       " 0.884241954570418,\n",
       " 0.719996544752459,\n",
       " 1.02921009516021,\n",
       " -0.0908001402654495,\n",
       " -2.19828685091541,\n",
       " -1.73786132833773,\n",
       " -1.23695139427351,\n",
       " 0.367028727303907,\n",
       " -0.296345507389176,\n",
       " 0.926520122082437,\n",
       " -0.304619423058557,\n",
       " 0.961031326948384,\n",
       " -0.397358539254111,\n",
       " 0.495914170923356,\n",
       " 0.41403413162775,\n",
       " -1.99583308993905,\n",
       " 0.922342675157862,\n",
       " 1.09563279213051,\n",
       " -0.63398929618739,\n",
       " 1.15937063285942,\n",
       " 1.38478199035282,\n",
       " -1.02571718725709,\n",
       " 0.914548771130317,\n",
       " -0.833021945706286,\n",
       " -0.904579217166058,\n",
       " 0.690942402274422,\n",
       " -0.631030521934587,\n",
       " 0.681086099476888,\n",
       " -0.0850246435223168,\n",
       " 0.291981646721172,\n",
       " 0.525444318374602,\n",
       " 0.418940575899193,\n",
       " 0.756711144595315,\n",
       " 0.876119110375324,\n",
       " -1.30334660957726,\n",
       " -1.09958954229816,\n",
       " 0.670641625528527,\n",
       " 0.700639537036547,\n",
       " -0.865310032116374,\n",
       " 1.01290466180783,\n",
       " 1.06281053932284,\n",
       " -2.45573327887905,\n",
       " 0.577192147961468,\n",
       " -1.40935238415628,\n",
       " 0.989797466710602,\n",
       " -1.08862345996662,\n",
       " -0.88169378228938,\n",
       " 0.681086099476888,\n",
       " -0.631030521934587,\n",
       " -1.38485265117887,\n",
       " 1.47720793355067,\n",
       " -2.15959033354874,\n",
       " -1.59466782113548,\n",
       " 1.0701905522326,\n",
       " -1.59022989529419,\n",
       " -1.62054791291846,\n",
       " 0.0783099145510313,\n",
       " 0.37271797660176,\n",
       " 0.608326484276941,\n",
       " 0.586294255246056,\n",
       " 0.741178037701597,\n",
       " -1.7020225684799,\n",
       " 0.515021160981687,\n",
       " -1.21524266829661,\n",
       " -1.18738825351849,\n",
       " -0.356869042585994,\n",
       " -1.26700502030908,\n",
       " 0.910308411792737,\n",
       " 0.71831182779596,\n",
       " -0.677766865960105,\n",
       " -1.22966642103051,\n",
       " -0.746331126250924,\n",
       " -0.252764587136829,\n",
       " -1.68921921850741,\n",
       " 0.977384239780983,\n",
       " 1.37707956533788,\n",
       " -1.67083618888355,\n",
       " 0.86318702926281,\n",
       " 0.585925829502245,\n",
       " 0.291981646721172,\n",
       " 0.165513106866101,\n",
       " 0.272619017338022,\n",
       " -1.54724786336601,\n",
       " -0.340255970190741,\n",
       " -0.971258111375682,\n",
       " -1.18723448071181,\n",
       " -1.1330580437527,\n",
       " 0.525444318374602,\n",
       " 0.920352322992141,\n",
       " -0.434019278718319,\n",
       " 0.0870105983706088,\n",
       " 0.219120709404338,\n",
       " -0.246525665219529,\n",
       " 0.875638325854746,\n",
       " 1.1740437247872,\n",
       " 0.586294255246056,\n",
       " 0.483313793502665,\n",
       " 0.0885164203515176,\n",
       " 0.500709442737836,\n",
       " -0.241671092187928,\n",
       " -0.548865626582772,\n",
       " 0.107884006505189,\n",
       " -1.80897244437611,\n",
       " -0.0885287116111344,\n",
       " 0.291981646721172,\n",
       " 0.961031326948384,\n",
       " -0.195940003025553,\n",
       " -0.823820570438701,\n",
       " 1.72007680147304,\n",
       " -1.26700502030908,\n",
       " 1.15937063285942,\n",
       " 0.214160756170029,\n",
       " 0.603265208925745,\n",
       " 1.22246729466657,\n",
       " -1.23116964849535,\n",
       " -1.36733755393449,\n",
       " 0.229574910778941,\n",
       " 0.334318659802405,\n",
       " -0.779261527378905,\n",
       " 1.3101425624288,\n",
       " 0.99236966168146,\n",
       " -0.284648153582344,\n",
       " -0.0492461679878697,\n",
       " -0.136033251310115,\n",
       " -1.63732361915646,\n",
       " -0.75860037571926,\n",
       " 0.972182822522608,\n",
       " -1.66855406702536,\n",
       " -0.0458777306939917,\n",
       " -1.30628756393234,\n",
       " -1.65218305936452,\n",
       " 0.987107045391448,\n",
       " -1.03384980805919,\n",
       " -0.63848432233684,\n",
       " -1.65983045654172,\n",
       " -0.790341698554976,\n",
       " 0.382983283095002,\n",
       " 1.0255063621908,\n",
       " 0.92999271151655,\n",
       " 0.292347609402157,\n",
       " -1.87440001422189,\n",
       " 0.23927090856685,\n",
       " -1.77027195288412,\n",
       " -1.43398521737853,\n",
       " 1.12923014071007,\n",
       " -0.397358539254111,\n",
       " 1.02752736478197,\n",
       " 0.00479229747097395,\n",
       " 1.06617184637462,\n",
       " -1.42007794540398,\n",
       " 1.16851268433334,\n",
       " 0.876119110375324,\n",
       " 1.40949953018436,\n",
       " -1.70434875861064,\n",
       " 0.291981646721172,\n",
       " 0.330892091996744,\n",
       " 1.09563279213051,\n",
       " -1.05899799038095,\n",
       " 0.419182111938213,\n",
       " 0.382861811868042,\n",
       " 0.473430026065269,\n",
       " -1.00965742817504,\n",
       " -0.52513770406583,\n",
       " 0.564354763650173,\n",
       " 0.214160756170029,\n",
       " 0.23915411187824,\n",
       " -1.52561359361464,\n",
       " -1.14770482847498,\n",
       " -0.258510043347204,\n",
       " 1.18692188805932,\n",
       " -0.0599155859935225,\n",
       " 0.225900885807531,\n",
       " 0.473968273650239,\n",
       " 0.257520026203694,\n",
       " -1.65272776646046,\n",
       " 1.40949953018436,\n",
       " 0.439592583267062,\n",
       " -1.77767808741152,\n",
       " 0.701947740974723,\n",
       " 0.932817422593748,\n",
       " 0.763375274232797,\n",
       " 0.330892091996744,\n",
       " -0.0285974957528473,\n",
       " 0.30120187818858,\n",
       " -0.559919235090311,\n",
       " -0.257268568254085,\n",
       " -1.34225705485283,\n",
       " -0.856060160977616,\n",
       " -0.992063047372689,\n",
       " -1.03097349264826,\n",
       " -0.402789060597252,\n",
       " -0.564048149341402,\n",
       " -1.14770482847498,\n",
       " 0.411117293401116,\n",
       " 0.272619017338022,\n",
       " -1.2355846352725,\n",
       " 0.0783099145510313,\n",
       " 0.331646285081327,\n",
       " 0.373024521701646,\n",
       " -2.27610774146655,\n",
       " -1.70434875861064,\n",
       " 1.16851268433334,\n",
       " 0.525444318374602,\n",
       " 1.16256503549545,\n",
       " -0.779261527378905,\n",
       " 1.0255063621908,\n",
       " -0.304619423058557,\n",
       " -0.174943696585686,\n",
       " -0.932247035025456,\n",
       " -0.0885287116111344,\n",
       " 0.222208368527447,\n",
       " 1.34930179720262,\n",
       " -0.932858794576327,\n",
       " -1.09773497636255,\n",
       " -0.430871108981201,\n",
       " -0.81766084417826,\n",
       " 1.08994759708681,\n",
       " -1.70434875861064,\n",
       " 0.621594397640184,\n",
       " -0.262877005934635,\n",
       " 0.913092906777817,\n",
       " -0.992063047372689,\n",
       " 0.813281151747804,\n",
       " 0.909684951356344,\n",
       " 0.0196085297921715,\n",
       " -1.77767808741152,\n",
       " -1.98116499583196,\n",
       " 1.12923014071007,\n",
       " 1.28467217835392,\n",
       " -0.299546735766103,\n",
       " 0.147166550128454,\n",
       " 0.707709536247056,\n",
       " -0.00996362436460503,\n",
       " 0.972182822522608,\n",
       " 0.719996544752459,\n",
       " 0.221082543490581,\n",
       " 0.573835530428892,\n",
       " 0.349987581279877,\n",
       " 1.12727142153235,\n",
       " 0.071808008610776,\n",
       " -1.56814856266174,\n",
       " -1.65354061705741,\n",
       " 1.16851268433334,\n",
       " -0.999184037934538,\n",
       " -0.130434065718029,\n",
       " 0.876119110375324,\n",
       " 0.292347609402157,\n",
       " 1.23783376309809,\n",
       " 0.429063024279698,\n",
       " 0.105276510065317,\n",
       " 1.33466174502193,\n",
       " -1.06988393792383,\n",
       " -0.702462893780194,\n",
       " 0.304296724621513,\n",
       " 1.0701905522326,\n",
       " -1.77767808741152,\n",
       " 1.40949953018436,\n",
       " -1.06612104084362,\n",
       " 0.861287270198005,\n",
       " 0.473968273650239,\n",
       " -0.719689930443688,\n",
       " -1.99019804198158,\n",
       " -1.14511008600648,\n",
       " -0.274241375533518,\n",
       " -0.910440724305693,\n",
       " 1.51818018465465,\n",
       " -1.49932207289429,\n",
       " -0.548865626582772,\n",
       " -0.894459477776971,\n",
       " -0.481354147843781,\n",
       " -0.341824903278122,\n",
       " -0.568377543224087,\n",
       " -1.40473269744839,\n",
       " -0.43021951320734,\n",
       " -1.35525127936924,\n",
       " -0.689242921649265,\n",
       " -0.308296499795993,\n",
       " -0.0162341031651332,\n",
       " 0.842606540648234,\n",
       " 1.16851268433334,\n",
       " 0.607304031883433,\n",
       " -1.97409080552784,\n",
       " -0.43021951320734,\n",
       " -0.206376342480928,\n",
       " -2.66712411643915,\n",
       " -0.430871108981201,\n",
       " 0.257520026203694,\n",
       " 1.05335462461849,\n",
       " -0.515949037009763,\n",
       " -0.218130719983525,\n",
       " -1.26799312743916,\n",
       " -1.22076013144799,\n",
       " 1.67969747810936,\n",
       " 1.07403731052786,\n",
       " 0.418940575899193,\n",
       " 0.09658283511177,\n",
       " -0.268982875926372,\n",
       " -1.70084513056344,\n",
       " 1.06281053932284,\n",
       " -0.834897040453163,\n",
       " -0.0620659972073883,\n",
       " 1.37707956533788,\n",
       " 1.09402340261556,\n",
       " -1.26680619562754,\n",
       " -1.46774305829811,\n",
       " -1.30040055102541,\n",
       " 0.884241954570418,\n",
       " 1.24475737737332,\n",
       " 0.993248980926827,\n",
       " -1.30219792188555,\n",
       " -1.67083618888355,\n",
       " -0.39526835938535,\n",
       " 0.681086099476888,\n",
       " 1.10910099750817,\n",
       " 1.24475737737332,\n",
       " 0.962998784292824,\n",
       " -0.719689930443688,\n",
       " 0.0655234422069162,\n",
       " -0.833021945706286,\n",
       " -1.27194458854253,\n",
       " 0.841583542065221,\n",
       " -0.482802158719479,\n",
       " -1.80897244437611,\n",
       " -0.0492461679878697,\n",
       " 0.914548771130317,\n",
       " 0.962998784292824,\n",
       " 0.0655234422069162,\n",
       " -0.641869039892545,\n",
       " 0.395815005362906,\n",
       " 0.993248980926827,\n",
       " -0.697967524843669,\n",
       " -0.09699274989249,\n",
       " -1.51626202555283,\n",
       " -0.369495922963544,\n",
       " -2.58256778141511,\n",
       " -1.66855406702536,\n",
       " 0.565946659941896,\n",
       " -0.831137946148934,\n",
       " 1.0701905522326,\n",
       " 0.447623427823459,\n",
       " -1.23346354811633,\n",
       " -0.284941429727458,\n",
       " -1.22966642103051,\n",
       " -0.184027794053265,\n",
       " 0.814969791723953,\n",
       " 0.884241954570418,\n",
       " -1.66855406702536,\n",
       " -2.17050352364416,\n",
       " -0.460406660165596,\n",
       " 0.291981646721172,\n",
       " 1.08994759708681,\n",
       " 0.758906990028031,\n",
       " 0.00479229747097395,\n",
       " -0.225492548362466,\n",
       " 0.564714560598538,\n",
       " -1.26868535215846,\n",
       " 0.595303118863663,\n",
       " 0.642175654201316,\n",
       " -0.856060160977616,\n",
       " 0.657567349510425,\n",
       " -1.1087943831994,\n",
       " 0.809093970921143,\n",
       " -1.61016992863868,\n",
       " -0.126473141789861,\n",
       " -0.695735501030716,\n",
       " 0.330892091996744,\n",
       " -1.30219792188555,\n",
       " -0.559919235090311,\n",
       " -0.971258111375682,\n",
       " 1.1497599683492,\n",
       " 0.408111519585134,\n",
       " -0.162471501571012,\n",
       " 0.32931896752932,\n",
       " -1.65354061705741,\n",
       " 1.40949953018436,\n",
       " -2.62630174894669,\n",
       " -1.10987484581602,\n",
       " -0.564048149341402,\n",
       " 1.63931815474568,\n",
       " -0.548865626582772,\n",
       " 1.27367351292414,\n",
       " -0.274241375533518,\n",
       " -1.63231414856146,\n",
       " -0.559919235090311,\n",
       " 0.640772533337974,\n",
       " 0.968798289594455,\n",
       " -0.430871108981201,\n",
       " -1.4704492297673,\n",
       " 0.440455703923149,\n",
       " -2.66712411643915,\n",
       " 0.0686014628819244,\n",
       " -1.1248553785731,\n",
       " 0.628444531108159,\n",
       " -0.992063047372689,\n",
       " -0.965715536479997,\n",
       " 1.31592111393706,\n",
       " 0.835750085171348,\n",
       " -1.0110088439584,\n",
       " -0.397358539254111,\n",
       " -0.965715536479997,\n",
       " 1.17626855661063,\n",
       " -2.1175079387829,\n",
       " 0.0686014628819244,\n",
       " -0.430871108981201,\n",
       " -1.70434875861064,\n",
       " 0.993248980926827,\n",
       " -0.520636691467046,\n",
       " 0.14528319028958,\n",
       " -1.3455701075556,\n",
       " -0.363506516973987,\n",
       " -1.44748460421017,\n",
       " 0.989797466710602,\n",
       " 1.40949953018436,\n",
       " 0.841963787058399,\n",
       " -1.08314219382245,\n",
       " 0.473968273650239,\n",
       " 0.865130426150909,\n",
       " 1.26338865075756,\n",
       " -1.14770482847498,\n",
       " -0.363282510298258,\n",
       " 0.640772533337974,\n",
       " 0.70061479017368,\n",
       " 0.706598918332718,\n",
       " -1.51864198975974,\n",
       " 1.47780086129097,\n",
       " 0.707709536247056,\n",
       " -1.28276570388248,\n",
       " -1.10987484581602,\n",
       " -1.20165401217182,\n",
       " -1.06609651062077,\n",
       " -1.57571972650626,\n",
       " 0.69320389664261,\n",
       " 0.977384239780983,\n",
       " 1.37707956533788,\n",
       " 1.06281053932284,\n",
       " 0.837204646485788,\n",
       " -1.38485265117887,\n",
       " 0.500709442737836,\n",
       " 0.103922759006272,\n",
       " -1.24649160387974,\n",
       " 1.33466174502193,\n",
       " 0.99236966168146,\n",
       " -2.66712411643915,\n",
       " 1.01107645710647,\n",
       " 0.607304031883433,\n",
       " 0.48653387309903,\n",
       " 0.876119110375324,\n",
       " -1.62054791291846,\n",
       " 0.138745011519858,\n",
       " -2.04264506981312,\n",
       " -0.169401316222573,\n",
       " -2.08125974412258,\n",
       " 1.12923014071007,\n",
       " -0.0582123607589716,\n",
       " -1.06612104084362,\n",
       " 1.25649604667355,\n",
       " -0.468659405814178,\n",
       " 0.00479229747097395,\n",
       " 0.291981646721172,\n",
       " 0.642175654201316,\n",
       " 0.129422940519542,\n",
       " 1.31592111393706,\n",
       " 0.257520026203694,\n",
       " 1.03362830429051,\n",
       " -0.356869042585994,\n",
       " 0.384805693494673,\n",
       " -0.00359956318197308,\n",
       " 1.19514559774522,\n",
       " -1.69881018639504,\n",
       " 1.27826994710041,\n",
       " 0.239150515883481,\n",
       " 0.695047175614041,\n",
       " 0.382202121221773,\n",
       " -2.00373462453755,\n",
       " 0.30120187818858,\n",
       " -0.81766084417826,\n",
       " -1.19843375478667,\n",
       " 1.14801144278375,\n",
       " -1.34875177416652,\n",
       " -0.763315239935053,\n",
       " -0.167093798857664,\n",
       " -1.47847546258359,\n",
       " -1.73191860151754,\n",
       " -1.06612104084362,\n",
       " 0.0947402695193354,\n",
       " -0.971258111375682,\n",
       " -1.53257009181108,\n",
       " 0.500709442737836,\n",
       " -0.00996362436460503,\n",
       " -0.0850246435223168,\n",
       " 0.306800483744294,\n",
       " -0.809006505715899,\n",
       " 0.180721392604983,\n",
       " -0.664063576980838,\n",
       " -0.397358539254111,\n",
       " 0.257520026203694,\n",
       " 0.758394347826551,\n",
       " 0.640772533337974,\n",
       " -1.10647583398445,\n",
       " 1.28191560319977,\n",
       " -0.397358539254111,\n",
       " -0.756331953206634,\n",
       " 1.40949953018436,\n",
       " -2.56332895987681,\n",
       " 0.914548771130317,\n",
       " 0.408712982547887,\n",
       " 1.24475737737332,\n",
       " 0.32931896752932,\n",
       " 0.140542876799583,\n",
       " 0.253071201445601,\n",
       " 1.12500429027107,\n",
       " -0.396751011752799,\n",
       " 1.03362830429051,\n",
       " -1.26799312743916,\n",
       " -0.229408504480094,\n",
       " -0.363506516973987,\n",
       " -0.688183878486488,\n",
       " -0.894459477776971,\n",
       " -0.447316813514687,\n",
       " 1.37707956533788,\n",
       " 0.841963787058399,\n",
       " -2.09806992039415,\n",
       " 0.253457304110579,\n",
       " 1.10212913917881,\n",
       " -0.756331953206634,\n",
       " 1.14801144278375,\n",
       " -0.797510820994831,\n",
       " -1.10647583398445,\n",
       " 1.40949953018436,\n",
       " 1.0701905522326,\n",
       " -0.229408504480094,\n",
       " 1.01138250984028,\n",
       " 0.103922759006272,\n",
       " -0.510937573326197,\n",
       " -0.674549859665813,\n",
       " -0.0620659972073883,\n",
       " 1.0701905522326,\n",
       " -0.442071604220517,\n",
       " -0.402137448640123,\n",
       " 0.295919343003049,\n",
       " 1.14801144278375,\n",
       " 0.841963787058399,\n",
       " -1.19746581154428,\n",
       " 0.607304031883433,\n",
       " 0.92062304968959,\n",
       " -1.14685515734813,\n",
       " -1.2408362182553,\n",
       " -1.62054791291846,\n",
       " -0.683895173702397,\n",
       " 0.909631680102414,\n",
       " 0.291981646721172,\n",
       " -1.70434875861064,\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt = '../data/MasterArbeit/data/data_scores'\n",
    "data_tgt = []\n",
    "with open(tgt) as fi:\n",
    "    for line in fi:\n",
    "        data_tgt.append(float(line.strip()))\n",
    "data_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.17366603836231"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(data_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.mean(a)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8722813232690143"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = np.std(a)\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.5666989 , -1.21854359, -0.87038828, -0.52223297, -0.17407766,\n",
       "        0.17407766,  0.52223297,  0.87038828,  1.21854359,  1.5666989 ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = (a-mean)/std\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min = np.min(a)\n",
    "min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max = np.max(a)\n",
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./utils')\n",
    "sys.path.append('./models')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from LinearModel import BasicLinear, BasicLinear_dropout, BiLinear\n",
    "from FullHiddenModel import MultiHeadAttnMlpModel, MultiHeadAttnLSTMModel, MultiHeadAttnConvModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nnInit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers = nn.Sequential()\n",
    "layers.add_module('fc1', nn.Linear(4,2))\n",
    "layers.add_module('fc2', nn.Linear(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers.add_module('bili', MultiHeadAttnLSTMModel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> initializing Linear model\n",
      "Linear (4 -> 2)\n",
      "=> initializing Linear model\n",
      "Linear (2 -> 1)\n",
      "=> initializing Linear model\n",
      "Linear (512 -> 500)\n",
      "=> initializing rnn\n",
      "LSTM(500, 500, num_layers=2)\n",
      "('num layers: ', 4)\n",
      "=> initializing Linear model\n",
      "Linear (500 -> 100)\n",
      "=> initializing BatchNorm1d\n",
      "BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True)\n",
      "=> initializing Linear model\n",
      "Linear (100 -> 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential (\n",
       "  (fc1): Linear (4 -> 2)\n",
       "  (fc2): Linear (2 -> 1)\n",
       "  (bili): MultiHeadAttnLSTMModel (\n",
       "    (attn): MultiHeadAttention (\n",
       "      (attention): ScaledDotProductAttention (\n",
       "        (dropout): Dropout (p = 0.1)\n",
       "        (softmax): Softmax ()\n",
       "      )\n",
       "      (project): Linear (\n",
       "        (li): Linear (512 -> 500)\n",
       "      )\n",
       "      (dropout): Dropout (p = 0.1)\n",
       "    )\n",
       "    (rnn): LSTM(500, 500, num_layers=2)\n",
       "    (mlp): Sequential (\n",
       "      (fc1): Linear (500 -> 100)\n",
       "      (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (act_fun2): LeakyReLU (0.01)\n",
       "      (fc3): Linear (100 -> 1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.apply(nnInit.weight_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py27",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
